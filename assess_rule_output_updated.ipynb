{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67eb78f",
   "metadata": {},
   "source": [
    "### Decide which hand-crafted rules are meaning-preserving and thus safe to include in the reward model (RM) or PPO training.\n",
    "\n",
    "- look into an LLM that provides a targeted German support:\n",
    "  - \"xlm-roberta-base\"\n",
    "  - \"dbmdz/bert-base-german-uncased\"\n",
    "  - deepset/gbert-base\n",
    "  - bert-base-german-dbmdz-uncased\n",
    "\n",
    "- simplification score to be:\n",
    "  - the rule-compliance tracker\n",
    "  - inserting SARI as well would be too 'simple minded'\n",
    "\n",
    "possible simplification score combination\n",
    "- combine \n",
    "- reward = alpha * simplification_score + beta * bert_score\n",
    "- alpha, beta can be tuned depending on priorities (which score is more critical?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e626d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision transformers\n",
    "# pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25ef65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/im_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac338688",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"master_data/0_original/all.txt\"\n",
    "output_path = \"master_data/3_simplified/all_simplified_plain.txt\"\n",
    "#log_path = \"simplification_logs/all_parsed_log_2025-09-13_23-31-26.csv\"\n",
    "log_path = \"simplification_logs/all_parsed_log_2025-09-14_12-38-08.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007d5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99543474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112715 entries, 0 to 112714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   uid                        112715 non-null  int64 \n",
      " 1   original                   112710 non-null  object\n",
      " 2   initial_original_sentence  112715 non-null  object\n",
      " 3   rule                       112715 non-null  object\n",
      " 4   applied                    112715 non-null  bool  \n",
      " 5   simplified                 112654 non-null  object\n",
      " 6   doc_name                   112715 non-null  object\n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24b4ef",
   "metadata": {},
   "source": [
    "#### There are non-null rows in simplified, identified to come from word_to_number() vconversion. They need to be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ececaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112654 entries, 0 to 112714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   uid                        112654 non-null  int64 \n",
      " 1   original                   112654 non-null  object\n",
      " 2   initial_original_sentence  112654 non-null  object\n",
      " 3   rule                       112654 non-null  object\n",
      " 4   applied                    112654 non-null  bool  \n",
      " 5   simplified                 112654 non-null  object\n",
      " 6   doc_name                   112654 non-null  object\n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(how='any', axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62bb9b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original</th>\n",
       "      <th>initial_original_sentence</th>\n",
       "      <th>rule</th>\n",
       "      <th>applied</th>\n",
       "      <th>simplified</th>\n",
       "      <th>doc_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>clean_punctuation</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>rewrite_apposition</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>simplify_subordinate</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>convert_passive_to_active</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>normalize_verb_tense</td>\n",
       "      <td>True</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Präsidentin</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Präsi·Dentin</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>clean_punctuation</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>rewrite_apposition</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>simplify_subordinate</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>convert_passive_to_active</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>normalize_verb_tense</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Mittwoch</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>False</td>\n",
       "      <td>Mittwoch</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>erste</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>convert_word_to_number</td>\n",
       "      <td>True</td>\n",
       "      <td>1.</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>clean_punctuation</td>\n",
       "      <td>False</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>rewrite_apposition</td>\n",
       "      <td>False</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid                                           original  \\\n",
       "0     1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1     1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "2     1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "3     1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "4     1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "5     2                                        Präsidentin   \n",
       "6     2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "7     2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "8     2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "9     2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "10    2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "11    3                                           Mittwoch   \n",
       "12    3                                              erste   \n",
       "13    3  Am Mittwoch hat sie ihre 1. Rede zur Lage der ...   \n",
       "14    3  Am Mittwoch hat sie ihre 1. Rede zur Lage der ...   \n",
       "\n",
       "                            initial_original_sentence  \\\n",
       "0   Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1   Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "2   Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "3   Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "4   Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "5   Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "6   Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "7   Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "8   Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "9   Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "10  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "11  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "12  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "13  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "14  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "\n",
       "                         rule  applied  \\\n",
       "0           clean_punctuation    False   \n",
       "1          rewrite_apposition    False   \n",
       "2        simplify_subordinate    False   \n",
       "3   convert_passive_to_active    False   \n",
       "4        normalize_verb_tense     True   \n",
       "5              split_compound     True   \n",
       "6           clean_punctuation    False   \n",
       "7          rewrite_apposition    False   \n",
       "8        simplify_subordinate    False   \n",
       "9   convert_passive_to_active    False   \n",
       "10       normalize_verb_tense    False   \n",
       "11             split_compound    False   \n",
       "12     convert_word_to_number     True   \n",
       "13          clean_punctuation    False   \n",
       "14         rewrite_apposition    False   \n",
       "\n",
       "                                           simplified        doc_name  \n",
       "0   Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "1   Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "2   Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "3   Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "4   Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "5                                        Präsi·Dentin  all_parsed.txt  \n",
       "6   Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "7   Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "8   Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "9   Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "10  Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "11                                           Mittwoch  all_parsed.txt  \n",
       "12                                                 1.  all_parsed.txt  \n",
       "13  Am Mittwoch hat sie ihre 1. Rede zur Lage der ...  all_parsed.txt  \n",
       "14  Am Mittwoch hat sie ihre 1. Rede zur Lage der ...  all_parsed.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24784 entries, 5 to 108443\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   uid         24784 non-null  int64 \n",
      " 1   original    24784 non-null  object\n",
      " 2   rule        24784 non-null  object\n",
      " 3   applied     24784 non-null  bool  \n",
      " 4   simplified  24784 non-null  object\n",
      " 5   doc_name    24784 non-null  object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"master_data/output_assessment/all_simplifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a49ad",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compound.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e40a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number = df[df[\"rule\"] == \"convert_word_to_number\"]\n",
    "df_number.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89a498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original</th>\n",
       "      <th>rule</th>\n",
       "      <th>applied</th>\n",
       "      <th>simplified</th>\n",
       "      <th>doc_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Präsidentin</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Präsi·Dentin</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8</td>\n",
       "      <td>Lade-Stationen</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Lade·Stationen</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>Elektro-Fahrzeuge</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Elektro·Fahrzeuge</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10</td>\n",
       "      <td>Union-Gesetze</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Union·Gesetze</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>15</td>\n",
       "      <td>Corona-Virus</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Corona·Virus</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108290</th>\n",
       "      <td>16520</td>\n",
       "      <td>Gesundheits-Krise</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Gesundheits·Krise</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108296</th>\n",
       "      <td>16521</td>\n",
       "      <td>Gesundheits-Minister</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Gesundheits·Minister</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108313</th>\n",
       "      <td>16524</td>\n",
       "      <td>Gesundheits-Minister</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Gesundheits·Minister</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108390</th>\n",
       "      <td>16537</td>\n",
       "      <td>Fußball-Trainer</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Fußball·Trainer</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108401</th>\n",
       "      <td>16539</td>\n",
       "      <td>Fußball-Trainer</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Fußball·Trainer</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4954 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid              original            rule  applied  \\\n",
       "5           2           Präsidentin  split_compound     True   \n",
       "46          8        Lade-Stationen  split_compound     True   \n",
       "47          8     Elektro-Fahrzeuge  split_compound     True   \n",
       "59         10         Union-Gesetze  split_compound     True   \n",
       "87         15          Corona-Virus  split_compound     True   \n",
       "...       ...                   ...             ...      ...   \n",
       "108290  16520     Gesundheits-Krise  split_compound     True   \n",
       "108296  16521  Gesundheits-Minister  split_compound     True   \n",
       "108313  16524  Gesundheits-Minister  split_compound     True   \n",
       "108390  16537       Fußball-Trainer  split_compound     True   \n",
       "108401  16539       Fußball-Trainer  split_compound     True   \n",
       "\n",
       "                  simplified        doc_name  \n",
       "5               Präsi·Dentin  all_parsed.txt  \n",
       "46            Lade·Stationen  all_parsed.txt  \n",
       "47         Elektro·Fahrzeuge  all_parsed.txt  \n",
       "59             Union·Gesetze  all_parsed.txt  \n",
       "87              Corona·Virus  all_parsed.txt  \n",
       "...                      ...             ...  \n",
       "108290     Gesundheits·Krise  all_parsed.txt  \n",
       "108296  Gesundheits·Minister  all_parsed.txt  \n",
       "108313  Gesundheits·Minister  all_parsed.txt  \n",
       "108390       Fußball·Trainer  all_parsed.txt  \n",
       "108401       Fußball·Trainer  all_parsed.txt  \n",
       "\n",
       "[4954 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_comp = df_compound[df_compound[\"applied\"] == True]\n",
    "filtered_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_number = df_number[df_number[\"applied\"] == True]\n",
    "filtered_number.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedf05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assess_rule_output(df):\n",
    "#     results = []\n",
    "\n",
    "#     for uid, group in df.groupby(\"uid\"):\n",
    "#         original = group[\"original\"].iloc[0]              # the very first \"original\" sentence\n",
    "#         simplified = group[\"simplified\"].iloc[-1]         # the last simplification\n",
    "#         applied_rules = group.loc[group[\"applied\"] == True, \"rule\"].tolist()\n",
    "\n",
    "#         results.append({\n",
    "#             \"uid\": uid,\n",
    "#             \"original\": original,\n",
    "#             \"simplified\": simplified,\n",
    "#             \"applied_rules\": applied_rules\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654b62c",
   "metadata": {},
   "source": [
    "## Outdated approach to aggregate from applied=True approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f568b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out only applied rules\n",
    "df_applied = df[df[\"applied\"] == True]\n",
    "df_applied.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26041532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applied_dropped.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applied_dropped.to_csv(\"master_data/output_assessment/all_applied_rules.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee51576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTDATED code for the original simplification approach on original/complex sentences\n",
    "\n",
    "# # Get the last applied simplification per sentence UID\n",
    "# # (Assume rules are applied in order of appearance)\n",
    "# last_applied_per_uid = df_applied.groupby(\"uid\").tail(1)\n",
    "\n",
    "# # Also get original sentences from any row (all identical for a UID)\n",
    "# originals_per_uid = df.groupby(\"uid\").first().reset_index()[[\"uid\", \"original\"]]\n",
    "\n",
    "# # Merge to get (original, final simplified) pairs\n",
    "# final_pairs = pd.merge(originals_per_uid, last_applied_per_uid[[\"uid\", \"simplified\"]], on=\"uid\")\n",
    "\n",
    "# # Extract all applied rules per UID (True only)\n",
    "# # gives out UID and a second column of all applied rules according to uid\n",
    "\n",
    "# applied_rules_per_uid = (\n",
    "#     df[df[\"applied\"] == True]\n",
    "#     .groupby(\"uid\")[\"rule\"]\n",
    "#     .apply(list)\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"rule\": \"applied_rules\"})\n",
    "# )\n",
    "\n",
    "# # Merge with the final_pairs (which already has original + final simplified)\n",
    "# final_pairs_with_rules = pd.merge(final_pairs, applied_rules_per_uid, on=\"uid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ====OUTDATED, was applied on applied=True ==== ###\n",
    "# # Get the unique original sentences in the order of their first appearance\n",
    "# #unique_originals = df_applied['original'].unique()\n",
    "# grouped = df_applied_dropped.groupby('uid')\n",
    "\n",
    "# processed_data = []\n",
    "\n",
    "# #for sentence in unique_originals:\n",
    "# for uid, group in grouped:\n",
    "#         # Get all rows for the current original sentence\n",
    "#         #group = df_applied[df_applied['original'] == sentence]\n",
    "        \n",
    "#         # Find all rules that were successfully applied for this group\n",
    "#         applied_rules_list = group[group['applied'] == True]['rule'].tolist()\n",
    "        \n",
    "#         # We only want to include sentences where at least one rule was applied\n",
    "#         if not applied_rules_list:\n",
    "#             continue\n",
    "\n",
    "#         # De-duplicate the list of rules while preserving order\n",
    "#         unique_applied_rules = list(dict.fromkeys(applied_rules_list))\n",
    "\n",
    "#         # Heuristic: The \"main\" original sentence is the longest one in the group\n",
    "#         main_original_sentence = group.loc[group['original'].str.len().idxmax(), 'original']\n",
    "\n",
    "#         # The final simplification is the 'simplified' text from the very last logged step\n",
    "#         final_simplification_text = group.loc[group.index.max(), 'simplified']\n",
    "\n",
    "#         # Alternative (if you want the very last simplification regardless of application):    \n",
    "#         # The final simplification is the 'simplified' text from the very last entry in the group\n",
    "#         #final_simplification_text = group['simplified'].iloc[-1]\n",
    "        \n",
    "#         # Append the structured data\n",
    "#         processed_data.append({\n",
    "#             'uid': uid,\n",
    "#             'original_sentence': main_original_sentence,\n",
    "#             'final_simplification': final_simplification_text,\n",
    "#             'applied_rules': unique_applied_rules\n",
    "#         })\n",
    "\n",
    "# # Create the final DataFrame from our processed list\n",
    "# result_df = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3be140",
   "metadata": {},
   "source": [
    "# Filter out and aggregate from simplification log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7743968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by UID to ensure chronological order of steps, reset index due to dropped rows\n",
    "df = df.sort_values(by=['uid']).reset_index(drop=True)\n",
    "\n",
    "# Group by the unique identifier for each original sentence\n",
    "grouped_by_sentence = df.groupby('uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea307cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('uid')\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "#for sentence in unique_originals:\n",
    "for uid, group in grouped:\n",
    "        # Get all rows for the current original sentence\n",
    "        #group = df_applied[df_applied['original'] == sentence]\n",
    "        \n",
    "        # Find all rules that were successfully applied for this group\n",
    "        applied_rules_list = group[group['applied'] == True]['rule'].tolist()\n",
    "        \n",
    "        # We only want to include sentences where at least one rule was applied\n",
    "        if not applied_rules_list:\n",
    "            continue\n",
    "\n",
    "        # De-duplicate the list of rules while preserving order\n",
    "        unique_applied_rules = list(dict.fromkeys(applied_rules_list))\n",
    "\n",
    "        # Heuristic: The \"main\" original sentence is the longest one in the group\n",
    "        main_original_sentence = group.loc[group['original'].str.len().idxmax(), 'original']\n",
    "\n",
    "        # The final simplification is the 'simplified' text from the very last logged step\n",
    "        final_simplification_text = group.loc[group.index.max(), 'simplified']\n",
    "\n",
    "        # Alternative (if you want the very last simplification regardless of application):    \n",
    "        # The final simplification is the 'simplified' text from the very last entry in the group\n",
    "        #final_simplification_text = group['simplified'].iloc[-1]\n",
    "        \n",
    "        # Append the structured data\n",
    "        processed_data.append({\n",
    "            'uid': uid,\n",
    "            'original_sentence': main_original_sentence,\n",
    "            'final_simplification': final_simplification_text,\n",
    "            'applied_rules': unique_applied_rules\n",
    "        })\n",
    "\n",
    "# Create the final DataFrame from our processed list\n",
    "result_df = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final DataFrame from the processed list\n",
    "result_df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Display the first few rows of the result\n",
    "result_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the final result by UID to approximate the original file order\n",
    "result_df = result_df.sort_values(by='uid').reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f138e6",
   "metadata": {},
   "source": [
    "### Applying final cleanup step on df to eliminate trainling whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanup = result_df.copy()\n",
    "df_cleanup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanup.columns = df_cleanup.columns.str.strip() # This removes leading/trailing spaces from each column name\n",
    "\n",
    "def clean_all_whitespace(sentence):\n",
    "  \"\"\"\n",
    "  Replaces multiple spaces inside a string with a single space,\n",
    "  and then strips leading/trailing whitespace.\n",
    "  \"\"\"\n",
    "  # 0: If the input is not a string, return it as is\n",
    "  if not isinstance(sentence, str):\n",
    "      return sentence\n",
    "  # 1: Clean up all internal whitespace first.\n",
    "  sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "  # 2: Strip whitespace from the beginning and end\n",
    "  sentence = re.sub(r'\\s+([.,:;?!])', r'\\1', sentence)\n",
    "  return sentence\n",
    "\n",
    "columns_to_clean = ['original_sentence', 'final_simplification']\n",
    "\n",
    "print(f\"Attempting to strip whitespace from columns: {', '.join(columns_to_clean)}\")\n",
    "\n",
    "# Loop through the identified columns and apply the strip() method\n",
    "for col in columns_to_clean:\n",
    "  if col in df_cleanup.columns and df_cleanup[col].dtype == 'object':\n",
    "    print(f\"Cleaning column: '{col}'...\")\n",
    "    # Apply our new, more powerful cleaning function to each sentence in the column\n",
    "    df_cleanup[col] = df_cleanup[col].apply(clean_all_whitespace)\n",
    "  else:\n",
    "    print(f\"Column '{col}' not found or is not a text column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleanup.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3303244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58724a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'master_data/output_assessment/ordered_simplifications_with_rules_clean_FINAL.csv'\n",
    "df_cleanup.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150186ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\Saved the final, ordered file: '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keel original_sentence and final_simplification\n",
    "final_pairs = df_cleanup[['original_sentence', 'final_simplification']]\n",
    "final_pairs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39900e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pairs.to_csv(\"master_data/output_assessment/final_simplified_pairs_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056848c8",
   "metadata": {},
   "source": [
    "# Assess the Performance using roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your exported sentence pairs\n",
    "df = pd.read_csv(\"final_simplified_pairs.csv\")\n",
    "\n",
    "originals = df[\"original\"].tolist()\n",
    "simplifieds = df[\"simplified\"].tolist()\n",
    "\n",
    "# Compute BERTScore using German-specific model\n",
    "P, R, F1 = score(simplifieds, originals, model_type=\"xlm-roberta-base\", lang=\"de\")\n",
    "\n",
    "# Add scores back to dataframe\n",
    "df[\"bertscore_f1\"] = F1.tolist()\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(\"bert_score_results.csv\", index=False)\n",
    "print(\"Done! Results saved to 'bert_score_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6903569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate with the csv files that includes applied rules\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load final output with applied rules\n",
    "df_rules = pd.read_csv(\"final_simplified_pairs_with_rules.csv\")  # <- export this first from our current state\n",
    "\n",
    "# Group sentence pairs by rule\n",
    "rule_to_pairs = defaultdict(list)\n",
    "\n",
    "for _, row in df_rules.iterrows():\n",
    "    if pd.isna(row[\"applied_rules\"]):\n",
    "        continue\n",
    "    rules = eval(row[\"applied_rules\"]) if isinstance(row[\"applied_rules\"], str) else row[\"applied_rules\"]\n",
    "    for rule in rules:\n",
    "        rule_to_pairs[rule].append((row[\"original\"], row[\"simplified\"]))\n",
    "\n",
    "# Compute average BERTScore-F1 per rule\n",
    "rule_to_f1 = {}\n",
    "\n",
    "for rule, pairs in rule_to_pairs.items():\n",
    "    o, s = zip(*pairs)\n",
    "    _, _, F1 = score(s, o, model_type=\"xlm-roberta-base\", lang=\"de\") #bert-base-german-dbmdz-uncased #\n",
    "    rule_to_f1[rule] = sum(F1.tolist()) / len(F1)\n",
    "\n",
    "# Print results\n",
    "print(\"Average BERTScore-F1 per rule:\")\n",
    "for rule, f1 in sorted(rule_to_f1.items(), key=lambda x: x[1]):\n",
    "    print(f\"{rule}: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Example calc\n",
    "\n",
    "# # Original vs. Simplified sentences\n",
    "# originals = [\"Der Hund läuft schnell zur Tür.\"]\n",
    "# simplifieds = [\"Der Hund rennt zur Tür.\"]\n",
    "\n",
    "# # Compute BERTScore using a German or multilingual model\n",
    "# P, R, F1 = score(simplifieds, originals, lang=\"de\", model_type=\"bert-base-multilingual-cased\")\n",
    "\n",
    "# print(f\"Precision: {P.mean().item():.4f}\")\n",
    "# print(f\"Recall: {R.mean().item():.4f}\")\n",
    "# print(f\"F1: {F1.mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f2704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "im_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
