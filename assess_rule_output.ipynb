{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67eb78f",
   "metadata": {},
   "source": [
    "### Decide which hand-crafted rules are meaning-preserving and thus safe to include in the reward model (RM) or PPO training.\n",
    "\n",
    "- look into an LLM that provides a targeted German support:\n",
    "  - \"xlm-roberta-base\"\n",
    "  - \"dbmdz/bert-base-german-uncased\"\n",
    "  - deepset/gbert-base\n",
    "  - bert-base-german-dbmdz-uncased\n",
    "\n",
    "- simplification score to be:\n",
    "  - the rule-compliance tracker\n",
    "  - inserting SARI as well would be too 'simple minded'\n",
    "\n",
    "possible simplification score combination\n",
    "- combine \n",
    "- reward = alpha * simplification_score + beta * bert_score\n",
    "- alpha, beta can be tuned depending on priorities (which score is more critical?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e626d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision transformers\n",
    "# pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25ef65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/im_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac338688",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"master_data/0_original/all.txt\"\n",
    "output_path = \"master_data/3_simplified/all_simplified_plain.txt\"\n",
    "#log_path = \"simplification_logs/all_parsed_log_2025-09-13_23-31-26.csv\"\n",
    "log_path = \"simplification_logs/all_parsed_log_2025-09-14_12-38-08.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007d5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99543474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112715 entries, 0 to 112714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   uid                        112715 non-null  int64 \n",
      " 1   original                   112710 non-null  object\n",
      " 2   initial_original_sentence  112715 non-null  object\n",
      " 3   rule                       112715 non-null  object\n",
      " 4   applied                    112715 non-null  bool  \n",
      " 5   simplified                 112654 non-null  object\n",
      " 6   doc_name                   112715 non-null  object\n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83df4e5",
   "metadata": {},
   "source": [
    "#### There are non-null rows in simplified, identified to come from word_to_number() vconversion. They need to be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d87e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112654 entries, 0 to 112714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   uid                        112654 non-null  int64 \n",
      " 1   original                   112654 non-null  object\n",
      " 2   initial_original_sentence  112654 non-null  object\n",
      " 3   rule                       112654 non-null  object\n",
      " 4   applied                    112654 non-null  bool  \n",
      " 5   simplified                 112654 non-null  object\n",
      " 6   doc_name                   112654 non-null  object\n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(how='any', axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62bb9b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original</th>\n",
       "      <th>initial_original_sentence</th>\n",
       "      <th>rule</th>\n",
       "      <th>applied</th>\n",
       "      <th>simplified</th>\n",
       "      <th>doc_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>clean_punctuation</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>rewrite_apposition</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>simplify_subordinate</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>convert_passive_to_active</td>\n",
       "      <td>False</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>normalize_verb_tense</td>\n",
       "      <td>True</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Präsidentin</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>split_compound</td>\n",
       "      <td>True</td>\n",
       "      <td>Präsi·Dentin</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>clean_punctuation</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>rewrite_apposition</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>simplify_subordinate</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>convert_passive_to_active</td>\n",
       "      <td>False</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>all_parsed.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                           original  \\\n",
       "0    1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1    1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "2    1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "3    1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "4    1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "5    2                                        Präsidentin   \n",
       "6    2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "7    2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "8    2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "9    2  Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "\n",
       "                           initial_original_sentence  \\\n",
       "0  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "2  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "3  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "4  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "5  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "6  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "7  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "8  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "9  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "\n",
       "                        rule  applied  \\\n",
       "0          clean_punctuation    False   \n",
       "1         rewrite_apposition    False   \n",
       "2       simplify_subordinate    False   \n",
       "3  convert_passive_to_active    False   \n",
       "4       normalize_verb_tense     True   \n",
       "5             split_compound     True   \n",
       "6          clean_punctuation    False   \n",
       "7         rewrite_apposition    False   \n",
       "8       simplify_subordinate    False   \n",
       "9  convert_passive_to_active    False   \n",
       "\n",
       "                                          simplified        doc_name  \n",
       "0  Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "1  Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "2  Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "3  Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "4  Der Iran wird teilweise aus dem Atom-Abkommen ...  all_parsed.txt  \n",
       "5                                       Präsi·Dentin  all_parsed.txt  \n",
       "6  Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "7  Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "8  Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  \n",
       "9  Brüssel Ursula von der Leyen ist die Präsi·Den...  all_parsed.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"master_data/output_assessment/all_simplifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28258c",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compound.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7104c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number = df[df[\"rule\"] == \"convert_word_to_number\"]\n",
    "df_number.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_comp = df_compound[df_compound[\"applied\"] == True]\n",
    "filtered_comp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_number = df_number[df_number[\"applied\"] == True]\n",
    "filtered_number.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assess_rule_output(df):\n",
    "#     results = []\n",
    "\n",
    "#     for uid, group in df.groupby(\"uid\"):\n",
    "#         original = group[\"original\"].iloc[0]              # the very first \"original\" sentence\n",
    "#         simplified = group[\"simplified\"].iloc[-1]         # the last simplification\n",
    "#         applied_rules = group.loc[group[\"applied\"] == True, \"rule\"].tolist()\n",
    "\n",
    "#         results.append({\n",
    "#             \"uid\": uid,\n",
    "#             \"original\": original,\n",
    "#             \"simplified\": simplified,\n",
    "#             \"applied_rules\": applied_rules\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5fe895",
   "metadata": {},
   "source": [
    "## Outdated approach to aggregate from applied=True approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out only applied rules\n",
    "df_applied = df[df[\"applied\"] == True]\n",
    "df_applied.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applied_dropped.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applied_dropped.to_csv(\"master_data/output_assessment/all_applied_rules.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTDATED code for the original simplification approach on original/complex sentences\n",
    "\n",
    "# # Get the last applied simplification per sentence UID\n",
    "# # (Assume rules are applied in order of appearance)\n",
    "# last_applied_per_uid = df_applied.groupby(\"uid\").tail(1)\n",
    "\n",
    "# # Also get original sentences from any row (all identical for a UID)\n",
    "# originals_per_uid = df.groupby(\"uid\").first().reset_index()[[\"uid\", \"original\"]]\n",
    "\n",
    "# # Merge to get (original, final simplified) pairs\n",
    "# final_pairs = pd.merge(originals_per_uid, last_applied_per_uid[[\"uid\", \"simplified\"]], on=\"uid\")\n",
    "\n",
    "# # Extract all applied rules per UID (True only)\n",
    "# # gives out UID and a second column of all applied rules according to uid\n",
    "\n",
    "# applied_rules_per_uid = (\n",
    "#     df[df[\"applied\"] == True]\n",
    "#     .groupby(\"uid\")[\"rule\"]\n",
    "#     .apply(list)\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"rule\": \"applied_rules\"})\n",
    "# )\n",
    "\n",
    "# # Merge with the final_pairs (which already has original + final simplified)\n",
    "# final_pairs_with_rules = pd.merge(final_pairs, applied_rules_per_uid, on=\"uid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ====OUTDATED, was applied on applied=True ==== ###\n",
    "# # Get the unique original sentences in the order of their first appearance\n",
    "# #unique_originals = df_applied['original'].unique()\n",
    "# grouped = df_applied_dropped.groupby('uid')\n",
    "\n",
    "# processed_data = []\n",
    "\n",
    "# #for sentence in unique_originals:\n",
    "# for uid, group in grouped:\n",
    "#         # Get all rows for the current original sentence\n",
    "#         #group = df_applied[df_applied['original'] == sentence]\n",
    "        \n",
    "#         # Find all rules that were successfully applied for this group\n",
    "#         applied_rules_list = group[group['applied'] == True]['rule'].tolist()\n",
    "        \n",
    "#         # We only want to include sentences where at least one rule was applied\n",
    "#         if not applied_rules_list:\n",
    "#             continue\n",
    "\n",
    "#         # De-duplicate the list of rules while preserving order\n",
    "#         unique_applied_rules = list(dict.fromkeys(applied_rules_list))\n",
    "\n",
    "#         # Heuristic: The \"main\" original sentence is the longest one in the group\n",
    "#         main_original_sentence = group.loc[group['original'].str.len().idxmax(), 'original']\n",
    "\n",
    "#         # The final simplification is the 'simplified' text from the very last logged step\n",
    "#         final_simplification_text = group.loc[group.index.max(), 'simplified']\n",
    "\n",
    "#         # Alternative (if you want the very last simplification regardless of application):    \n",
    "#         # The final simplification is the 'simplified' text from the very last entry in the group\n",
    "#         #final_simplification_text = group['simplified'].iloc[-1]\n",
    "        \n",
    "#         # Append the structured data\n",
    "#         processed_data.append({\n",
    "#             'uid': uid,\n",
    "#             'original_sentence': main_original_sentence,\n",
    "#             'final_simplification': final_simplification_text,\n",
    "#             'applied_rules': unique_applied_rules\n",
    "#         })\n",
    "\n",
    "# # Create the final DataFrame from our processed list\n",
    "# result_df = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb22725",
   "metadata": {},
   "source": [
    "# Filter out and aggregate from simplification log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a74d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112654 entries, 0 to 112714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   uid                        112654 non-null  int64 \n",
      " 1   original                   112654 non-null  object\n",
      " 2   initial_original_sentence  112654 non-null  object\n",
      " 3   rule                       112654 non-null  object\n",
      " 4   applied                    112654 non-null  bool  \n",
      " 5   simplified                 112654 non-null  object\n",
      " 6   doc_name                   112654 non-null  object\n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f05351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rule categories\n",
    "PARTIAL_RULES = {\"split_compound\", \"convert_word_to_number\"}\n",
    "SPLIT_RULES = {\"rewrite_apposition\", \"simplify_subordinate\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ff6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s: str) -> str:\n",
    "    \"\"\"Whitespace-normalize a string for duplicate checks.\"\"\"\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def split_into_sentences(text: str):\n",
    "    \"\"\"\n",
    "    Very lightweight sentence splitter for cleanup/dedup.\n",
    "    Splits on . ! ? while keeping punctuation.\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    parts = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "    return [normalize(p) for p in parts if normalize(p)]\n",
    "\n",
    "def dedup_preserve_order(items):\n",
    "    \"\"\"Remove duplicates while preserving order.\"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for it in items:\n",
    "        key = normalize(it)\n",
    "        if key not in seen:\n",
    "            out.append(it)\n",
    "            seen.add(key)\n",
    "    return out\n",
    "\n",
    "records = []\n",
    "\n",
    "# Process sentence-by-sentence groups\n",
    "for uid, group in df.groupby(\"uid\", sort=False):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    # Collect applied rules\n",
    "    applied_rules_list = group[group[\"applied\"] == True][\"rule\"].tolist()\n",
    "    if not applied_rules_list:\n",
    "        continue\n",
    "\n",
    "    # Deduplicate rules while preserving order\n",
    "    seen_rules = set()\n",
    "    unique_applied_rules = []\n",
    "    for r in applied_rules_list:\n",
    "        if r not in seen_rules:\n",
    "            unique_applied_rules.append(r)\n",
    "            seen_rules.add(r)\n",
    "\n",
    "    # Did any split-type rule fire?\n",
    "    split_applied = any(r in SPLIT_RULES for r in unique_applied_rules)\n",
    "\n",
    "    # Start from the true original\n",
    "    main_sentence = normalize(group[\"initial_original_sentence\"].iloc[0])\n",
    "    sentences = [main_sentence]\n",
    "    seen_sentences = {main_sentence}\n",
    "\n",
    "    # Replay transformations\n",
    "    for _, row in group.iterrows():\n",
    "        if not row[\"applied\"]:\n",
    "            continue\n",
    "\n",
    "        rule = row[\"rule\"]\n",
    "        simplified_piece = normalize(row[\"simplified\"]) if pd.notna(row[\"simplified\"]) else \"\"\n",
    "        original_piece   = normalize(row[\"original\"]) if pd.notna(row[\"original\"]) else \"\"\n",
    "\n",
    "        if rule in PARTIAL_RULES:\n",
    "            # Patch fragment into the last sentence\n",
    "            if original_piece and original_piece in sentences[-1]:\n",
    "                sentences[-1] = sentences[-1].replace(original_piece, simplified_piece, 1)\n",
    "\n",
    "        elif rule in SPLIT_RULES:\n",
    "            # Append new sentence(s), deduped\n",
    "            if simplified_piece:\n",
    "                new_sents = split_into_sentences(simplified_piece) or [simplified_piece]\n",
    "                for ns in new_sents:\n",
    "                    ns_norm = normalize(ns)\n",
    "                    if ns_norm not in seen_sentences:\n",
    "                        sentences.append(ns)\n",
    "                        seen_sentences.add(ns_norm)\n",
    "\n",
    "        else:\n",
    "            # Full-sentence rewrite\n",
    "            if simplified_piece:\n",
    "                sentences[-1] = simplified_piece\n",
    "\n",
    "    # --- Post-processing ---\n",
    "    # sentences = dedup_preserve_order(sentences)\n",
    "\n",
    "    # # Drop the original if split happened and we now have other sentences\n",
    "    # original_norm = normalize(group[\"initial_original_sentence\"].iloc[0])\n",
    "    # if split_applied and any(normalize(s) != original_norm for s in sentences):\n",
    "    #     sentences = [s for s in sentences if normalize(s) != original_norm]\n",
    "\n",
    "    # # Join final sentences\n",
    "    # final_text = \" \".join(sentences).strip()\n",
    "\n",
    "    # # Safety: remove the original if it still appears verbatim in the joined text\n",
    "    # if split_applied and len(sentences) > 1 and original_norm in normalize(final_text):\n",
    "    #     raw_original = group[\"initial_original_sentence\"].iloc[0]\n",
    "    #     final_text = final_text.replace(raw_original, \"\", 1).strip()\n",
    "    #     final_text = normalize(final_text)\n",
    "\n",
    "    # --- Post-processing ---\n",
    "    sentences = dedup_preserve_order(sentences)\n",
    "\n",
    "    original_raw  = group[\"initial_original_sentence\"].iloc[0]\n",
    "    original_norm = normalize(original_raw)\n",
    "\n",
    "    if split_applied:\n",
    "        # Check if the original still appears exactly as one of the collected sentences\n",
    "        has_exact_original = any(normalize(s) == original_norm for s in sentences)\n",
    "        has_transformed    = any(original_norm in normalize(s) and normalize(s) != original_norm for s in sentences)\n",
    "\n",
    "        if has_exact_original and not has_transformed:\n",
    "            # Only drop the original if it is *unchanged* and other sentences exist\n",
    "            if len(sentences) > 1:\n",
    "                sentences = [s for s in sentences if normalize(s) != original_norm]\n",
    "\n",
    "    # Join final sentences\n",
    "    final_text = \" \".join(sentences).strip()\n",
    "\n",
    "\n",
    "    # Store result\n",
    "    records.append({\n",
    "        \"uid\": uid,\n",
    "        \"original_sentence\": group[\"initial_original_sentence\"].iloc[0],\n",
    "        \"final_simplification\": final_text,\n",
    "        \"applied_rules\": unique_applied_rules\n",
    "    })\n",
    "\n",
    "# Build DataFrame\n",
    "result_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c515ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>final_simplification</th>\n",
       "      <th>applied_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>16520</td>\n",
       "      <td>Derzeit gibt es eine schlimme Gesundheits-Kris...</td>\n",
       "      <td>Anschober hat Derzeit gibt es eine schlimme Ge...</td>\n",
       "      <td>[split_compound, normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>16521</td>\n",
       "      <td>Deshalb braucht Österreich einen Gesundheits-M...</td>\n",
       "      <td>Deshalb braucht Österreich einen Gesundheits·M...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11094</th>\n",
       "      <td>16524</td>\n",
       "      <td>Ein Arzt wird neuer Gesundheits-Minister von Ö...</td>\n",
       "      <td>Ein Arzt wird neuer Gesundheits·Minister von Ö...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11095</th>\n",
       "      <td>16527</td>\n",
       "      <td>Aber jetzt wird er in Wien und in Niederösterr...</td>\n",
       "      <td>Man hat er verlängert.</td>\n",
       "      <td>[convert_passive_to_active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>16528</td>\n",
       "      <td>Dort dauert der Lockdown nun bis 2. Mai .</td>\n",
       "      <td>Dort dauert der Lockdown nun bis 2 Mai .</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11097</th>\n",
       "      <td>16529</td>\n",
       "      <td>Der Lockdown sollte bis zum 18. April dauern .</td>\n",
       "      <td>Der Lockdown hat bis zum 18 April dauern gesollt.</td>\n",
       "      <td>[convert_word_to_number, normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>16530</td>\n",
       "      <td>Man weiß noch nicht , ob der Lockdown auch im ...</td>\n",
       "      <td>Man hat Man nicht verlängert.</td>\n",
       "      <td>[convert_passive_to_active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>16531</td>\n",
       "      <td>Das soll am Mittwoch entschieden werden .</td>\n",
       "      <td>Man hat Das entschieden.</td>\n",
       "      <td>[convert_passive_to_active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>16535</td>\n",
       "      <td>Im Ramadan essen und trinken die Muslime tagsü...</td>\n",
       "      <td>Im Ramadan essen und trinken die Muslime tagsü...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11101</th>\n",
       "      <td>16537</td>\n",
       "      <td>Der Fußball-Trainer Adi Hütter wechselt zu Mön...</td>\n",
       "      <td>Der Fußball·Trainer Adi Hütter wechselt zu Mön...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11102</th>\n",
       "      <td>16539</td>\n",
       "      <td>Mönchengladbach Adi Hütter ist ein Fußball-Tra...</td>\n",
       "      <td>Mönchengladbach Adi Hütter ist ein Fußball·Tra...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11103</th>\n",
       "      <td>16541</td>\n",
       "      <td>Hütter wird aber mit Saison-Ende in der deutsc...</td>\n",
       "      <td>Hütter wird aber mit Saison-Ende in der deutsc...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>16544</td>\n",
       "      <td>2024.</td>\n",
       "      <td>2024</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11105</th>\n",
       "      <td>16545</td>\n",
       "      <td>Für Hütter muss Mönchengladbach eine hohe Ablö...</td>\n",
       "      <td>Für Hütter muss Mönchengladbach eine hohe Ablö...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>16546</td>\n",
       "      <td>Deutsche Zeitungen rechen mit einer Ablöse von...</td>\n",
       "      <td>Deutsche Zeitungen rechen mit einer Ablöse von...</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                                  original_sentence  \\\n",
       "11092  16520  Derzeit gibt es eine schlimme Gesundheits-Kris...   \n",
       "11093  16521  Deshalb braucht Österreich einen Gesundheits-M...   \n",
       "11094  16524  Ein Arzt wird neuer Gesundheits-Minister von Ö...   \n",
       "11095  16527  Aber jetzt wird er in Wien und in Niederösterr...   \n",
       "11096  16528          Dort dauert der Lockdown nun bis 2. Mai .   \n",
       "11097  16529     Der Lockdown sollte bis zum 18. April dauern .   \n",
       "11098  16530  Man weiß noch nicht , ob der Lockdown auch im ...   \n",
       "11099  16531          Das soll am Mittwoch entschieden werden .   \n",
       "11100  16535  Im Ramadan essen und trinken die Muslime tagsü...   \n",
       "11101  16537  Der Fußball-Trainer Adi Hütter wechselt zu Mön...   \n",
       "11102  16539  Mönchengladbach Adi Hütter ist ein Fußball-Tra...   \n",
       "11103  16541  Hütter wird aber mit Saison-Ende in der deutsc...   \n",
       "11104  16544                                              2024.   \n",
       "11105  16545  Für Hütter muss Mönchengladbach eine hohe Ablö...   \n",
       "11106  16546  Deutsche Zeitungen rechen mit einer Ablöse von...   \n",
       "\n",
       "                                    final_simplification  \\\n",
       "11092  Anschober hat Derzeit gibt es eine schlimme Ge...   \n",
       "11093  Deshalb braucht Österreich einen Gesundheits·M...   \n",
       "11094  Ein Arzt wird neuer Gesundheits·Minister von Ö...   \n",
       "11095                             Man hat er verlängert.   \n",
       "11096           Dort dauert der Lockdown nun bis 2 Mai .   \n",
       "11097  Der Lockdown hat bis zum 18 April dauern gesollt.   \n",
       "11098                      Man hat Man nicht verlängert.   \n",
       "11099                           Man hat Das entschieden.   \n",
       "11100  Im Ramadan essen und trinken die Muslime tagsü...   \n",
       "11101  Der Fußball·Trainer Adi Hütter wechselt zu Mön...   \n",
       "11102  Mönchengladbach Adi Hütter ist ein Fußball·Tra...   \n",
       "11103  Hütter wird aber mit Saison-Ende in der deutsc...   \n",
       "11104                                               2024   \n",
       "11105  Für Hütter muss Mönchengladbach eine hohe Ablö...   \n",
       "11106  Deutsche Zeitungen rechen mit einer Ablöse von...   \n",
       "\n",
       "                                        applied_rules  \n",
       "11092          [split_compound, normalize_verb_tense]  \n",
       "11093                                [split_compound]  \n",
       "11094                                [split_compound]  \n",
       "11095                     [convert_passive_to_active]  \n",
       "11096                        [convert_word_to_number]  \n",
       "11097  [convert_word_to_number, normalize_verb_tense]  \n",
       "11098                     [convert_passive_to_active]  \n",
       "11099                     [convert_passive_to_active]  \n",
       "11100                          [normalize_verb_tense]  \n",
       "11101                                [split_compound]  \n",
       "11102                                [split_compound]  \n",
       "11103                          [normalize_verb_tense]  \n",
       "11104                        [convert_word_to_number]  \n",
       "11105                          [normalize_verb_tense]  \n",
       "11106                        [convert_word_to_number]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6901aa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>final_simplification</th>\n",
       "      <th>applied_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bis zum Jahr 2030 soll es in der Europäische U...</td>\n",
       "      <td>Bis zum Jahr 2030 soll es in der Europäische U...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Das ist sehr viel , denn in den letzten 29 Jah...</td>\n",
       "      <td>Das hat ist sehr viel , denn in den letzten 29...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11102</th>\n",
       "      <td>16539</td>\n",
       "      <td>Mönchengladbach Adi Hütter ist ein Fußball-Tra...</td>\n",
       "      <td>Mönchengladbach Adi Hütter ist ein Fußball·Tra...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11103</th>\n",
       "      <td>16541</td>\n",
       "      <td>Hütter wird aber mit Saison-Ende in der deutsc...</td>\n",
       "      <td>Hütter wird aber mit Saison-Ende in der deutsc...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>16544</td>\n",
       "      <td>2024.</td>\n",
       "      <td>2024</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11105</th>\n",
       "      <td>16545</td>\n",
       "      <td>Für Hütter muss Mönchengladbach eine hohe Ablö...</td>\n",
       "      <td>Für Hütter muss Mönchengladbach eine hohe Ablö...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>16546</td>\n",
       "      <td>Deutsche Zeitungen rechen mit einer Ablöse von...</td>\n",
       "      <td>Deutsche Zeitungen rechen mit einer Ablöse von...</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11107 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                                  original_sentence  \\\n",
       "0          1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1          2  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "2          3  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "3          4  Bis zum Jahr 2030 soll es in der Europäische U...   \n",
       "4          5  Das ist sehr viel , denn in den letzten 29 Jah...   \n",
       "...      ...                                                ...   \n",
       "11102  16539  Mönchengladbach Adi Hütter ist ein Fußball-Tra...   \n",
       "11103  16541  Hütter wird aber mit Saison-Ende in der deutsc...   \n",
       "11104  16544                                              2024.   \n",
       "11105  16545  Für Hütter muss Mönchengladbach eine hohe Ablö...   \n",
       "11106  16546  Deutsche Zeitungen rechen mit einer Ablöse von...   \n",
       "\n",
       "                                    final_simplification  \\\n",
       "0      Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1      Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "2      Am Mittwoch hat sie ihre 1. Rede zur Lage der ...   \n",
       "3      Bis zum Jahr 2030 soll es in der Europäische U...   \n",
       "4      Das hat ist sehr viel , denn in den letzten 29...   \n",
       "...                                                  ...   \n",
       "11102  Mönchengladbach Adi Hütter ist ein Fußball·Tra...   \n",
       "11103  Hütter wird aber mit Saison-Ende in der deutsc...   \n",
       "11104                                               2024   \n",
       "11105  Für Hütter muss Mönchengladbach eine hohe Ablö...   \n",
       "11106  Deutsche Zeitungen rechen mit einer Ablöse von...   \n",
       "\n",
       "                  applied_rules  \n",
       "0        [normalize_verb_tense]  \n",
       "1              [split_compound]  \n",
       "2      [convert_word_to_number]  \n",
       "3        [normalize_verb_tense]  \n",
       "4        [normalize_verb_tense]  \n",
       "...                         ...  \n",
       "11102          [split_compound]  \n",
       "11103    [normalize_verb_tense]  \n",
       "11104  [convert_word_to_number]  \n",
       "11105    [normalize_verb_tense]  \n",
       "11106  [convert_word_to_number]  \n",
       "\n",
       "[11107 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the final result by UID to approximate the original file order\n",
    "result_df = result_df.sort_values(by='uid').reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32644fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>final_simplification</th>\n",
       "      <th>applied_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bis zum Jahr 2030 soll es in der Europäische U...</td>\n",
       "      <td>Bis zum Jahr 2030 soll es in der Europäische U...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Das ist sehr viel , denn in den letzten 29 Jah...</td>\n",
       "      <td>Das hat ist sehr viel , denn in den letzten 29...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                  original_sentence  \\\n",
       "0    1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1    2  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "2    3  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "3    4  Bis zum Jahr 2030 soll es in der Europäische U...   \n",
       "4    5  Das ist sehr viel , denn in den letzten 29 Jah...   \n",
       "\n",
       "                                final_simplification             applied_rules  \n",
       "0  Der Iran wird teilweise aus dem Atom-Abkommen ...    [normalize_verb_tense]  \n",
       "1  Brüssel Ursula von der Leyen ist die Präsi·Den...          [split_compound]  \n",
       "2  Am Mittwoch hat sie ihre 1. Rede zur Lage der ...  [convert_word_to_number]  \n",
       "3  Bis zum Jahr 2030 soll es in der Europäische U...    [normalize_verb_tense]  \n",
       "4  Das hat ist sehr viel , denn in den letzten 29...    [normalize_verb_tense]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2814128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11107 entries, 0 to 11106\n",
      "Data columns (total 4 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   uid                   11107 non-null  int64 \n",
      " 1   original_sentence     11107 non-null  object\n",
      " 2   final_simplification  11107 non-null  object\n",
      " 3   applied_rules         11107 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 347.2+ KB\n"
     ]
    }
   ],
   "source": [
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a3b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanup = result_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5d046b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11107 entries, 0 to 11106\n",
      "Data columns (total 4 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   uid                   11107 non-null  int64 \n",
      " 1   original_sentence     11107 non-null  object\n",
      " 2   final_simplification  11107 non-null  object\n",
      " 3   applied_rules         11107 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 347.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleanup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd09ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to strip whitespace from columns: original_sentence, final_simplification\n",
      "Cleaning column: 'original_sentence'...\n",
      "Cleaning column: 'final_simplification'...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cleanup.columns = df_cleanup.columns.str.strip() # This removes leading/trailing spaces from each column name\n",
    "\n",
    "def clean_all_whitespace(sentence):\n",
    "  \"\"\"\n",
    "  Replaces multiple spaces inside a string with a single space,\n",
    "  and then strips leading/trailing whitespace.\n",
    "  \"\"\"\n",
    "  # 0: If the input is not a string, return it as is\n",
    "  if not isinstance(sentence, str):\n",
    "      return sentence\n",
    "  # 1: Clean up all internal whitespace first.\n",
    "  sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "  # 2: Strip whitespace from the beginning and end\n",
    "  sentence = re.sub(r'\\s+([.,:;?!])', r'\\1', sentence)\n",
    "  return sentence\n",
    "\n",
    "columns_to_clean = ['original_sentence', 'final_simplification']\n",
    "\n",
    "print(f\"Attempting to strip whitespace from columns: {', '.join(columns_to_clean)}\")\n",
    "\n",
    "# Loop through the identified columns and apply the strip() method\n",
    "for col in columns_to_clean:\n",
    "  if col in df_cleanup.columns and df_cleanup[col].dtype == 'object':\n",
    "    print(f\"Cleaning column: '{col}'...\")\n",
    "    # Apply our new, more powerful cleaning function to each sentence in the column\n",
    "    df_cleanup[col] = df_cleanup[col].apply(clean_all_whitespace)\n",
    "  else:\n",
    "    print(f\"Column '{col}' not found or is not a text column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da7f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   uid | original_sentence                                                                              | final_simplification                                                                           | applied_rules              |\n",
      "|------:|:-----------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|:---------------------------|\n",
      "|     1 | Der Iran wird teilweise aus dem Atom-Abkommen aussteigen.                                      | Der Iran wird teilweise aus dem Atom-Abkommen aussteigen.                                      | ['normalize_verb_tense']   |\n",
      "|     2 | Brüssel Ursula von der Leyen ist die Präsidentin von der Europäische Union-Kommission.         | Brüssel Ursula von der Leyen ist die Präsi·Dentin von der Europäische Union-Kommission.        | ['split_compound']         |\n",
      "|     3 | Am Mittwoch hat sie ihre erste Rede zur Lage der Europäische Union gehalten.                   | Am Mittwoch hat sie ihre 1. Rede zur Lage der Europäische Union gehalten.                      | ['convert_word_to_number'] |\n",
      "|     4 | Bis zum Jahr 2030 soll es in der Europäische Union um 55 Prozent weniger Treibhaus-Gase geben. | Bis zum Jahr 2030 soll es in der Europäische Union um 55 Prozent weniger Treibhaus-Gase geben. | ['normalize_verb_tense']   |\n",
      "|     5 | Das ist sehr viel, denn in den letzten 29 Jahren schaffte man nur 25 Prozent.                  | Das hat ist sehr viel, denn in den letzten 29 Jahren man nur 25 Prozent geschaffen.            | ['normalize_verb_tense']   |\n"
     ]
    }
   ],
   "source": [
    "print(df_cleanup.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f64756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>final_simplification</th>\n",
       "      <th>applied_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>Der Iran wird teilweise aus dem Atom-Abkommen ...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsident...</td>\n",
       "      <td>Brüssel Ursula von der Leyen ist die Präsi·Den...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Am Mittwoch hat sie ihre erste Rede zur Lage d...</td>\n",
       "      <td>Am Mittwoch hat sie ihre 1. Rede zur Lage der ...</td>\n",
       "      <td>[convert_word_to_number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bis zum Jahr 2030 soll es in der Europäische U...</td>\n",
       "      <td>Bis zum Jahr 2030 soll es in der Europäische U...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Das ist sehr viel, denn in den letzten 29 Jahr...</td>\n",
       "      <td>Das hat ist sehr viel, denn in den letzten 29 ...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Die Europäische Union-Kommission will vor alle...</td>\n",
       "      <td>Die Europäische Union-Kommission will vor alle...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Dazu gehören zum Beispiel die Renovierung von ...</td>\n",
       "      <td>Dazu gehören zum Beispiel die Renovierung von ...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Sie schlägt zum Beispiel Europäische Union-Ges...</td>\n",
       "      <td>Sie schlägt zum Beispiel Europäische Union·Ges...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>Die Maßnahmen gegen den Corona-Virus sind sehr...</td>\n",
       "      <td>Die Maßnahmen gegen den Corona·Virus sind sehr...</td>\n",
       "      <td>[split_compound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>Vor allem in Europa und in den USA schrumpft d...</td>\n",
       "      <td>man angenommen hat. Dann Vor allem in Europa u...</td>\n",
       "      <td>[simplify_subordinate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>Und in China wird die Wirtschaft heuer sogar w...</td>\n",
       "      <td>Und in China wird die Wirtschaft heuer sogar w...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>Erklärung: OECD.</td>\n",
       "      <td>Erklärung: OECD.</td>\n",
       "      <td>[clean_punctuation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>Bei der OECD sind zum Beispiel Österreich, Deu...</td>\n",
       "      <td>Bei der OECD sind zum Beispiel Österreich, Deu...</td>\n",
       "      <td>[rewrite_apposition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>In einem Hafen in Italien gab es einen großen ...</td>\n",
       "      <td>hat In einem Hafen in Italien es einen großen ...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>Zeugen berichteten von Explosionen.</td>\n",
       "      <td>Zeugen hat von Explosionen berichtet.</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26</td>\n",
       "      <td>Verletzt wurde niemand.</td>\n",
       "      <td>Man hat niemand Verletzt.</td>\n",
       "      <td>[convert_passive_to_active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>Die Flammen zerstörten Lager-Hallen.</td>\n",
       "      <td>Die Flammen hat Lager-Hallen zerstört.</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29</td>\n",
       "      <td>Auch Fahrzeuge wurden zerstört.</td>\n",
       "      <td>Man hat Auch Fahrzeuge zerstört.</td>\n",
       "      <td>[convert_passive_to_active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>Durch den Brand entstand eine große schwarze R...</td>\n",
       "      <td>eine große schwarze Rauch-Wolke ist Durch den ...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31</td>\n",
       "      <td>Die Wolke verbreitete sich über die ganze Stadt.</td>\n",
       "      <td>Die Wolke hat sich über die ganze Stadt verbre...</td>\n",
       "      <td>[normalize_verb_tense]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid                                  original_sentence  \\\n",
       "0     1  Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1     2  Brüssel Ursula von der Leyen ist die Präsident...   \n",
       "2     3  Am Mittwoch hat sie ihre erste Rede zur Lage d...   \n",
       "3     4  Bis zum Jahr 2030 soll es in der Europäische U...   \n",
       "4     5  Das ist sehr viel, denn in den letzten 29 Jahr...   \n",
       "5     7  Die Europäische Union-Kommission will vor alle...   \n",
       "6     8  Dazu gehören zum Beispiel die Renovierung von ...   \n",
       "7    10  Sie schlägt zum Beispiel Europäische Union-Ges...   \n",
       "8    15  Die Maßnahmen gegen den Corona-Virus sind sehr...   \n",
       "9    17  Vor allem in Europa und in den USA schrumpft d...   \n",
       "10   18  Und in China wird die Wirtschaft heuer sogar w...   \n",
       "11   19                                   Erklärung: OECD.   \n",
       "12   22  Bei der OECD sind zum Beispiel Österreich, Deu...   \n",
       "13   23  In einem Hafen in Italien gab es einen großen ...   \n",
       "14   25                Zeugen berichteten von Explosionen.   \n",
       "15   26                            Verletzt wurde niemand.   \n",
       "16   28               Die Flammen zerstörten Lager-Hallen.   \n",
       "17   29                    Auch Fahrzeuge wurden zerstört.   \n",
       "18   30  Durch den Brand entstand eine große schwarze R...   \n",
       "19   31   Die Wolke verbreitete sich über die ganze Stadt.   \n",
       "\n",
       "                                 final_simplification  \\\n",
       "0   Der Iran wird teilweise aus dem Atom-Abkommen ...   \n",
       "1   Brüssel Ursula von der Leyen ist die Präsi·Den...   \n",
       "2   Am Mittwoch hat sie ihre 1. Rede zur Lage der ...   \n",
       "3   Bis zum Jahr 2030 soll es in der Europäische U...   \n",
       "4   Das hat ist sehr viel, denn in den letzten 29 ...   \n",
       "5   Die Europäische Union-Kommission will vor alle...   \n",
       "6   Dazu gehören zum Beispiel die Renovierung von ...   \n",
       "7   Sie schlägt zum Beispiel Europäische Union·Ges...   \n",
       "8   Die Maßnahmen gegen den Corona·Virus sind sehr...   \n",
       "9   man angenommen hat. Dann Vor allem in Europa u...   \n",
       "10  Und in China wird die Wirtschaft heuer sogar w...   \n",
       "11                                   Erklärung: OECD.   \n",
       "12  Bei der OECD sind zum Beispiel Österreich, Deu...   \n",
       "13  hat In einem Hafen in Italien es einen großen ...   \n",
       "14              Zeugen hat von Explosionen berichtet.   \n",
       "15                          Man hat niemand Verletzt.   \n",
       "16             Die Flammen hat Lager-Hallen zerstört.   \n",
       "17                   Man hat Auch Fahrzeuge zerstört.   \n",
       "18  eine große schwarze Rauch-Wolke ist Durch den ...   \n",
       "19  Die Wolke hat sich über die ganze Stadt verbre...   \n",
       "\n",
       "                  applied_rules  \n",
       "0        [normalize_verb_tense]  \n",
       "1              [split_compound]  \n",
       "2      [convert_word_to_number]  \n",
       "3        [normalize_verb_tense]  \n",
       "4        [normalize_verb_tense]  \n",
       "5        [normalize_verb_tense]  \n",
       "6              [split_compound]  \n",
       "7              [split_compound]  \n",
       "8              [split_compound]  \n",
       "9        [simplify_subordinate]  \n",
       "10       [normalize_verb_tense]  \n",
       "11          [clean_punctuation]  \n",
       "12         [rewrite_apposition]  \n",
       "13       [normalize_verb_tense]  \n",
       "14       [normalize_verb_tense]  \n",
       "15  [convert_passive_to_active]  \n",
       "16       [normalize_verb_tense]  \n",
       "17  [convert_passive_to_active]  \n",
       "18       [normalize_verb_tense]  \n",
       "19       [normalize_verb_tense]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleanup.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8893cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'master_data/output_assessment/ordered_simplifications_with_rules_clean_FINAL_FINAL.csv'\n",
    "df_cleanup.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "302347d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finally saved the final, ordered file: 'master_data/output_assessment/ordered_simplifications_with_rules_clean_FINAL_FINAL.csv'\n",
      "\n",
      "Here is a preview of the new format:\n",
      "|   uid | original_sentence                                                                              | final_simplification                                                                           | applied_rules              |\n",
      "|------:|:-----------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|:---------------------------|\n",
      "|     1 | Der Iran wird teilweise aus dem Atom-Abkommen aussteigen.                                      | Der Iran wird teilweise aus dem Atom-Abkommen aussteigen.                                      | ['normalize_verb_tense']   |\n",
      "|     2 | Brüssel Ursula von der Leyen ist die Präsidentin von der Europäische Union-Kommission.         | Brüssel Ursula von der Leyen ist die Präsi·Dentin von der Europäische Union-Kommission.        | ['split_compound']         |\n",
      "|     3 | Am Mittwoch hat sie ihre erste Rede zur Lage der Europäische Union gehalten.                   | Am Mittwoch hat sie ihre 1. Rede zur Lage der Europäische Union gehalten.                      | ['convert_word_to_number'] |\n",
      "|     4 | Bis zum Jahr 2030 soll es in der Europäische Union um 55 Prozent weniger Treibhaus-Gase geben. | Bis zum Jahr 2030 soll es in der Europäische Union um 55 Prozent weniger Treibhaus-Gase geben. | ['normalize_verb_tense']   |\n",
      "|     5 | Das ist sehr viel, denn in den letzten 29 Jahren schaffte man nur 25 Prozent.                  | Das hat ist sehr viel, denn in den letzten 29 Jahren man nur 25 Prozent geschaffen.            | ['normalize_verb_tense']   |\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFinally saved the final, ordered file: '{output_filename}'\")\n",
    "print(\"\\nHere is a preview of the new format:\")\n",
    "print(df_cleanup.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f102f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11107 entries, 0 to 11106\n",
      "Data columns (total 4 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   uid                   11107 non-null  int64 \n",
      " 1   original_sentence     11107 non-null  object\n",
      " 2   final_simplification  11107 non-null  object\n",
      " 3   applied_rules         11107 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 347.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleanup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63a688f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11107 entries, 0 to 11106\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   uid                   11107 non-null  int64 \n",
      " 1   original_sentence     11107 non-null  object\n",
      " 2   final_simplification  11107 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 260.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#only keel original_sentence and final_simplification\n",
    "final_pairs = df_cleanup[['uid', 'original_sentence', 'final_simplification']]\n",
    "final_pairs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d10e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pairs.to_csv(\"master_data/output_assessment/final_simplified_pairs_cleaned_FINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056848c8",
   "metadata": {},
   "source": [
    "# Assess the Performance using BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5972e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/im_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from bert_score import score\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Results saved to 'bert_score_results_25sept.csv'.\n"
     ]
    }
   ],
   "source": [
    "#original -> simplified\n",
    "\n",
    "# Load your exported sentence pairs\n",
    "df = pd.read_csv(\"master_data/output_assessment/final_simplified_pairs_cleaned_FINAL.csv\")\n",
    "\n",
    "originals = df[\"original_sentence\"].tolist()\n",
    "simplifieds = df[\"final_simplification\"].tolist()\n",
    "\n",
    "# Compute BERTScore using German-specific model\n",
    "P, R, F1 = score(simplifieds, originals, model_type=\"xlm-roberta-large\", lang=\"de\")\n",
    "\n",
    "# Add scores back to dataframe\n",
    "df[\"bertscore_f1\"] = F1.tolist()\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(\"bert_score_results_25sept.csv\", index=False)\n",
    "print(\"Done! Results saved to 'bert_score_results_25sept.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59001658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average BERTScore-F1 per rule (ranked) ===\n",
      "                     rule    N  mean_f1    std  ci95_lo  ci95_hi\n",
      "convert_passive_to_active 1653   0.9272 0.0292   0.9258   0.9286\n",
      "     simplify_subordinate  273   0.9361 0.0216   0.9335   0.9387\n",
      "           split_compound 4541   0.9623 0.0227   0.9616   0.9629\n",
      "        clean_punctuation  116   0.9678 0.0246   0.9630   0.9722\n",
      "   convert_word_to_number  917   0.9690 0.0295   0.9670   0.9709\n",
      "       rewrite_apposition  214   0.9710 0.0274   0.9673   0.9747\n",
      "     normalize_verb_tense 6409   0.9728 0.0244   0.9722   0.9734\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# 1. Load your files\n",
    "# -------------------------------------------------------\n",
    "# BERTScore results (per sentence)\n",
    "df_scores = pd.read_csv(\"bert_score_results_25sept.csv\")\n",
    "\n",
    "# Rules + sentence pairs\n",
    "df_rules = pd.read_csv(\"master_data/output_assessment/ordered_simplifications_with_rules_clean_FINAL_FINAL.csv\")\n",
    "# -------------------------------------------------------\n",
    "# 2. Merge BERTScore into rules file\n",
    "# -------------------------------------------------------\n",
    "df = df_rules.merge(\n",
    "    df_scores[[\"uid\", \"bertscore_f1\"]],\n",
    "    on=\"uid\", how=\"left\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Helper: compute mean + std + CI\n",
    "# -------------------------------------------------------\n",
    "def mean_ci(x, n_boot=2000, alpha=0.05, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    arr = np.array(x, dtype=float)\n",
    "    boots = [np.mean(rng.choice(arr, size=len(arr), replace=True)) for _ in range(n_boot)]\n",
    "    lo, hi = np.percentile(boots, [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return float(np.mean(arr)), float(np.std(arr)), float(lo), float(hi)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Aggregate scores per rule\n",
    "# -------------------------------------------------------\n",
    "rule_to_scores = defaultdict(list)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if pd.isna(row[\"applied_rules\"]) or pd.isna(row[\"bertscore_f1\"]):\n",
    "        continue\n",
    "\n",
    "    rules = row[\"applied_rules\"]\n",
    "\n",
    "    # Parse applied_rules robustly\n",
    "    if isinstance(rules, str):\n",
    "        try:\n",
    "            rules = json.loads(rules)  # works if JSON (with double quotes)\n",
    "        except Exception:\n",
    "            try:\n",
    "                rules = ast.literal_eval(rules)  # works if Python-style list\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if not isinstance(rules, list):\n",
    "        continue\n",
    "\n",
    "    for rule in rules:\n",
    "        rule_to_scores[rule].append(row[\"bertscore_f1\"])\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. Build results table\n",
    "# -------------------------------------------------------\n",
    "results = []\n",
    "for rule, scores in rule_to_scores.items():\n",
    "    mean_, std_, lo, hi = mean_ci(scores)\n",
    "    results.append({\n",
    "        \"rule\": rule,\n",
    "        \"N\": len(scores),\n",
    "        \"mean_f1\": mean_,\n",
    "        \"std\": std_,\n",
    "        \"ci95_lo\": lo,\n",
    "        \"ci95_hi\": hi\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values(\"mean_f1\")\n",
    "\n",
    "print(\"\\n=== Average BERTScore-F1 per rule (ranked) ===\")\n",
    "print(df_results.to_string(index=False, float_format=\"%.4f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63bbaee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- normalize_verb_tense ---\n",
      "Good examples:\n",
      "  1.000 | Mit der Quarantäne will man verhindern, dass andere Menschen krank werden. -> Mit der Quarantäne will man verhindern, dass andere Menschen krank werden.\n",
      "  1.000 | Die Wahl soll im September sein. -> Die Wahl soll im September sein.\n",
      "Bad examples:\n",
      "  0.850 | Dabei kam heraus: -> ist Dabei heraus, gekommen\n",
      "  0.851 | Am Donnerstag waren es nur noch 360. -> es ist Am Donners·Tag nur noch 360 gewesen\n",
      "\n",
      "--- split_compound ---\n",
      "Good examples:\n",
      "  0.993 | In der Steiermark kann man in Liezen, Bruck an der Mur, Gleisdorf, Judenburg und Graz einen Corona-Test machen. -> In der Steiermark kann man in Liezen, Bruck an der Mur, Gleisdorf, Judenburg und Graz einen Corona·Test machen.\n",
      "  0.994 | Nach dem so genannten Ibiza-Skandal ist der damalige FPÖ-Chef Heinz-Christian Strache als Vize-Kanzler zurück getreten. -> Nach dem so genannten Ibiza-Skandal ist der damalige FPÖ-Chef Heinz-Christian Strache als Vize·Kanzler zurück getreten.\n",
      "Bad examples:\n",
      "  0.825 | Diesen Pass soll man bekommen, wenn man gegen Corona geimpft ist oder wenn man einen Corona-Test gemacht hat. -> Man hat man geimpft.\n",
      "  0.832 | In Europa wird viel zu langsam gegen das Corona-Virus geimpft. -> Man hat geimpft.\n",
      "\n",
      "--- convert_word_to_number ---\n",
      "Good examples:\n",
      "  0.999 | In Österreich gelten seit 15. Juni die neuen Lockerungen bei den Corona-Schutz-Maßnahmen. -> In Österreich gelten seit 15 Juni die neuen Lockerungen bei den Corona-Schutz-Maßnahmen.\n",
      "  0.999 | Mit dieser Partei will Strache zur Wahl in Wien am 11. Oktober antreten. -> Mit dieser Partei will Strache zur Wahl in Wien am 11 Oktober antreten.\n",
      "Bad examples:\n",
      "  0.798 | Es ist der erste Hund in den USA, der sich mit dem Virus angesteckt hat. -> Man hat Es angesteckt.\n",
      "  0.824 | Um 9.00 Uhr wird an der MedUni Wien zum ersten Mal jemand gegen den Virus geimpft. -> Man hat geimpft.\n",
      "\n",
      "--- simplify_subordinate ---\n",
      "Good examples:\n",
      "  0.994 | Zum Beispiel, um Straßen zu reparieren und neue Straßen zu bauen. -> Zum Beispiel um Straßen zu reparieren und neue Straßen zu bauen.\n",
      "  1.000 | Vor allem zum Einkaufen und um zu Hause zu arbeiten. -> Vor allem zum Einkaufen und um zu Hause zu arbeiten.\n",
      "Bad examples:\n",
      "  0.853 | Um das BVT gibt es politischen Streit. -> Dazu.\n",
      "  0.867 | Um das andere Baby kümmert sich Mutter Nora liebevoll. -> Mutter Dazu.\n",
      "\n",
      "--- clean_punctuation ---\n",
      "Good examples:\n",
      "  1.000 | Erklärung: Oppositions-Partei. -> Erklärung: Oppositions-Partei.\n",
      "  1.000 | Erklärung: Nord-Korea. -> Erklärung: Nord-Korea.\n",
      "Bad examples:\n",
      "  0.850 | Dabei kam heraus: -> ist Dabei heraus, gekommen\n",
      "  0.905 | Für alle anderen Menschen gilt: -> Für alle anderen Menschen gilt,\n",
      "\n",
      "--- rewrite_apposition ---\n",
      "Good examples:\n",
      "  1.000 | Wer glaubt, dass er Corona hat, kann bei seinem Arzt so einen Test machen. -> Wer glaubt, dass er Corona hat, kann bei seinem Arzt so einen Test machen.\n",
      "  1.000 | Baron, Handler und Kops wünschen sich, dass Heinz-Christian Strache der Spitzen-Kandidat von der DAÖ wird. -> Baron, Handler und Kops wünschen sich, dass Heinz-Christian Strache der Spitzen-Kandidat von der DAÖ wird.\n",
      "Bad examples:\n",
      "  0.837 | Wenn Mütter gegen den Virus, geimpft sind, kann das auch ihre kleinen Babys vor Corona schützen. -> Man hat Mütter geimpft.\n",
      "  0.900 | Wenn man aber bei der Einreise sagt, dass man Anzeichen für Corona hat, wird man gar nicht hereingelassen. -> Man hat man nicht hereingelassen.\n",
      "\n",
      "--- convert_passive_to_active ---\n",
      "Good examples:\n",
      "  0.984 | Viele Häuser wurden zerstört. -> Man hat Viele Häuser zerstört.\n",
      "  0.986 | Der Mann wurde angezeigt. -> Man hat Der Mann angezeigt.\n",
      "Bad examples:\n",
      "  0.798 | Es ist der erste Hund in den USA, der sich mit dem Virus angesteckt hat. -> Man hat Es angesteckt.\n",
      "  0.815 | Ob sich noch mehr angesteckt haben wird noch untersucht. -> Man hat angesteckt.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# 6. Extract good/bad examples per rule\n",
    "# -------------------------------------------------------\n",
    "examples = defaultdict(lambda: {\"good\": [], \"bad\": []})\n",
    "\n",
    "for rule, scores in rule_to_scores.items():\n",
    "    subset = df[df[\"applied_rules\"].str.contains(rule, na=False)]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "\n",
    "    # Sort by score\n",
    "    subset_sorted = subset.sort_values(\"bertscore_f1\")\n",
    "\n",
    "    # Worst 2\n",
    "    bad = subset_sorted.head(2)[[\"original_sentence\", \"final_simplification\", \"bertscore_f1\"]].to_dict(\"records\")\n",
    "    # Best 2\n",
    "    good = subset_sorted.tail(2)[[\"original_sentence\", \"final_simplification\", \"bertscore_f1\"]].to_dict(\"records\")\n",
    "\n",
    "    examples[rule][\"bad\"] = bad\n",
    "    examples[rule][\"good\"] = good\n",
    "\n",
    "# Example printout\n",
    "for rule, ex in examples.items():\n",
    "    print(f\"\\n--- {rule} ---\")\n",
    "    print(\"Good examples:\")\n",
    "    for e in ex[\"good\"]:\n",
    "        print(f\"  {e['bertscore_f1']:.3f} | {e['original_sentence']} -> {e['final_simplification']}\")\n",
    "    print(\"Bad examples:\")\n",
    "    for e in ex[\"bad\"]:\n",
    "        print(f\"  {e['bertscore_f1']:.3f} | {e['original_sentence']} -> {e['final_simplification']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4773975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e29085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        rule  count\n",
      "0       normalize_verb_tense   6409\n",
      "1             split_compound   4541\n",
      "6  convert_passive_to_active   1653\n",
      "2     convert_word_to_number    917\n",
      "3       simplify_subordinate    273\n",
      "5         rewrite_apposition    214\n",
      "4          clean_punctuation    116\n"
     ]
    }
   ],
   "source": [
    "df_count = pd.read_csv(\"master_data/output_assessment/ordered_simplifications_with_rules_clean_FINAL_FINAL.csv\")\n",
    "\n",
    "# Helper to parse applied_rules into Python list\n",
    "def parse_rules(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return json.loads(x)  # works if JSON with double quotes\n",
    "        except Exception:\n",
    "            try:\n",
    "                return ast.literal_eval(x)  # works if Python-style ['rule1','rule2']\n",
    "            except Exception:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "df_count[\"applied_rules\"] = df_count[\"applied_rules\"].apply(parse_rules)\n",
    "\n",
    "# Flatten all rules into one big list\n",
    "all_rules = [rule for rules in df_count[\"applied_rules\"] for rule in rules]\n",
    "\n",
    "# Count occurrences\n",
    "rule_counts = Counter(all_rules)\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "df_counts = pd.DataFrame(rule_counts.items(), columns=[\"rule\", \"count\"]).sort_values(\"count\", ascending=False)\n",
    "\n",
    "print(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Example calc\n",
    "\n",
    "# # Original vs. Simplified sentences\n",
    "# originals = [\"Der Hund läuft schnell zur Tür.\"]\n",
    "# simplifieds = [\"Der Hund rennt zur Tür.\"]\n",
    "\n",
    "# # Compute BERTScore using a German or multilingual model\n",
    "# P, R, F1 = score(simplifieds, originals, lang=\"de\", model_type=\"bert-base-multilingual-cased\")\n",
    "\n",
    "# print(f\"Precision: {P.mean().item():.4f}\")\n",
    "# print(f\"Recall: {R.mean().item():.4f}\")\n",
    "# print(f\"F1: {F1.mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f2704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "im_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
