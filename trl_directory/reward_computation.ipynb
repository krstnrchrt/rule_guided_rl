{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b828b3",
   "metadata": {},
   "source": [
    "## How to calculate a score for each rule compliance\n",
    "\n",
    "### Given an output sentence, the simplified version, does it still violate the rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c9920",
   "metadata": {},
   "source": [
    "- Reverse every transformation rule into a fast “is this violated?” predicate.\n",
    "\n",
    "- Aggregate predicates with interpretable weights → a single 0-1 compliance score.\n",
    "\n",
    "- Unit-test each predicate and the global scorer before you feed rewards into PPO TRL.\n",
    "\n",
    "- Monitor per-rule violation rates so you know exactly what to fix when the score drops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c1735",
   "metadata": {},
   "source": [
    "#### Step-by step\n",
    "\n",
    "##### Sanity Check\n",
    "\n",
    "1. Create a unit-test set of complex ↔ gold-simplified pairs.\n",
    "\n",
    "2. Compute rewards for:\n",
    "- the gold simplification (should be high),\n",
    "- the original sentence (should be low, especially on rule compliance),\n",
    "- clearly bad outputs (random word order, content dropped – should be low).\n",
    "\n",
    "If these qualitative expectations hold, your scalar function is probably informative enough for RL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b711c41a",
   "metadata": {},
   "source": [
    "### 1. Create a mirror function for every rule that returns \n",
    "- as of now it returns binary variables. later, weights can be assigned and scores can be averaged\n",
    "- 1 = compliant, 0 = not-compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e92d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 15:56:26.447000 18892 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import regex as re\n",
    "\n",
    "from typing import List, Set, Generator, Dict, Any\n",
    "from spacy.tokens import Doc, Token\n",
    "from word2num_de import word_to_number\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from helper import SUBORDINATE_MARKERS, COORD_CONJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9a48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file - german_dict/german_utf8.dic\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "from german_compound_splitter import comp_split\n",
    "\n",
    "utf8_file = os.path.join(\"german_dict\", \"german_utf8.dic\")\n",
    "ahoc = comp_split.read_dictionary_from_file(utf8_file) #activate the compound_spliter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538555a",
   "metadata": {},
   "source": [
    "## Generate Checker functions for compound and converted numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7dd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7ac9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ok_numbers_converted(doc: Doc) -> float:\n",
    "    \"\"\"\n",
    "    A single, self-contained function to check for unconverted numbers.\n",
    "    This has NO external dependencies to ensure the correct logic is always executed.\n",
    "    \"\"\"\n",
    "    # All necessary constants are defined INSIDE this function\n",
    "    NUMBER_DICT = {\n",
    "    # Ordinals\n",
    "    \"erster\": \"1.\", \"zweiter\": \"2.\", \"dritter\": \"3.\", \"vierter\": \"4.\", \"fünfter\": \"5.\", \"sechster\": \"6.\", \"siebter\": \"7.\",\n",
    "    \"achter\": \"8.\", \"neunter\": \"9.\", \"zehnter\": \"10.\", \"elfter\": \"11.\", \"zwölfter\": \"12.\",\n",
    "    # Fractions\n",
    "    \"halb\": \"0.5\", \"eineinhalb\": \"1.5\", \"zweieinhalb\": \"2.5\", \"dreieinhalb\": \"3.5\", \"viereinhalb\": \"4.5\",\n",
    "    \"fünfeinhalb\": \"5.5\", \"sechseinhalb\": \"6.5\", \"siebeneinhalb\": \"7.5\", \"achteinhalb\": \"8.5\", \"neuneinhalb\": \"9.5\", \"zehneinhalb\": \"10.5\",\n",
    "}\n",
    "    RE_NUMERIC = re.compile(r\"^\\d+([.,]\\d+)?$\")\n",
    "    RE_ORDINAL = re.compile(r\"^\\d+\\.$\")\n",
    "\n",
    "    # --- Internal helper to check each token ---\n",
    "\n",
    "    def _is_unconverted_internal(token: Token) -> bool:\n",
    "        \"\"\"Internal helper to check a single token.\"\"\"\n",
    "        # This is the 'like_num' logic, using token attributes correctly\n",
    "        text, lemma = token.text, token.lemma_\n",
    "        text_lower, lemma_lower = text.lower(), lemma.lower()\n",
    "        is_like_num = False\n",
    "        if lemma_lower in NUMBER_DICT or text_lower in NUMBER_DICT: is_like_num = True\n",
    "        elif RE_NUMERIC.match(text) or RE_ORDINAL.match(text): is_like_num = True\n",
    "        elif text.isdigit(): is_like_num = True\n",
    "        else:\n",
    "            try:\n",
    "                word_to_number(lemma_lower)\n",
    "                is_like_num = True\n",
    "            except Exception:\n",
    "                try:\n",
    "                    word_to_number(text_lower)\n",
    "                    is_like_num = True\n",
    "                except Exception:\n",
    "                    is_like_num = False\n",
    "        \n",
    "        # 'is_number' logic\n",
    "        is_a_number = False\n",
    "        if token.text.lower() == \"ein\" and token.pos_ != \"NUM\":\n",
    "            is_a_number = False\n",
    "        else:\n",
    "            is_a_number = is_like_num or token.pos_ == \"NUM\"\n",
    "\n",
    "        # 'is_number_word_that_should_be_converted' logic\n",
    "        if not is_a_number:\n",
    "            return False\n",
    "        return not token.text.isdigit()\n",
    "\n",
    "    # --- Main calculation ---\n",
    "    violating_tokens = [token for token in doc if _is_unconverted_internal(token)]\n",
    "    violation_count = len(violating_tokens)\n",
    "    total_tokens = len(doc)\n",
    "    \n",
    "    score = 1.0 # Default score is perfect (1.0)\n",
    "    if total_tokens > 0: # Calculate penalty based on violations\n",
    "        penalty = min(1.0, violation_count / total_tokens) # Normalize the penalty\n",
    "        score = 1.0 - penalty\n",
    "\n",
    "    return score # if I want to return all for tracking/debugging violation_count, total_tokens, violating_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60d3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_unsplit_compound(doc: spacy.tokens.Doc, ahoc: set) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a document contains any unsplit compound nouns\n",
    "    that should be simplified according to the given rules.\n",
    "\n",
    "    This function iterates through each token in a spaCy Doc object and\n",
    "    applies a set of heuristics to determine if it is a compound that\n",
    "    should have been split but wasn't.\n",
    "\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): The spaCy document object to check.\n",
    "        ahoc (set): A lexicon or set of valid German words for checking\n",
    "                    the validity of split parts.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if at least one unsplit compound is found, False otherwise.\n",
    "    \"\"\"\n",
    "    for token in doc:\n",
    "        # Step 1: Preliminary checks on the token based on your logic.\n",
    "        # This combines the logic from your `check_compound_split` and\n",
    "        # `should_split` functions.\n",
    "        if token.pos_ != \"NOUN\" or token.ent_type_ in {\"PER\", \"LOC\", \"ORG\"}:\n",
    "            continue\n",
    "\n",
    "        # Step 2: Attempt to split the compound using your splitter.\n",
    "        parts =  comp_split.dissect(token.text, ahoc)\n",
    "        \n",
    "        # Step 3: Check if the token is a compound that can be split.\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Step 4: Apply your \"Konvens\" rule check.\n",
    "        # This rule suggests that if both the first and last parts of a\n",
    "        # compound are short (<= 4 characters), it's not considered\n",
    "        # \"hard to read\" and shouldn't be flagged as a violation.\n",
    "        if len(parts[0]) <= 4 and len(parts[-1]) <= 4:\n",
    "            continue\n",
    "\n",
    "        # Step 5: Check if the split parts are valid words in the lexicon.\n",
    "        # This ensures we don't try to split non-compounds or proper nouns\n",
    "        # that aren't marked as named entities.\n",
    "        valid_parts_count = sum(p.lower() in ahoc for p in parts)\n",
    "        \n",
    "        # Step 6: If a majority of the parts are valid, it's a compound that\n",
    "        # should have been split. We've found a violation.\n",
    "        if valid_parts_count / len(parts) >= 0.8:\n",
    "            print(f\"Violation detected: Found unsplit compound '{token.text}'\")\n",
    "            return True\n",
    "            \n",
    "    # If the loop completes without finding any violations, the rule is followed.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1589545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_apposition(doc: spacy.tokens.Doc) -> bool: #regex finds likely comma apposition\n",
    "    if any(tok.dep_ == \"app\" for tok in doc):\n",
    "        return True\n",
    "    # Fallback: regex check for ', ... ,'\n",
    "    # Only trigger if pattern matches (not followed by \"die\", \"der\", etc.)\n",
    "    match = re.search(r', (?!die |der |das |und |aber |weil |obwohl )[^,]+,', doc.text)\n",
    "    return bool(match)\n",
    "\n",
    "def has_subordinate_clause(doc: spacy.tokens.Doc) -> bool:\n",
    "    for tok in doc:\n",
    "        if (tok.text.lower() in SUBORDINATE_MARKERS and \n",
    "            (tok.dep_ in \"cp\" or tok.pos_ == \"SCONJ\")):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_coordinate_clause(doc: spacy.tokens.Doc) -> bool:\n",
    "    \"\"\"Check if the document contains a coordinate clause.\"\"\"\n",
    "    return any(tok.dep_ == \"cd\" and tok.text.lower() in COORD_CONJ for tok in doc)\n",
    "\n",
    "def has_disallowed_tense(doc: spacy.tokens.Doc) -> bool:\n",
    "    for tok in doc:\n",
    "        if tok.pos_ in (\"VERB\", \"AUX\"):\n",
    "            tense = tok.morph.get(\"Tense\")\n",
    "            form = tok.morph.get(\"VerbForm\")\n",
    "            mood = tok.morph.get(\"Mood\")\n",
    "            if (\"Pres\" not in tense and \"Part\" not in form) or (\"Sub\" in mood):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_passive(doc: spacy.tokens.Doc) -> bool:\n",
    "    # Werden + participle: Vorgangspassiv (event passive)\n",
    "    has_werden = any(tok.lemma_ == \"werden\" and tok.pos_ == \"AUX\" for tok in doc)\n",
    "    has_participle = any(tok.pos_ == \"VERB\" and \"Part\" in tok.morph.get(\"VerbForm\", []) for tok in doc)\n",
    "    if has_werden and has_participle:\n",
    "        return True\n",
    "    # Sein + participle: Zustandspassiv (state passive), only for transitive verbs!\n",
    "    has_sein = any(tok.lemma_ == \"sein\" and tok.pos_ == \"AUX\" for tok in doc)\n",
    "    if has_sein and has_participle:\n",
    "        # Check: is the main verb transitive (does it take an object)?\n",
    "        if any(tok.dep_ in {\"oa\", \"obj\"} for tok in doc):  # object present\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e088b",
   "metadata": {},
   "source": [
    "# Collect the main functions to compute reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e95e48",
   "metadata": {},
   "source": [
    "### Example Sentence\n",
    "\n",
    "- has_apposition(doc) returns True/False\n",
    "- float(has_apposition(doc)) returns 1.0 (True, violated), 0.0 (False, compliant)\n",
    "- what does the ok counterpart do?\n",
    "  - flips the perspective\n",
    "\n",
    "| original text flag | has_xy -> float | ok_no_xy | meaning |\n",
    "| --- | --- | --- | --- |\n",
    "| apposition present | 1.0 | 0.0 | not okay |\n",
    "| no apposition | 0.0 | 1.0 | okay |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c73dec",
   "metadata": {},
   "source": [
    "| Function | Returns | Meaning |\n",
    "| --- | --- | --- |\n",
    "| float(has_xy(...)) | 1.0 if violation, 0.0 if compliant | \"Badness Score\"|\n",
    "| ok_no_xy | 1.0 if compliant, 0.0 if violation | \"Goodness Score\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a66af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ok_no_apposition(doc)           -> float: return 1.0 - float(has_apposition(doc))\n",
    "def ok_no_subordinate_clause(doc)   -> float: return 1.0 - float(has_subordinate_clause(doc))\n",
    "#def ok_no_coordinate_clause(doc)    -> float: return 1.0 - float(has_coordinate_clause(doc))\n",
    "def ok_active_voice(doc)            -> float: return 1.0 - float(is_passive(doc))\n",
    "def ok_allowed_verb_tense(doc)      -> float: return 1.0 - float(has_disallowed_tense(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a single \"source of truth\" generator function\n",
    "def _find_unsplit_compounds_gen(doc: spacy.tokens.Doc, ahoc: Set[str]) -> Generator[spacy.tokens.Token, None, None]:\n",
    "    \"\"\"\n",
    "    A generator that yields each token that is an unsplit compound violation.\n",
    "    This contains the core, shared logic.\n",
    "    \"\"\"\n",
    "    for token in doc:\n",
    "        # Initial checks: must be a NOUN and not a named entity\n",
    "        if token.pos_ != \"NOUN\" or token.ent_type_ in {\"PER\", \"LOC\", \"ORG\"}:\n",
    "            continue\n",
    "        if not token.text or not token.text.strip() or not any(char.isalpha() for char in token.text): #adding fix\n",
    "            continue\n",
    "\n",
    "        #parts = comp_split.dissect(token.text, ahoc)\n",
    "        parts = [] # Default to an empty list\n",
    "        try:\n",
    "            # --- THIS IS THE KEY ---\n",
    "            # We call the potentially problematic library function inside a try block\n",
    "            parts = comp_split.dissect(token.text, ahoc)\n",
    "        except IndexError:\n",
    "            # If the library crashes with an IndexError, we catch it,\n",
    "            # print a warning, and simply continue to the next token.\n",
    "            # print(f\"Warning: german_compound_splitter failed on token: '{token.text}'. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        if not parts or len(parts) < 2:\n",
    "            continue\n",
    "        if len(parts[0]) <= 4 and len(parts[-1]) <= 4:\n",
    "            continue\n",
    "\n",
    "        valid_parts_count = sum(p.lower() in ahoc for p in parts)\n",
    "        \n",
    "        if valid_parts_count / len(parts) >= 0.8:\n",
    "            yield token # Yield the violating token and continue the loop\n",
    "\n",
    "def count_unsplit_compounds(doc: spacy.tokens.Doc, ahoc: Set[str]) -> int:\n",
    "    \"\"\"Counts ALL unsplit compounds\"\"\"\n",
    "    return sum(1 for _ in _find_unsplit_compounds_gen(doc, ahoc))\n",
    "\n",
    "def find_all_unsplit_compounds(doc: spacy.tokens.Doc, ahoc: Set[str]) -> list[spacy.tokens.Token]:\n",
    "    \"\"\"Gets a list of all violating tokens. Useful for debugging.\"\"\"\n",
    "    return list(_find_unsplit_compounds_gen(doc, ahoc))\n",
    "\n",
    "def ok_no_compounds(doc: spacy.tokens.Doc) -> float:\n",
    "    \"\"\"\n",
    "    Computes a compliance score (0-1) for compound splitting.\n",
    "    \"\"\"\n",
    "    violation_count = count_unsplit_compounds(doc, ahoc)\n",
    "    noun_count = len([token for token in doc if token.pos_ == \"NOUN\"])\n",
    "    \n",
    "    if noun_count == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    penalty = min(1.0, violation_count / noun_count)\n",
    "    return 1.0 - penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8066c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_unconverted_numbers(doc: spacy.tokens.Doc) -> int:\n",
    "#     \"\"\"\n",
    "#     Counts number words that should have been converted but weren't.\n",
    "#     This function is a helper for `ok_numbers_converted`.\n",
    "#     \"\"\"\n",
    "#     violation_count = 0\n",
    "#     for token in doc:\n",
    "#         # Check if the token is a number word that should have been converted\n",
    "#         if is_number_word_that_should_be_converted(token):\n",
    "#             violation_count += 1\n",
    "#     return violation_count\n",
    "\n",
    "# def ok_numbers_converted(doc: spacy.tokens.Doc) -> float:\n",
    "#     \"\"\"\n",
    "#     Computes a compliance score (0-1) for number word conversion.\n",
    "#     \"\"\"\n",
    "#     violation_count = count_unconverted_numbers(doc)\n",
    "#     total_tokens = len(doc)\n",
    "    \n",
    "#     if total_tokens == 0:\n",
    "#         return 1.0\n",
    "    \n",
    "#     # Penalize based on the ratio of unconverted numbers to total tokens.\n",
    "#     penalty = min(1.0, violation_count / total_tokens)\n",
    "#     return 1.0 - penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0713cb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "s1 = nlp(\"Herr Müller, der Projektleiter, kam gestern.\")   # has apposition\n",
    "s2 = nlp(\"Der Projektleiter Herr Müller kam gestern.\")     # no apposition\n",
    "\n",
    "print(ok_no_apposition(s1))   # 0.0  ← rule broken\n",
    "print(ok_no_apposition(s2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc20ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sentence: 'Der Riesenräder und das Riesenrad oder die Riesenräder sind sehr speziell.'\n",
      "Dissect compound:  Riesenrad\n",
      "Violation detected: Found unsplit compound 'Riesenrad'\n",
      "Has unsplit compound violation: True\n",
      "\n",
      "Checking sentence: 'Die Hütte steht in der Sonne.'\n",
      "Dissect compound:  Hütte\n",
      "Dissect compound:  Sonne\n",
      "Has unsplit compound violation: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example sentences to test\n",
    "sentence_with_compound = \"Der Riesenräder und das Riesenrad oder die Riesenräder sind sehr speziell.\"\n",
    "sentence_without_compound = \"Die Hütte steht in der Sonne.\"\n",
    "\n",
    "# Process the sentences with spaCy\n",
    "doc1 = nlp(sentence_with_compound)\n",
    "doc2 = nlp(sentence_without_compound)\n",
    "\n",
    "# Test the function\n",
    "print(f\"Checking sentence: '{sentence_with_compound}'\")\n",
    "has_compound_violation = has_unsplit_compound(doc1, ahoc)\n",
    "print(f\"Has unsplit compound violation: {has_compound_violation}\\n\")\n",
    "\n",
    "print(f\"Checking sentence: '{sentence_without_compound}'\")\n",
    "has_compound_violation = has_unsplit_compound(doc2, ahoc)\n",
    "print(f\"Has unsplit compound violation: {has_compound_violation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f450069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sentence: 'Der Donaudampfschifffahrtskapitänsmützenabzeichen und zweihundert Riesenrad sind sehr speziell.'\n",
      "--------------------\n",
      "Dissect compound:  Donaudampfschifffahrtskapitänsmützenabzeichen\n",
      "Dissect compound:  Riesenrad\n",
      "Compound violation score: 0.00\n",
      "Number violation score: 0.00\n",
      "--------------------\n",
      "\n",
      "Checking sentence: 'Die Hütte steht in der Sonne.'\n",
      "--------------------\n",
      "Dissect compound:  Hütte\n",
      "Dissect compound:  Sonne\n",
      "Compound violation score: 1.00\n",
      "Number violation score: 0.00\n",
      "--------------------\n",
      "\n",
      "Checking sentence: 'Das zweite Haus wurde drei Mal verkauft und kostet hundert Euro.'\n",
      "--------------------\n",
      "Dissect compound:  Haus\n",
      "Dissect compound:  Mal\n",
      "Dissect compound:  Euro\n",
      "Compound violation score: 1.00\n",
      "Number violation score: 0.00\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Example with a sentence from a table\n",
    "sentence1 = \"Der Donaudampfschifffahrtskapitänsmützenabzeichen und zweihundert Riesenrad sind sehr speziell.\"\n",
    "doc1 = nlp(sentence1)\n",
    "\n",
    "# Test the functions\n",
    "print(f\"Checking sentence: '{sentence1}'\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Compound violation score: {ok_no_compounds(doc1):.2f}\")\n",
    "print(f\"Number violation score: {ok_numbers_converted(doc1):.2f}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "sentence2 = \"Die Hütte steht in der Sonne.\"\n",
    "doc2 = nlp(sentence2)\n",
    "\n",
    "print(f\"\\nChecking sentence: '{sentence2}'\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Compound violation score: {ok_no_compounds(doc2):.2f}\")\n",
    "print(f\"Number violation score: {ok_numbers_converted(doc2):.2f}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "sent3 = nlp(\"Das zweite Haus wurde drei Mal verkauft und kostet hundert Euro.\")\n",
    "\n",
    "print(f\"\\nChecking sentence: '{sent3.text}'\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Compound violation score: {ok_no_compounds(sent3):.2f}\")\n",
    "print(f\"Number violation score: {ok_numbers_converted(sent3):.2f}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c831eb4",
   "metadata": {},
   "source": [
    "### 2. Collect them all in a single rule wrapper\n",
    "- adjust the weights to reflect the rule's importance\n",
    "- Normalise everything to [0, 1] before weighting.\n",
    "- Keep the weights in a config file; you will probably retune them a few times.\n",
    "- Evaluate each feature per sentence only if you need finer control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28009e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE_CHECKS = {\n",
    "    \"apposition\"        : ok_no_apposition,\n",
    "    \"subord_clause\"     : ok_no_subordinate_clause,\n",
    "    #\"coord_clause\"      : ok_no_coordinate_clause,\n",
    "    \"voice_active\"      : ok_active_voice,\n",
    "    \"verb_tense\"        : ok_allowed_verb_tense,\n",
    "    \"no_compounds\"      : ok_no_compounds,\n",
    "    \"numbers_converted\" : ok_numbers_converted,\n",
    "}\n",
    "\n",
    "RULE_WEIGHTS = {           # must sum to 1.0\n",
    "    \"apposition\"        : 0.20,\n",
    "    \"subord_clause\"     : 0.10,\n",
    "    #\"coord_clause\"      : 0.10,\n",
    "    \"voice_active\"      : 0.20,\n",
    "    \"verb_tense\"        : 0.15,\n",
    "    \"no_compounds\"      : 0.25,\n",
    "    \"numbers_converted\" : 0.10,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ec0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize weights to ensure they sum to 1.0\n",
    "total_weight = sum(RULE_WEIGHTS.values())\n",
    "if total_weight != 1.0:\n",
    "    for key in RULE_WEIGHTS:\n",
    "        RULE_WEIGHTS[key] /= total_weight\n",
    "    print(\"Warning: RULE_WEIGHTS did not sum to 1.0. They have been normalized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f1b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(total_weight) #should print 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77edd1ac",
   "metadata": {},
   "source": [
    "### 3. Create the scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60cbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_compliance_score(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Computes a weighted 0-1 compliance score for a simplified sentence.\n",
    "    This is the core function for rule-based rewards.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    total_score = 0.0\n",
    "    \n",
    "    # Iterate through each rule and its corresponding checker function\n",
    "    for name, check_func in RULE_CHECKS.items():\n",
    "        # Call the checker function and get the score\n",
    "        score = check_func(doc)\n",
    "        \n",
    "        # Add the weighted score to the total\n",
    "        total_score += RULE_WEIGHTS[name] * score\n",
    "        \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03997b8",
   "metadata": {},
   "source": [
    "### 4. Compute a meaning-preservation score\n",
    "- embedding-level similarity which works cross-lingually without refences\n",
    "- https://sbert.net/docs/sentence_transformer/usage/semantic_textual_similarity.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449d031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util, SimilarityFunction\n",
    "from sentence_transformers.evaluation import SimilarityFunction\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9656aa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SBERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name deepset/gbert-base. Creating a new one with mean pooling.\n",
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model similarity function set to: 'dot'\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading SBERT model...\")\n",
    "# model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "# model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2') #smaller & faster model\n",
    "model = SentenceTransformer('deepset/gbert-base') #-large\n",
    "model.similarity_fn_name = SimilarityFunction.DOT_PRODUCT\n",
    "print(f\"Model similarity function set to: '{model.similarity_fn_name}'\")\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fe4191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_semantic_similarity(original_sentence: str, simplified_sentence: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the meaning preservation score using SBERT embeddings.\n",
    "    Returns a score between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "    # Encode sentences with normalization for faster comparison\n",
    "    emb_original = model.encode(original_sentence, normalize_embeddings=True)\n",
    "    emb_simplified = model.encode(simplified_sentence, normalize_embeddings=True)\n",
    "    \n",
    "    \n",
    "    # 2. Calculate the cosine similarity between the two vectors. This returns a tensor.\n",
    "    #dot product on normalized embeddings is equivalent to cosine similarity but cosine will re-normalize embeddings\n",
    "    #again. dot product is faster and more efficient\n",
    "    similarity_score = model.similarity(emb_original, emb_simplified)\n",
    "    \n",
    "    #convert the final tensor to a float.\n",
    "    return similarity_score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0938ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- EXAMPLE USAGE ---\n",
    "# original = \"Der Ausflug nach Potsdam, der am vergangenen Wochenende stattfand, war ein voller Erfolg.\"\n",
    "\n",
    "# # Test with a good simplification\n",
    "# simplified_good = \"Der Ausflug nach Potsdam am Wochenende war ein Erfolg.\"\n",
    "# score_good = calculate_semantic_similarity(original, simplified_good)\n",
    "# print(f\"\\nOriginal: '{original}'\")\n",
    "# print(f\"Simplified (Good): '{simplified_good}'\")\n",
    "# print(f\"SBERT Meaning Preservation Score: {score_good:.4f}\") # Expect a high score (e.g., > 0.9)\n",
    "\n",
    "# # Test with a simplification that loses nuance\n",
    "# simplified_lossy = \"Der Ausflug war ein Erfolg.\"\n",
    "# score_lossy = calculate_semantic_similarity(original, simplified_lossy)\n",
    "# print(f\"\\nSimplified (Lossy): '{simplified_lossy}'\")\n",
    "# print(f\"SBERT Meaning Preservation Score: {score_lossy:.4f}\") # Expect a lower score\n",
    "\n",
    "# # Test with a simplification that changes the meaning\n",
    "# simplified_bad = \"Der Ausflug nach Potsdam war ein Misserfolg.\"\n",
    "# score_bad = calculate_semantic_similarity(original, simplified_bad)\n",
    "# print(f\"\\nSimplified (Bad): '{simplified_bad}'\")\n",
    "# print(f\"SBERT Meaning Preservation Score: {score_bad:.4f}\") # Expect a much lower score|\n",
    "\n",
    "# simplified_worst = \"der Ausflug war Weihnachtsmann.\"\n",
    "# score_worst = calculate_semantic_similarity(original, simplified_worst)\n",
    "# print(f\"\\nSimplified (Worst): '{simplified_worst}'\")\n",
    "# print(f\"SBERT Meaning Preservation Score: {score_worst:.4f}\") # Expect the worst score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5bb57f",
   "metadata": {},
   "source": [
    "# Compute Grammar Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efd7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8c83cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46b411ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grammar_score(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Computes a grammatical compliance score (0-1) for a sentence.\n",
    "    A score of 1.0 means no errors were found.\n",
    "    \"\"\"\n",
    "    error_count = 0\n",
    "    \n",
    "    if not text.strip():\n",
    "        return 1.0 # Return perfect score for empty strings\n",
    "    \n",
    "    # Check the text for errors\n",
    "    matches = tool.check(text)\n",
    "\n",
    "    grammar_errors = [match for match in matches if match.category == 'GRAMMAR']\n",
    "\n",
    "\n",
    "    if matches:\n",
    "        #print(f\"Found {len(grammar_errors)} grammar errors\")\n",
    "        error_count = len(grammar_errors) #track number of errors\n",
    "        #for match in matches:\n",
    "        #    print(f\"Error: {match.message}\")\n",
    "    \n",
    "    # Get a base for normalization, by counting number of tokens\n",
    "    token_count = len(text.split())\n",
    "    \n",
    "    if token_count == 0:\n",
    "        return 1.0\n",
    "        \n",
    "    # Calculate the penalty. We use a simple normalization. Capped at 1. Make sure to be less harsh on short sentences\n",
    "    #penalty = min(1.0, error_count / token_count) ## linear penalty\n",
    "    penalty = error_count / (error_count + token_count) #softer penalty, as errors increase, penalty -> 1.0 asymptotically\n",
    "    \n",
    "    # Return the compliance score\n",
    "    return 1.0 - penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c3161",
   "metadata": {},
   "source": [
    "### Testing Fucntions of grammar calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "467c863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar score (good): 1.00\n",
      "Grammar score (bad): 0.89\n"
     ]
    }
   ],
   "source": [
    "text = \"Man sollte das vermeiden..\"\n",
    "text_bad = \"Dieser Satz sind falsch. Man sollte das vermeiden.\"\n",
    "\n",
    "print(f\"Grammar score (good): {calculate_grammar_score(text):.2f}\")       # Expect 1.0\n",
    "print(f\"Grammar score (bad): {calculate_grammar_score(text_bad):.2f}\")  # Expect < 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f7a7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Diese Sätze sind gut nicht schreiben.'\n",
      "Grammar score: 1.00\n",
      "\n",
      "Sentence: 'Dieser Satz sind gut nicht schreiben.'\n",
      "Grammar score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# This sentence has multiple errors, but the tool will likely only report the first one it finds.\n",
    "text_bad_1 = \"Diese Sätze sind gut nicht schreiben.\" \n",
    "# After fixing the first error, the tool will now find the second one.\n",
    "text_bad_2 = \"Dieser Satz sind gut nicht schreiben.\"\n",
    "\n",
    "print(f\"Sentence: '{text_bad_1}'\")\n",
    "score1 = calculate_grammar_score(text_bad_1)\n",
    "print(f\"Grammar score: {score1:.2f}\")  # Expects a penalty for 1 error: 1 - (1 / (1 + 6)) = 0.86\n",
    "\n",
    "print(f\"\\nSentence: '{text_bad_2}'\")\n",
    "score2 = calculate_grammar_score(text_bad_2)\n",
    "print(f\"Grammar score: {score2:.2f}\")  # Expects a penalty for 1 different error: 1 - (1 / (1 + 6)) = 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f360c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 errors in the sentence: 'Dieser Satz sind falsch. Man sollte das vermeiden.'\n",
      "\n",
      "--- Error 1 ---\n",
      "Message: Bitte prüfen, ob hier „ist“ stehen sollte.\n",
      "Category: GRAMMAR\n",
      "Rule ID: DE_SUBJECT_VERB_AGREEMENT\n",
      "Context: 'Dieser Satz sind falsch. Man sollte das vermeiden.'\n",
      "Suggested replacements: ['ist']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##testing\n",
    "\n",
    "matches = tool.check(text_bad)\n",
    "\n",
    "print(f\"Found {len(matches)} errors in the sentence: '{text_bad}'\\n\")\n",
    "\n",
    "# Let's print each error individually to see them clearly\n",
    "for i, match in enumerate(matches):\n",
    "    print(f\"--- Error {i+1} ---\")\n",
    "    print(f\"Message: {match.message}\")\n",
    "    print(f\"Category: {match.category}\")\n",
    "    print(f\"Rule ID: {match.ruleId}\")\n",
    "    print(f\"Context: '{match.context}'\")\n",
    "    print(f\"Suggested replacements: {match.replacements}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95190b",
   "metadata": {},
   "source": [
    "### 4. Plug into the global reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da4d95",
   "metadata": {},
   "source": [
    "Fix a few candidate distributions (that sum to 1.0). For example:\n",
    "\n",
    "Baseline (0.5, 0.3, 0.2)\n",
    "\n",
    "Rules-heavy (0.6, 0.2, 0.2)\n",
    "\n",
    "Meaning-heavy (0.3, 0.6, 0.1)\n",
    "\n",
    "Grammar-sensitive (0.4, 0.2, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b003e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = [\n",
    "#     {\"rules_score\": 0.5, \"meaning_score\": 0.3, \"grammar_score\": 0.2},\n",
    "#     {\"rules_score\": 0.6, \"meaning_score\": 0.2, \"grammar_score\": 0.2},\n",
    "#     {\"rules_score\": 0.3, \"meaning_score\": 0.6, \"grammar_score\": 0.1},\n",
    "#     {\"rules_score\": 0.4, \"meaning_score\": 0.2, \"grammar_score\": 0.4},\n",
    "# ]\n",
    "\n",
    "# weights = {\n",
    "#     \"rules_score\":   0.5,\n",
    "#     \"meaning_score\": 0.3,\n",
    "#     \"grammar_score\": 0.2,\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(src: str, simpl: str, weights: dict) -> float:\n",
    "    \"\"\"\n",
    "    Combines the rule compliance, meaning preservation and grammar scores into one.\n",
    "    \n",
    "    Args:\n",
    "        src (str): The original, complex sentence.\n",
    "        simpl (str): The simplified output sentence.\n",
    "    \n",
    "    Returns:\n",
    "        float: The final reward score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure weights sum is very close avoiding floating point issues\n",
    "    if abs(sum(weights.values()) - 1.0) > 1e-9:\n",
    "        # I've also added a more helpful error message\n",
    "        raise ValueError(f\"Reward weights must sum to 1.0, but they sum to {sum(weights.values())}\")\n",
    "    \n",
    "    \n",
    "    r_rules   = rule_compliance_score(simpl)\n",
    "    r_meaning = calculate_semantic_similarity(src, simpl)\n",
    "    r_grammar = calculate_grammar_score(simpl)\n",
    "\n",
    "    reward = (weights[\"rules_score\"]   * r_rules +\n",
    "              weights[\"meaning_score\"] * r_meaning +\n",
    "              weights[\"grammar_score\"] * r_grammar)\n",
    "    \n",
    "    return reward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2ec51",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac61c49",
   "metadata": {},
   "source": [
    "Add a gold simplification set and check that those examples always score >= 0.9 while the originals score <= 0.5. That sanity check tells you whether any rule weight is mistuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sanity Check 2: Bad Simplification ---\n",
      "Original:   'Der zweite Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den ersten Alliierten gewonnen.'\n",
      "Simplified: 'Weihnachtsmann. Der 2te Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den ersten Alliierten gewonnen.'\n",
      "Dissect compound:  Weltkrieg\n",
      "Dissect compound:  Alliierten\n",
      "\n",
      "Rule Compliance Score: 0.56\n",
      "Dissect compound:  Weltkrieg\n",
      "Dissect compound:  Alliierten\n",
      "Final Reward Score:    0.77\n",
      "------------------------------\n",
      "--- Offline Diagnostics Example ---\n",
      "Dissect compound:  Weltkrieg\n",
      "Dissect compound:  Alliierten\n",
      "Rule: apposition           | Violations: 0.00 (0=good, 1=bad)\n",
      "Rule: subord_clause        | Violations: 0.00 (0=good, 1=bad)\n",
      "Rule: voice_active         | Violations: 1.00 (0=good, 1=bad)\n",
      "Rule: verb_tense           | Violations: 1.00 (0=good, 1=bad)\n",
      "Rule: no_compounds         | Violations: 0.00 (0=good, 1=bad)\n",
      "Rule: numbers_converted    | Violations: 0.91 (0=good, 1=bad)\n"
     ]
    }
   ],
   "source": [
    "# # --- Example 2: A bad, non-compliant sentence ---\n",
    "# src_sentence_2 = \"Der zweite Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den ersten Alliierten gewonnen.\"\n",
    "# bad_simplified_sentence = \"Weihnachtsmann. Der 2te Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den ersten Alliierten gewonnen.\"\n",
    "    \n",
    "# print(\"--- Sanity Check 2: Bad Simplification ---\")\n",
    "# print(f\"Original:   '{src_sentence_2}'\")\n",
    "# print(f\"Simplified: '{bad_simplified_sentence}'\")\n",
    "    \n",
    "#     # This should show a low compliance score due to unconverted numbers\n",
    "# compliance_score_2 = rule_compliance_score(bad_simplified_sentence)\n",
    "# print(f\"\\nRule Compliance Score: {compliance_score_2:.2f}\")\n",
    "    \n",
    "# reward_2 = compute_reward(src_sentence_2, bad_simplified_sentence, weights)\n",
    "# print(f\"Final Reward Score:    {reward_2:.2f}\")\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "#     # --- Example 3: Offline Diagnostics ---\n",
    "# print(\"--- Offline Diagnostics Example ---\")\n",
    "# simplified_doc = nlp(bad_simplified_sentence)\n",
    "    \n",
    "# violations_by_rule: Dict[str, Any] = {}\n",
    "# for name, check_func in RULE_CHECKS.items():\n",
    "#     score = check_func(simplified_doc)\n",
    "#     violations_by_rule[name] = 1.0 - score\n",
    "\n",
    "# for name, violation in violations_by_rule.items():\n",
    "#     print(f\"Rule: {name:<20} | Violations: {violation:.2f} (0=good, 1=bad)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8749d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sanity Check 2: Bad Simplification ---\n",
      "Original:   'Der zweite Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den ersten Alliierten gewonnen.'\n",
      "Simplified: 'Der 2te Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den erster Alliierten gewonnen.'\n",
      "Dissect compound:  Weltkrieg\n",
      "Dissect compound:  Alliierten\n",
      "\n",
      "Rule Compliance Score: 0.56\n",
      "Dissect compound:  Weltkrieg\n",
      "Dissect compound:  Alliierten\n",
      "Final Reward Score:    0.76\n",
      "------------------------------\n",
      "--- Offline Diagnostics Example ---\n",
      "Dissect compound:  Weltkrieg\n",
      "Dissect compound:  Alliierten\n",
      "Rule: apposition           | Violations: 0.00 (0=good, 1=bad)\n",
      "Rule: subord_clause        | Violations: 0.00 (0=good, 1=bad)\n",
      "Rule: voice_active         | Violations: 1.00 (0=good, 1=bad)\n",
      "Rule: verb_tense           | Violations: 1.00 (0=good, 1=bad)\n",
      "Rule: no_compounds         | Violations: 0.00 (0=good, 1=bad)\n",
      "Rule: numbers_converted    | Violations: 0.90 (0=good, 1=bad)\n"
     ]
    }
   ],
   "source": [
    "# # --- Example 2: A bad, non-compliant sentence ---\n",
    "# src_sentence_2 = \"Der zweite Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den ersten Alliierten gewonnen.\"\n",
    "# bad_simplified_sentence = \"Der 2te Weltkrieg, der in Europa von 1939 bis 1945 dauerte, wurde von den erster Alliierten gewonnen.\"\n",
    "    \n",
    "# print(\"--- Sanity Check 2: Bad Simplification ---\")\n",
    "# print(f\"Original:   '{src_sentence_2}'\")\n",
    "# print(f\"Simplified: '{bad_simplified_sentence}'\")\n",
    "    \n",
    "#     # This should show a low compliance score due to unconverted numbers\n",
    "# compliance_score_2 = rule_compliance_score(bad_simplified_sentence)\n",
    "# print(f\"\\nRule Compliance Score: {compliance_score_2:.2f}\")\n",
    "    \n",
    "# reward_2 = compute_reward(src_sentence_2, bad_simplified_sentence, weights)\n",
    "# print(f\"Final Reward Score:    {reward_2:.2f}\")\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "#     # --- Example 3: Offline Diagnostics ---\n",
    "# print(\"--- Offline Diagnostics Example ---\")\n",
    "# simplified_doc = nlp(bad_simplified_sentence)\n",
    "    \n",
    "# violations_by_rule: Dict[str, Any] = {}\n",
    "# for name, check_func in RULE_CHECKS.items():\n",
    "#     score = check_func(simplified_doc)\n",
    "#     violations_by_rule[name] = 1.0 - score\n",
    "\n",
    "# for name, violation in violations_by_rule.items():\n",
    "#     print(f\"Rule: {name:<20} | Violations: {violation:.2f} (0=good, 1=bad)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rule Check: 'numbers_converted' ---\n",
      "Text: 'Ein kurzer Bericht von meinem Ausflug in Potsdam heute, am 16. August 2025.\n",
      "Am ersten Tag war das Wetter super. Wir nahmen die zweite Straßenbahn und die Fahrt dauerte nur eine halbe Stunde.\n",
      "Es waren zwanzig Leute an Bord und ein Ticket kostete fünf Euro. Für den Eintritt zum dritten Turm zahlten wir 12,50 Euro.\n",
      "Ich sah nur ein Fahrrad, aber es war ein schönes Modell. Der ganze Ausflug war ein voller Erfolg.'\n",
      "--------------------\n",
      "Total tokens in doc: 86\n",
      "Compliance Score: 0.06\n"
     ]
    }
   ],
   "source": [
    "# # --- Test Execution ---\n",
    "# test_text = \"\"\"\n",
    "# Ein kurzer Bericht von meinem Ausflug in Potsdam heute, am 16. August 2025.\n",
    "# Am ersten Tag war das Wetter super. Wir nahmen die zweite Straßenbahn und die Fahrt dauerte nur eine halbe Stunde.\n",
    "# Es waren zwanzig Leute an Bord und ein Ticket kostete fünf Euro. Für den Eintritt zum dritten Turm zahlten wir 12,50 Euro.\n",
    "# Ich sah nur ein Fahrrad, aber es war ein schönes Modell. Der ganze Ausflug war ein voller Erfolg.\n",
    "# \"\"\"\n",
    "\n",
    "# doc = nlp(test_text)\n",
    "\n",
    "# # Run the specific check\n",
    "# numbers_check_function = RULE_CHECKS[\"numbers_converted\"]\n",
    "# score = numbers_check_function(doc)\n",
    "\n",
    "# # Let's see the details\n",
    "# #violation_count = count_unconverted_numbers(doc)\n",
    "# total_tokens = len(doc)\n",
    "\n",
    "# print(f\"--- Rule Check: 'numbers_converted' ---\")\n",
    "# print(f\"Text: '{test_text.strip()}'\")\n",
    "# print(\"-\" * 20)\n",
    "# print(f\"Total tokens in doc: {total_tokens}\")\n",
    "# #print(f\"Unconverted number words found: {violation_count}\")\n",
    "# print(f\"Compliance Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacdee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
