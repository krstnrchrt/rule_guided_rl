{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19f24fc",
   "metadata": {},
   "source": [
    "1. Load 'toy' policy model\n",
    "2. define a dummy reward function (e.g. reward = length of putput or preseence of a keyword)\n",
    "3. run one PPO iteration\n",
    "\n",
    "Once that is done, bring in Ollama / Groq into the picture\n",
    "- After the training is done and you want to apply a lightweight inference deployment\n",
    "    - export fine-tuned weights as a hugging face repo\n",
    "    - convert them to ggml format for llama.cpp or ollama\n",
    "    - spin up an OpenWebUI or Groq isntance to serve them with low latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c76b85",
   "metadata": {},
   "source": [
    "Created a conda env with python 3.10. \n",
    "- Then:\n",
    "    - pip install torch transformers accelerate trl datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aafb016",
   "metadata": {},
   "source": [
    "## Train a reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c59fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 18:39:46.663000 32807 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "from trl import PPOConfig, PPOTrainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed033f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for processing:\n",
    "from transformers import GPT2Tokenizer\n",
    "from trl import AutoModelForCausalLMWithValueHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cb0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7d5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file - german_dict/german_utf8.dic\n",
      "0.0\n",
      "1.0\n",
      "Checking sentence: 'Der Riesenräder und das Riesenrad oder die Riesenräder sind sehr speziell.'\n",
      "Dissect compound:  Riesenrad\n",
      "Violation detected: Found unsplit compound 'Riesenrad'\n",
      "Has unsplit compound violation: True\n",
      "\n",
      "Checking sentence: 'Die Hütte steht in der Sonne.'\n",
      "Dissect compound:  Hütte\n",
      "Dissect compound:  Sonne\n",
      "Has unsplit compound violation: False\n",
      "\n",
      "Checking sentence: 'Der Donaudampfschifffahrtskapitänsmützenabzeichen und zweihundert Riesenrad sind sehr speziell.'\n",
      "--------------------\n",
      "Dissect compound:  Donaudampfschifffahrtskapitänsmützenabzeichen\n",
      "Dissect compound:  Riesenrad\n",
      "Compound violation score: 0.00\n",
      "Number violation score: 0.00\n",
      "--------------------\n",
      "\n",
      "Checking sentence: 'Die Hütte steht in der Sonne.'\n",
      "--------------------\n",
      "Dissect compound:  Hütte\n",
      "Dissect compound:  Sonne\n",
      "Compound violation score: 1.00\n",
      "Number violation score: 0.00\n",
      "--------------------\n",
      "\n",
      "Checking sentence: 'Das zweite Haus wurde drei Mal verkauft und kostet hundert Euro.'\n",
      "--------------------\n",
      "Dissect compound:  Haus\n",
      "Dissect compound:  Mal\n",
      "Dissect compound:  Euro\n",
      "Compound violation score: 1.00\n",
      "Number violation score: 0.00\n",
      "--------------------\n",
      "1.0\n",
      "Loading SBERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name deepset/gbert-base. Creating a new one with mean pooling.\n",
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model similarity function set to: 'dot'\n",
      "Model loaded.\n",
      "Grammar score (good): 1.00\n",
      "Grammar score (bad): 0.89\n",
      "Sentence: 'Diese Sätze sind gut nicht schreiben.'\n",
      "Grammar score: 1.00\n",
      "\n",
      "Sentence: 'Dieser Satz sind gut nicht schreiben.'\n",
      "Grammar score: 0.86\n",
      "Found 1 errors in the sentence: 'Dieser Satz sind falsch. Man sollte das vermeiden.'\n",
      "\n",
      "--- Error 1 ---\n",
      "Message: Bitte prüfen, ob hier „ist“ stehen sollte.\n",
      "Category: GRAMMAR\n",
      "Rule ID: DE_SUBJECT_VERB_AGREEMENT\n",
      "Context: 'Dieser Satz sind falsch. Man sollte das vermeiden.'\n",
      "Suggested replacements: ['ist']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.reward_computation import compute_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0ea11",
   "metadata": {},
   "source": [
    "# Start with Training Reward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39de87",
   "metadata": {},
   "source": [
    "# 1) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d155ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the datasest\n",
    "df = pd.read_csv(\"data/ordered_simplifications_with_rules_clean_FINAL.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c18676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfa05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"original_sentence\": \"original\", \"final_simplification\": \"simplified\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af40936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9678b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe537173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc75c8",
   "metadata": {},
   "source": [
    "# Choice for the  RewardModel\n",
    "\n",
    "AutoModelForSequenceClassification\n",
    "    - a family of AutoModel classes by huggingface\n",
    "  - > loads a pretrained encoder and attach a classification head on top\n",
    "That classification head is\n",
    " - for classification: outputs logits over N classes (e.g. positive/negative)\n",
    " - for regression: if I set num_labels=1, it outputs a single scalar\n",
    "\n",
    "### BERT base vs DistilBERT\n",
    "\n",
    "BERT base uncased\n",
    " - higher accuracy\n",
    " - 12 layers, 110M parameters.\n",
    " - High accuracy, but slower and heavier to train/infer.\n",
    "\n",
    "DistilBERT - _Picking This one_\n",
    "- faster PPO training\n",
    "- A distilled (compressed) version of BERT.\n",
    "- ~40% smaller, ~60% faster, only ~3% loss in accuracy.\n",
    "- Often preferred as a reward model because PPO will call it a LOT (every generation gets scored).\n",
    "- Faster inference = cheaper RL training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e906df8",
   "metadata": {},
   "source": [
    "## 2) Define Grid Search + Model and Hyperparameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8609d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure that for each round in hyperparameter search, a new model is initialized from the chosen base model\n",
    "def model_init():\n",
    "    model_name = \"distilbert-base-german-cased\"\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=1, problem_type=\"regression\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True), # typical 1e-5 to 3e-5 WHAT TO ADD\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4), # Kept it small for speed, HOW TO SET??\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2800e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_WEIGHTS = [\n",
    "    {\"name\": \"balanced\", \"weights\": {\"rules_score\": 0.5, \"meaning_score\": 0.3, \"grammar_score\": 0.2}}, #baseline\n",
    "    {\"name\": \"rules_heavy\", \"weights\": {\"rules_score\": 0.7, \"meaning_score\": 0.2, \"grammar_score\": 0.1}},\n",
    "    {\"name\": \"meaning_heavy\", \"weights\": {\"rules_score\": 0.2, \"meaning_score\": 0.7, \"grammar_score\": 0.1}},\n",
    "    {\"name\": \"grammar_focused\", \"weights\": {\"rules_score\": 0.4, \"meaning_score\": 0.2, \"grammar_score\": 0.4}},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23810b39",
   "metadata": {},
   "source": [
    "## 2.5) Load, Split and Tokenize Data ONCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45af1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous versions, keeping for reference\n",
    "\n",
    "# #Define the preprocessing function\n",
    "# # Tokenize the 'text' column (the simplified sentences)\n",
    "# def preprocess_function(examples, tokenizer):\n",
    "#     tokenized = tokenizer(\n",
    "#         examples[\"simplified\"],\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=128,\n",
    "#         #load_from_cache_file=False, ##make sure that the cached files are not used\n",
    "#     )\n",
    "\n",
    "# # Tokenize the 'text' column (the simplified sentences)\n",
    "# def preprocess_function(examples, tokenizer):\n",
    "#     tokenized = tokenizer(\n",
    "#         examples[\"text\"],\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=128,\n",
    "#         load_from_cache_file=False, ##make sure that the cached files are not used\n",
    "#     )\n",
    "#     tokenized[\"labels\"] = [float(x) for x in examples[\"reward\"]] #np.array(examples[\"labels\"], dtype=np.float32)\n",
    "#     return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefine the preprocessing function\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    \"\"\"Tokenizes the 'simplified' text column.\"\"\"\n",
    "    # Important: Tokenization is applied on the 'simplified' column now, which becomes the 'text' for the RM\n",
    "    return tokenizer(examples[\"simplified\"], truncation=True, padding=\"max_length\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load, Split, and Tokenize Data ONCE ---\n",
    "print(\"--- Loading and tokenizing data once ---\")\n",
    "df = pd.read_csv(\"data/ordered_simplifications_with_rules.csv\", index_col=0)\n",
    "df.rename(columns={\"original_sentence\": \"original\", \"final_simplification\": \"simplified\"}, inplace=True)\n",
    "df = df.sample(n=50, random_state=42) #reduce size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial dataset from the full DataFrame\n",
    "full_dataset = Dataset.from_pandas(df)\n",
    "# Split it into train and test sets\n",
    "split_dataset = full_dataset.train_test_split(test_size=0.15, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and apply tokenization on both split sets\n",
    "\n",
    "tokenizer_rm = AutoTokenizer.from_pretrained(\"distilbert-base-german-cased\")\n",
    "\n",
    "# Tokenize the base train and test sets without the labels\n",
    "# We keep the original text columns to calculate rewards later\n",
    "tokenized_train_base = split_dataset[\"train\"].map(\n",
    "    lambda examples: preprocess_function(examples, tokenizer_rm),\n",
    "    batched=True\n",
    ")\n",
    "tokenized_test_base = split_dataset[\"test\"].map(\n",
    "    lambda examples: preprocess_function(examples, tokenizer_rm),\n",
    "    batched=True\n",
    ")\n",
    "print(\"--- Data tokenized successfully. Starting grid search... ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa65a15",
   "metadata": {},
   "source": [
    "### Eval Custom Metrics for regression RM\n",
    "- for the chosen regression RM model MSE loss is chosen\n",
    "- the following metrics are also loggeed\n",
    "  - MSE (Mean Squared Error) → matches your training loss, so you can track consistency.\n",
    "  - MAE (Mean Absolute Error) → more interpretable (average absolute difference).\n",
    "  - R² (Coefficient of Determination) → tells you how well your model explains variance (1 = perfect, 0 = baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44f9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.squeeze()   # shape: (batch,)\n",
    "    labels = labels.squeeze()\n",
    "\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    mae = mean_absolute_error(labels, preds)\n",
    "    r2  = r2_score(labels, preds)\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419b309",
   "metadata": {},
   "source": [
    "## 3) Main Training Loop including Grid Search\n",
    "- with the current setup and 50 rows, it took 19min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and tokenizing data once ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f10385e02042a5a9e5e6f72ae498ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e67a2de3c44a0abba122c84205d943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data tokenized successfully. Starting grid search... ---\n",
      "\n",
      "--- Processing configuration: balanced ---\n",
      "Weights: {'rules_score': 0.5, 'meaning_score': 0.3, 'grammar_score': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92ddeb77ce24e2595a640f39fbc1bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating train rewards:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Zahl\n",
      "Dissect compound:  Person\n",
      "Dissect compound:  Durch·Schnitt\n",
      "Dissect compound:  Lebensmittel\n",
      "Dissect compound:  Tisch\n",
      "Dissect compound:  Masken\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Bauarbeiter\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Feuerwehr\n",
      "Dissect compound:  Wasser\n",
      "Dissect compound:  Kellern\n",
      "Dissect compound:  Frist\n",
      "Dissect compound:  Brexit\n",
      "Dissect compound:  Geschäfte\n",
      "Dissect compound:  Lokale\n",
      "Dissect compound:  Notarzt\n",
      "Dissect compound:  Schuss·Waffen\n",
      "Dissect compound:  Pistolen\n",
      "Dissect compound:  Gewehre\n",
      "Dissect compound:  Polizei\n",
      "Dissect compound:  Bub\n",
      "Dissect compound:  Ziel\n",
      "Dissect compound:  Klima·Volksbegehren\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Ausbau\n",
      "Dissect compound:  Zoo\n",
      "Dissect compound:  Orang·Utan\n",
      "Dissect compound:  Jahre\n",
      "Dissect compound:  Bauern\n",
      "Dissect compound:  Gegend\n",
      "Dissect compound:  Exil\n",
      "Dissect compound:  Viertel\n",
      "Dissect compound:  SPÖ·Mitarbeiter\n",
      "Dissect compound:  Klassen\n",
      "Dissect compound:  Finanz-Minister\n",
      "Dissect compound:  Bundes·Länder\n",
      "Dissect compound:  Tragen\n",
      "Dissect compound:  Schutz-Masken\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Geld\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Sprache\n",
      "Dissect compound:  Bundes·Kanzler\n",
      "Dissect compound:  Feier\n",
      "Dissect compound:  Bundes·Präsident\n",
      "Dissect compound:  Trainer\n",
      "Dissect compound:  Fans\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Hause\n",
      "Dissect compound:  Sanktionen\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Montag\n",
      "Dissect compound:  Stadt\n",
      "Dissect compound:  September\n",
      "Dissect compound:  Kurz·Arbeit\n",
      "Dissect compound:  Arbeit\n",
      "Dissect compound:  Sieg\n",
      "Dissect compound:  Quali·fikation\n",
      "Dissect compound:  Matura\n",
      "Dissect compound:  Finale\n",
      "Dissect compound:  Teams\n",
      "Dissect compound:  Regierung\n",
      "Dissect compound:  Schüler\n",
      "Dissect compound:  Hilfe\n",
      "Dissect compound:  Flug·Linie\n",
      "Dissect compound:  Schießerei\n",
      "Dissect compound:  Synagoge\n",
      "Dissect compound:  Million\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0e1b1ae94b4fbf861d413e970fa2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating test rewards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Strom\n",
      "Dissect compound:  Lieder\n",
      "Dissect compound:  Folklore\n",
      "Dissect compound:  Preis\n",
      "Dissect compound:  Album\n",
      "Dissect compound:  Möglichkeiten\n",
      "Dissect compound:  Dichterin\n",
      "Dissect compound:  Literatur·Nobelpreis\n",
      "Dissect compound:  Zeit\n",
      "Dissect compound:  Auto·Fahrer\n",
      "Dissect compound:  Schnee\n",
      "Dissect compound:  Matsch\n",
      "Dissect compound:  Eis\n",
      "Dissect compound:  Autos\n",
      "Dissect compound:  Ausbruch\n",
      "Dissect compound:  Virus\n",
      "Dissect compound:  Corona-Pandemie\n",
      "Dissect compound:  Lebens·Erwartung\n",
      "Dissect compound:  Mal\n",
      "Dissect compound:  Zeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-09-14 18:40:18,552] A new study created in memory with name: no-name-c0eb53af-9105-4877-939d-c7462f609c19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running hyperparameter search for balanced ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8169a833f8047e1890fbe2cff5b36e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d00a168d824b6b9f155e39c9d2c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39793527126312256, 'eval_mse': 0.39793527126312256, 'eval_mae': 0.6295639872550964, 'eval_r2': -504.1300048828125, 'eval_runtime': 0.3581, 'eval_samples_per_second': 22.338, 'eval_steps_per_second': 2.792, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bd653e3b164827a165661451997e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2510538399219513, 'eval_mse': 0.2510538399219513, 'eval_mae': 0.499216765165329, 'eval_r2': -317.6820373535156, 'eval_runtime': 0.8264, 'eval_samples_per_second': 9.681, 'eval_steps_per_second': 1.21, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a72aca6ef7400489994fa5786fa4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17322784662246704, 'eval_mse': 0.17322784662246704, 'eval_mae': 0.4136693775653839, 'eval_r2': -218.89149475097656, 'eval_runtime': 1.2237, 'eval_samples_per_second': 6.537, 'eval_steps_per_second': 0.817, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1f9ed3aab04d2a93c57e9b8ea33edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14334534108638763, 'eval_mse': 0.14334532618522644, 'eval_mae': 0.3756512999534607, 'eval_r2': -180.9593048095703, 'eval_runtime': 2.3401, 'eval_samples_per_second': 3.419, 'eval_steps_per_second': 0.427, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:41:15,193] Trial 0 finished with value: -180.44030818343163 and parameters: {'learning_rate': 2.3113453937889977e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.0837112572386638}. Best is trial 0 with value: -180.44030818343163.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 56.1171, 'train_samples_per_second': 2.994, 'train_steps_per_second': 0.143, 'train_loss': 0.3073101341724396, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2af4aca2274c6381b676c51609607b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e383ce61ca43888adc9a7941ea8f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0850880965590477, 'eval_mse': 0.0850880965590477, 'eval_mae': 0.2886233925819397, 'eval_r2': -107.00889587402344, 'eval_runtime': 0.1766, 'eval_samples_per_second': 45.289, 'eval_steps_per_second': 5.661, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5603fa9b48842b688cd559089f64b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004014439415186644, 'eval_mse': 0.004014439415186644, 'eval_mae': 0.05303340405225754, 'eval_r2': -4.0958380699157715, 'eval_runtime': 0.5444, 'eval_samples_per_second': 14.694, 'eval_steps_per_second': 1.837, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74428737327e45d3a47d1c59525b237a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01033814437687397, 'eval_mse': 0.01033814437687397, 'eval_mae': 0.08971166610717773, 'eval_r2': -12.123005867004395, 'eval_runtime': 0.3507, 'eval_samples_per_second': 22.808, 'eval_steps_per_second': 2.851, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:41:45,216] Trial 1 finished with value: -12.022956056520343 and parameters: {'learning_rate': 4.705555295931991e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.09409394281344818}. Best is trial 0 with value: -180.44030818343163.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 28.8909, 'train_samples_per_second': 4.361, 'train_steps_per_second': 0.312, 'train_loss': 0.15060599644978842, 'epoch': 3.0}\n",
      "Best run for balanced: BestRun(run_id='0', objective=-180.44030818343163, hyperparameters={'learning_rate': 2.3113453937889977e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.0837112572386638}, run_summary=None)\n",
      "--- Training final model for balanced with best hyperparameters ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105cdbd8362340a69f350245c66735b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afef275ebdf644758e69e9a7b9417f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39793533086776733, 'eval_mse': 0.3979353606700897, 'eval_mae': 0.6295640468597412, 'eval_r2': -504.130126953125, 'eval_runtime': 0.3649, 'eval_samples_per_second': 21.924, 'eval_steps_per_second': 2.741, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3db8949dd8d4fc481e4b2c4c15e1117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2510538101196289, 'eval_mse': 0.2510538101196289, 'eval_mae': 0.4992167055606842, 'eval_r2': -317.6820068359375, 'eval_runtime': 0.8819, 'eval_samples_per_second': 9.072, 'eval_steps_per_second': 1.134, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada585113e254128b0fb06c36e3f5735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17322784662246704, 'eval_mse': 0.17322784662246704, 'eval_mae': 0.4136693477630615, 'eval_r2': -218.89149475097656, 'eval_runtime': 3.9559, 'eval_samples_per_second': 2.022, 'eval_steps_per_second': 0.253, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567e6a5515d046f2b0d9f27c45d1fa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14334538578987122, 'eval_mse': 0.14334538578987122, 'eval_mae': 0.37565135955810547, 'eval_r2': -180.95938110351562, 'eval_runtime': 0.5354, 'eval_samples_per_second': 14.943, 'eval_steps_per_second': 1.868, 'epoch': 4.0}\n",
      "{'train_runtime': 45.0878, 'train_samples_per_second': 3.726, 'train_steps_per_second': 0.177, 'train_loss': 0.30731016397476196, 'epoch': 4.0}\n",
      "--- Saved final optimized model to rm_out_balanced_final ---\n",
      "\n",
      "\n",
      "--- Processing configuration: rules_heavy ---\n",
      "Weights: {'rules_score': 0.7, 'meaning_score': 0.2, 'grammar_score': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb742983e7f24c1a9eb707f53c67e0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating train rewards:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Zahl\n",
      "Dissect compound:  Person\n",
      "Dissect compound:  Durch·Schnitt\n",
      "Dissect compound:  Lebensmittel\n",
      "Dissect compound:  Tisch\n",
      "Dissect compound:  Masken\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Bauarbeiter\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Feuerwehr\n",
      "Dissect compound:  Wasser\n",
      "Dissect compound:  Kellern\n",
      "Dissect compound:  Frist\n",
      "Dissect compound:  Brexit\n",
      "Dissect compound:  Geschäfte\n",
      "Dissect compound:  Lokale\n",
      "Dissect compound:  Notarzt\n",
      "Dissect compound:  Schuss·Waffen\n",
      "Dissect compound:  Pistolen\n",
      "Dissect compound:  Gewehre\n",
      "Dissect compound:  Polizei\n",
      "Dissect compound:  Bub\n",
      "Dissect compound:  Ziel\n",
      "Dissect compound:  Klima·Volksbegehren\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Ausbau\n",
      "Dissect compound:  Zoo\n",
      "Dissect compound:  Orang·Utan\n",
      "Dissect compound:  Jahre\n",
      "Dissect compound:  Bauern\n",
      "Dissect compound:  Gegend\n",
      "Dissect compound:  Exil\n",
      "Dissect compound:  Viertel\n",
      "Dissect compound:  SPÖ·Mitarbeiter\n",
      "Dissect compound:  Klassen\n",
      "Dissect compound:  Finanz-Minister\n",
      "Dissect compound:  Bundes·Länder\n",
      "Dissect compound:  Tragen\n",
      "Dissect compound:  Schutz-Masken\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Geld\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Sprache\n",
      "Dissect compound:  Bundes·Kanzler\n",
      "Dissect compound:  Feier\n",
      "Dissect compound:  Bundes·Präsident\n",
      "Dissect compound:  Trainer\n",
      "Dissect compound:  Fans\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Hause\n",
      "Dissect compound:  Sanktionen\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Montag\n",
      "Dissect compound:  Stadt\n",
      "Dissect compound:  September\n",
      "Dissect compound:  Kurz·Arbeit\n",
      "Dissect compound:  Arbeit\n",
      "Dissect compound:  Sieg\n",
      "Dissect compound:  Quali·fikation\n",
      "Dissect compound:  Matura\n",
      "Dissect compound:  Finale\n",
      "Dissect compound:  Teams\n",
      "Dissect compound:  Regierung\n",
      "Dissect compound:  Schüler\n",
      "Dissect compound:  Hilfe\n",
      "Dissect compound:  Flug·Linie\n",
      "Dissect compound:  Schießerei\n",
      "Dissect compound:  Synagoge\n",
      "Dissect compound:  Million\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cefeaf455e4e9988864bdd026573c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating test rewards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Strom\n",
      "Dissect compound:  Lieder\n",
      "Dissect compound:  Folklore\n",
      "Dissect compound:  Preis\n",
      "Dissect compound:  Album\n",
      "Dissect compound:  Möglichkeiten\n",
      "Dissect compound:  Dichterin\n",
      "Dissect compound:  Literatur·Nobelpreis\n",
      "Dissect compound:  Zeit\n",
      "Dissect compound:  Auto·Fahrer\n",
      "Dissect compound:  Schnee\n",
      "Dissect compound:  Matsch\n",
      "Dissect compound:  Eis\n",
      "Dissect compound:  Autos\n",
      "Dissect compound:  Ausbruch\n",
      "Dissect compound:  Virus\n",
      "Dissect compound:  Corona-Pandemie\n",
      "Dissect compound:  Lebens·Erwartung\n",
      "Dissect compound:  Mal\n",
      "Dissect compound:  Zeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-09-14 18:42:47,115] A new study created in memory with name: no-name-a67380fc-d1dd-45cc-8335-39f28e2559a3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running hyperparameter search for rules_heavy ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31e841ea4f74a62a76e2642391c3bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a95518f1d04e638d75f58c1f280141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23542112112045288, 'eval_mse': 0.23542112112045288, 'eval_mae': 0.4822903275489807, 'eval_r2': -134.37728881835938, 'eval_runtime': 0.4293, 'eval_samples_per_second': 18.637, 'eval_steps_per_second': 2.33, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baafc24baa49448397f0e8217dbc31b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08608052879571915, 'eval_mse': 0.08608052879571915, 'eval_mae': 0.28667086362838745, 'eval_r2': -48.5000114440918, 'eval_runtime': 0.4463, 'eval_samples_per_second': 17.927, 'eval_steps_per_second': 2.241, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e279672da6f545048d7f178320b0aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.043034877628088, 'eval_mse': 0.043034877628088, 'eval_mae': 0.19651466608047485, 'eval_r2': -23.74690818786621, 'eval_runtime': 1.8654, 'eval_samples_per_second': 4.289, 'eval_steps_per_second': 0.536, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:43:42,688] Trial 0 finished with value: -23.507358644157648 and parameters: {'learning_rate': 3.9910352452023014e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'weight_decay': 0.06796030512435813}. Best is trial 0 with value: -23.507358644157648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 53.0541, 'train_samples_per_second': 2.375, 'train_steps_per_second': 0.113, 'train_loss': 0.23748638232549033, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3688058892584a65aeefceb74c3852c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129ac57eaa4d4e17aa2e8addb5163478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39701712131500244, 'eval_mse': 0.39701712131500244, 'eval_mae': 0.6283830404281616, 'eval_r2': -227.30194091796875, 'eval_runtime': 0.9167, 'eval_samples_per_second': 8.727, 'eval_steps_per_second': 1.091, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdaf7cd5dea41ab980a6f698b437dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2834542989730835, 'eval_mse': 0.2834542989730835, 'eval_mae': 0.5300941467285156, 'eval_r2': -161.99842834472656, 'eval_runtime': 0.5459, 'eval_samples_per_second': 14.654, 'eval_steps_per_second': 1.832, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfea710891a941559ac20af36294e5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2431916445493698, 'eval_mse': 0.24319162964820862, 'eval_mae': 0.490520179271698, 'eval_r2': -138.8456573486328, 'eval_runtime': 0.5464, 'eval_samples_per_second': 14.64, 'eval_steps_per_second': 1.83, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:44:46,340] Trial 1 finished with value: -138.1119455397129 and parameters: {'learning_rate': 1.442456559412578e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.005419066603899559}. Best is trial 1 with value: -138.1119455397129.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 61.7631, 'train_samples_per_second': 2.04, 'train_steps_per_second': 0.146, 'train_loss': 0.3732747501797146, 'epoch': 3.0}\n",
      "Best run for rules_heavy: BestRun(run_id='1', objective=-138.1119455397129, hyperparameters={'learning_rate': 1.442456559412578e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.005419066603899559}, run_summary=None)\n",
      "--- Training final model for rules_heavy with best hyperparameters ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5a72e8324f42efab114a3cbc946296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082219c5a74247c39e6e37c519bda7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39701712131500244, 'eval_mse': 0.39701709151268005, 'eval_mae': 0.6283829808235168, 'eval_r2': -227.3019256591797, 'eval_runtime': 1.1713, 'eval_samples_per_second': 6.83, 'eval_steps_per_second': 0.854, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a03050d11142bcaa437d95e4a3cad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2834542393684387, 'eval_mse': 0.2834542393684387, 'eval_mae': 0.5300941467285156, 'eval_r2': -161.99839782714844, 'eval_runtime': 0.4726, 'eval_samples_per_second': 16.928, 'eval_steps_per_second': 2.116, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aacd5e05644ef5b086d16bd23cf24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2431916892528534, 'eval_mse': 0.2431916743516922, 'eval_mae': 0.4905202090740204, 'eval_r2': -138.84568786621094, 'eval_runtime': 1.3739, 'eval_samples_per_second': 5.823, 'eval_steps_per_second': 0.728, 'epoch': 3.0}\n",
      "{'train_runtime': 62.6641, 'train_samples_per_second': 2.011, 'train_steps_per_second': 0.144, 'train_loss': 0.3732748031616211, 'epoch': 3.0}\n",
      "--- Saved final optimized model to rm_out_rules_heavy_final ---\n",
      "\n",
      "\n",
      "--- Processing configuration: meaning_heavy ---\n",
      "Weights: {'rules_score': 0.2, 'meaning_score': 0.7, 'grammar_score': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fc6651fa0246e697e477256f64e4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating train rewards:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Zahl\n",
      "Dissect compound:  Person\n",
      "Dissect compound:  Durch·Schnitt\n",
      "Dissect compound:  Lebensmittel\n",
      "Dissect compound:  Tisch\n",
      "Dissect compound:  Masken\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Bauarbeiter\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Feuerwehr\n",
      "Dissect compound:  Wasser\n",
      "Dissect compound:  Kellern\n",
      "Dissect compound:  Frist\n",
      "Dissect compound:  Brexit\n",
      "Dissect compound:  Geschäfte\n",
      "Dissect compound:  Lokale\n",
      "Dissect compound:  Notarzt\n",
      "Dissect compound:  Schuss·Waffen\n",
      "Dissect compound:  Pistolen\n",
      "Dissect compound:  Gewehre\n",
      "Dissect compound:  Polizei\n",
      "Dissect compound:  Bub\n",
      "Dissect compound:  Ziel\n",
      "Dissect compound:  Klima·Volksbegehren\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Ausbau\n",
      "Dissect compound:  Zoo\n",
      "Dissect compound:  Orang·Utan\n",
      "Dissect compound:  Jahre\n",
      "Dissect compound:  Bauern\n",
      "Dissect compound:  Gegend\n",
      "Dissect compound:  Exil\n",
      "Dissect compound:  Viertel\n",
      "Dissect compound:  SPÖ·Mitarbeiter\n",
      "Dissect compound:  Klassen\n",
      "Dissect compound:  Finanz-Minister\n",
      "Dissect compound:  Bundes·Länder\n",
      "Dissect compound:  Tragen\n",
      "Dissect compound:  Schutz-Masken\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Geld\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Sprache\n",
      "Dissect compound:  Bundes·Kanzler\n",
      "Dissect compound:  Feier\n",
      "Dissect compound:  Bundes·Präsident\n",
      "Dissect compound:  Trainer\n",
      "Dissect compound:  Fans\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Hause\n",
      "Dissect compound:  Sanktionen\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Montag\n",
      "Dissect compound:  Stadt\n",
      "Dissect compound:  September\n",
      "Dissect compound:  Kurz·Arbeit\n",
      "Dissect compound:  Arbeit\n",
      "Dissect compound:  Sieg\n",
      "Dissect compound:  Quali·fikation\n",
      "Dissect compound:  Matura\n",
      "Dissect compound:  Finale\n",
      "Dissect compound:  Teams\n",
      "Dissect compound:  Regierung\n",
      "Dissect compound:  Schüler\n",
      "Dissect compound:  Hilfe\n",
      "Dissect compound:  Flug·Linie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Schießerei\n",
      "Dissect compound:  Synagoge\n",
      "Dissect compound:  Million\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c497f451f8a4ccd9b0f96f432d1d5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating test rewards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Strom\n",
      "Dissect compound:  Lieder\n",
      "Dissect compound:  Folklore\n",
      "Dissect compound:  Preis\n",
      "Dissect compound:  Album\n",
      "Dissect compound:  Möglichkeiten\n",
      "Dissect compound:  Dichterin\n",
      "Dissect compound:  Literatur·Nobelpreis\n",
      "Dissect compound:  Zeit\n",
      "Dissect compound:  Auto·Fahrer\n",
      "Dissect compound:  Schnee\n",
      "Dissect compound:  Matsch\n",
      "Dissect compound:  Eis\n",
      "Dissect compound:  Autos\n",
      "Dissect compound:  Ausbruch\n",
      "Dissect compound:  Virus\n",
      "Dissect compound:  Corona-Pandemie\n",
      "Dissect compound:  Lebens·Erwartung\n",
      "Dissect compound:  Mal\n",
      "Dissect compound:  Zeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-09-14 18:51:25,406] A new study created in memory with name: no-name-6d70b450-bb8e-4228-9fbc-d8a59627ff45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running hyperparameter search for meaning_heavy ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8d056c15b741f0938497aab4ef9eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba433ad25854af9ad7010ef33cbb9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5381573438644409, 'eval_mse': 0.5381573438644409, 'eval_mae': 0.732668399810791, 'eval_r2': -981.9249877929688, 'eval_runtime': 0.5128, 'eval_samples_per_second': 15.6, 'eval_steps_per_second': 1.95, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3665ab11563143d59e337b708c709045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4720667600631714, 'eval_mse': 0.4720667600631714, 'eval_mae': 0.686156690120697, 'eval_r2': -861.212890625, 'eval_runtime': 0.7465, 'eval_samples_per_second': 10.716, 'eval_steps_per_second': 1.34, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:52:26,575] Trial 0 finished with value: -860.0546671748161 and parameters: {'learning_rate': 1.5054253165962535e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'weight_decay': 0.09454363237216178}. Best is trial 0 with value: -860.0546671748161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 56.3304, 'train_samples_per_second': 1.491, 'train_steps_per_second': 0.071, 'train_loss': 0.5417770147323608, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a82f0262ed84753b97c8f2e979ab942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283c90e220c64393ac95beb3a19c0492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4675424098968506, 'eval_mse': 0.467542439699173, 'eval_mae': 0.6828292608261108, 'eval_r2': -852.9494018554688, 'eval_runtime': 0.3974, 'eval_samples_per_second': 20.129, 'eval_steps_per_second': 2.516, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a88599a6e345e2a58cb91a13fc2e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34296509623527527, 'eval_mse': 0.3429650664329529, 'eval_mae': 0.5846346616744995, 'eval_r2': -625.413330078125, 'eval_runtime': 1.1776, 'eval_samples_per_second': 6.794, 'eval_steps_per_second': 0.849, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db281aec1ee14fbcba326f733fc4d701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2984173595905304, 'eval_mse': 0.2984173595905304, 'eval_mae': 0.5452090501785278, 'eval_r2': -544.0485229492188, 'eval_runtime': 0.4383, 'eval_samples_per_second': 18.253, 'eval_steps_per_second': 2.282, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:53:35,051] Trial 1 finished with value: -543.2048965394497 and parameters: {'learning_rate': 1.439470108427635e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.09564979132984286}. Best is trial 0 with value: -860.0546671748161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 63.2216, 'train_samples_per_second': 1.993, 'train_steps_per_second': 0.142, 'train_loss': 0.4083252747853597, 'epoch': 3.0}\n",
      "Best run for meaning_heavy: BestRun(run_id='0', objective=-860.0546671748161, hyperparameters={'learning_rate': 1.5054253165962535e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'weight_decay': 0.09454363237216178}, run_summary=None)\n",
      "--- Training final model for meaning_heavy with best hyperparameters ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5067c0806740788575d292b26929f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e381b3cc65455987d18f3ef80ba7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5381574034690857, 'eval_mse': 0.5381574034690857, 'eval_mae': 0.732668399810791, 'eval_r2': -981.925048828125, 'eval_runtime': 0.626, 'eval_samples_per_second': 12.779, 'eval_steps_per_second': 1.597, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543d579d07a24d8ebc388852dc89a2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4720667600631714, 'eval_mse': 0.4720667600631714, 'eval_mae': 0.686156690120697, 'eval_r2': -861.212890625, 'eval_runtime': 1.2449, 'eval_samples_per_second': 6.426, 'eval_steps_per_second': 0.803, 'epoch': 2.0}\n",
      "{'train_runtime': 44.1107, 'train_samples_per_second': 1.904, 'train_steps_per_second': 0.091, 'train_loss': 0.5417770147323608, 'epoch': 2.0}\n",
      "--- Saved final optimized model to rm_out_meaning_heavy_final ---\n",
      "\n",
      "\n",
      "--- Processing configuration: grammar_focused ---\n",
      "Weights: {'rules_score': 0.4, 'meaning_score': 0.2, 'grammar_score': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a427cb851834530a8bf050cfb15edcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating train rewards:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Zahl\n",
      "Dissect compound:  Person\n",
      "Dissect compound:  Durch·Schnitt\n",
      "Dissect compound:  Lebensmittel\n",
      "Dissect compound:  Tisch\n",
      "Dissect compound:  Masken\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Bauarbeiter\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Feuerwehr\n",
      "Dissect compound:  Wasser\n",
      "Dissect compound:  Kellern\n",
      "Dissect compound:  Frist\n",
      "Dissect compound:  Brexit\n",
      "Dissect compound:  Geschäfte\n",
      "Dissect compound:  Lokale\n",
      "Dissect compound:  Notarzt\n",
      "Dissect compound:  Schuss·Waffen\n",
      "Dissect compound:  Pistolen\n",
      "Dissect compound:  Gewehre\n",
      "Dissect compound:  Polizei\n",
      "Dissect compound:  Bub\n",
      "Dissect compound:  Ziel\n",
      "Dissect compound:  Klima·Volksbegehren\n",
      "Dissect compound:  Beispiel\n",
      "Dissect compound:  Ausbau\n",
      "Dissect compound:  Zoo\n",
      "Dissect compound:  Orang·Utan\n",
      "Dissect compound:  Jahre\n",
      "Dissect compound:  Bauern\n",
      "Dissect compound:  Gegend\n",
      "Dissect compound:  Exil\n",
      "Dissect compound:  Viertel\n",
      "Dissect compound:  SPÖ·Mitarbeiter\n",
      "Dissect compound:  Klassen\n",
      "Dissect compound:  Finanz-Minister\n",
      "Dissect compound:  Bundes·Länder\n",
      "Dissect compound:  Tragen\n",
      "Dissect compound:  Schutz-Masken\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Geld\n",
      "Dissect compound:  Land\n",
      "Dissect compound:  Sprache\n",
      "Dissect compound:  Bundes·Kanzler\n",
      "Dissect compound:  Feier\n",
      "Dissect compound:  Bundes·Präsident\n",
      "Dissect compound:  Trainer\n",
      "Dissect compound:  Fans\n",
      "Dissect compound:  Corona·Virus\n",
      "Dissect compound:  Hause\n",
      "Dissect compound:  Sanktionen\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Montag\n",
      "Dissect compound:  Stadt\n",
      "Dissect compound:  September\n",
      "Dissect compound:  Kurz·Arbeit\n",
      "Dissect compound:  Arbeit\n",
      "Dissect compound:  Sieg\n",
      "Dissect compound:  Quali·fikation\n",
      "Dissect compound:  Matura\n",
      "Dissect compound:  Finale\n",
      "Dissect compound:  Teams\n",
      "Dissect compound:  Regierung\n",
      "Dissect compound:  Schüler\n",
      "Dissect compound:  Hilfe\n",
      "Dissect compound:  Flug·Linie\n",
      "Dissect compound:  Schießerei\n",
      "Dissect compound:  Synagoge\n",
      "Dissect compound:  Million\n",
      "Dissect compound:  Menschen\n",
      "Dissect compound:  Corona·Virus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018916f295364154bc682f9176a52d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating test rewards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissect compound:  Strom\n",
      "Dissect compound:  Lieder\n",
      "Dissect compound:  Folklore\n",
      "Dissect compound:  Preis\n",
      "Dissect compound:  Album\n",
      "Dissect compound:  Möglichkeiten\n",
      "Dissect compound:  Dichterin\n",
      "Dissect compound:  Literatur·Nobelpreis\n",
      "Dissect compound:  Zeit\n",
      "Dissect compound:  Auto·Fahrer\n",
      "Dissect compound:  Schnee\n",
      "Dissect compound:  Matsch\n",
      "Dissect compound:  Eis\n",
      "Dissect compound:  Autos\n",
      "Dissect compound:  Ausbruch\n",
      "Dissect compound:  Virus\n",
      "Dissect compound:  Corona-Pandemie\n",
      "Dissect compound:  Lebens·Erwartung\n",
      "Dissect compound:  Mal\n",
      "Dissect compound:  Zeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-09-14 18:54:44,473] A new study created in memory with name: no-name-fc907a5a-f0fa-4f33-902e-078afe069d32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running hyperparameter search for grammar_focused ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649c6918e66c404db9c726075281a861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aee947ec5314ed1b13fa057e243ebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31654101610183716, 'eval_mse': 0.31654101610183716, 'eval_mae': 0.5610895752906799, 'eval_r2': -564.7183837890625, 'eval_runtime': 0.4701, 'eval_samples_per_second': 17.019, 'eval_steps_per_second': 2.127, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9dcddd34eb48cfbe482beade2fc5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1577865034341812, 'eval_mse': 0.1577865034341812, 'eval_mae': 0.3946250379085541, 'eval_r2': -280.99420166015625, 'eval_runtime': 0.9074, 'eval_samples_per_second': 8.817, 'eval_steps_per_second': 1.102, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd4ae06d77c48c1a8bbc47952667f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10440894961357117, 'eval_mse': 0.10440894961357117, 'eval_mae': 0.31951093673706055, 'eval_r2': -185.59844970703125, 'eval_runtime': 0.4273, 'eval_samples_per_second': 18.722, 'eval_steps_per_second': 2.34, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:55:39,517] Trial 0 finished with value: -185.17452982068062 and parameters: {'learning_rate': 3.4225812239941936e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'weight_decay': 0.026386231545732487}. Best is trial 0 with value: -185.17452982068062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 50.5122, 'train_samples_per_second': 2.494, 'train_steps_per_second': 0.119, 'train_loss': 0.3165178894996643, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e47c66969e44b4a2657f29fd37d65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffa808b4e204f7f93ce02e0ca4bf148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4164586067199707, 'eval_mse': 0.4164586067199707, 'eval_mae': 0.6439814567565918, 'eval_r2': -743.2899169921875, 'eval_runtime': 0.3678, 'eval_samples_per_second': 21.748, 'eval_steps_per_second': 2.719, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0e3342162b427bab1bf38853121f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2666419744491577, 'eval_mse': 0.2666419446468353, 'eval_mae': 0.5146216154098511, 'eval_r2': -475.53936767578125, 'eval_runtime': 0.4224, 'eval_samples_per_second': 18.939, 'eval_steps_per_second': 2.367, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dde38398904c459b496229fbd1d340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18672196567058563, 'eval_mse': 0.18672195076942444, 'eval_mae': 0.42981430888175964, 'eval_r2': -332.707275390625, 'eval_runtime': 0.3662, 'eval_samples_per_second': 21.844, 'eval_steps_per_second': 2.73, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6a231ae9564b6bbcbfe8389da9d2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15587641298770905, 'eval_mse': 0.15587639808654785, 'eval_mae': 0.39217400550842285, 'eval_r2': -277.5804748535156, 'eval_runtime': 1.6777, 'eval_samples_per_second': 4.768, 'eval_steps_per_second': 0.596, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 18:57:15,134] Trial 1 finished with value: -277.03242444992065 and parameters: {'learning_rate': 2.291994616609982e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.031242999994574305}. Best is trial 1 with value: -277.03242444992065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 93.4935, 'train_samples_per_second': 1.797, 'train_steps_per_second': 0.086, 'train_loss': 0.33749592304229736, 'epoch': 4.0}\n",
      "Best run for grammar_focused: BestRun(run_id='1', objective=-277.03242444992065, hyperparameters={'learning_rate': 2.291994616609982e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.031242999994574305}, run_summary=None)\n",
      "--- Training final model for grammar_focused with best hyperparameters ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81cfa263ade44e09707510c89a44ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a731fa23e2bb46afa27937cca0d5ef3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4164586067199707, 'eval_mse': 0.4164586067199707, 'eval_mae': 0.6439814567565918, 'eval_r2': -743.2899169921875, 'eval_runtime': 1.1356, 'eval_samples_per_second': 7.045, 'eval_steps_per_second': 0.881, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93824ac1ba7c43398aca211b71db2445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26664191484451294, 'eval_mse': 0.26664191484451294, 'eval_mae': 0.5146216154098511, 'eval_r2': -475.539306640625, 'eval_runtime': 0.5576, 'eval_samples_per_second': 14.348, 'eval_steps_per_second': 1.794, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb26e6030bf942deba95270ce79279e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18672195076942444, 'eval_mse': 0.18672195076942444, 'eval_mae': 0.42981433868408203, 'eval_r2': -332.707275390625, 'eval_runtime': 0.7917, 'eval_samples_per_second': 10.104, 'eval_steps_per_second': 1.263, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristina/anaconda3/envs/trl-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b733de01c9d40aaaf6b51ccb1c2f21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15587642788887024, 'eval_mse': 0.15587642788887024, 'eval_mae': 0.39217400550842285, 'eval_r2': -277.5805358886719, 'eval_runtime': 0.4987, 'eval_samples_per_second': 16.042, 'eval_steps_per_second': 2.005, 'epoch': 4.0}\n",
      "{'train_runtime': 90.1293, 'train_samples_per_second': 1.864, 'train_steps_per_second': 0.089, 'train_loss': 0.33749592304229736, 'epoch': 4.0}\n",
      "--- Saved final optimized model to rm_out_grammar_focused_final ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Grid Search and Training Loop ---\n",
    "for config in CANDIDATE_WEIGHTS:\n",
    "    config_name = config[\"name\"]\n",
    "    weights = config[\"weights\"]\n",
    "    output_dir_base = f\"rm_out_{config_name}\"\n",
    "\n",
    "    print(f\"\\n--- Processing configuration: {config_name} ---\")\n",
    "    print(f\"Weights: {weights}\")\n",
    "\n",
    "    # # --- a. Calculate rewards for this configuration (Fast) ---\n",
    "    train_rewards = [\n",
    "        compute_reward(ex['original'], ex['simplified'], weights) \n",
    "        for ex in tqdm(split_dataset[\"train\"], desc=\"Calculating train rewards\")\n",
    "    ]\n",
    "    test_rewards = [\n",
    "        compute_reward(ex['original'], ex['simplified'], weights) \n",
    "        for ex in tqdm(split_dataset[\"test\"], desc=\"Calculating test rewards\")\n",
    "    ]\n",
    "\n",
    "    # --- b. Add the new rewards as the 'labels' column ---\n",
    "    train_dataset_for_run = tokenized_train_base.add_column(\"labels\", train_rewards)\n",
    "    test_dataset_for_run = tokenized_test_base.add_column(\"labels\", test_rewards)\n",
    "    \n",
    "    # --- c. Set the final format for the Trainer ---\n",
    "    train_dataset_for_run.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    test_dataset_for_run.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    # --- d. Set up Training Arguments ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir_base,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"mse\",\n",
    "        greater_is_better=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset_for_run,\n",
    "        eval_dataset=test_dataset_for_run,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer_rm,\n",
    "    )\n",
    "\n",
    "    # --- e. Run Hyperparameter Search ---\n",
    "    print(f\"--- Running hyperparameter search for {config_name} ---\")\n",
    "    best_run = trainer.hyperparameter_search(\n",
    "        direction=\"minimize\", hp_space=model_hp_space, n_trials=2\n",
    "    )\n",
    "    print(f\"Best run for {config_name}: {best_run}\")\n",
    "\n",
    "    # --- f. Train Final Model with Best Hyperparameters ---\n",
    "    print(f\"--- Training final model for {config_name} with best hyperparameters ---\")\n",
    "    for k, v in best_run.hyperparameters.items():\n",
    "        setattr(trainer.args, k, v)\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    # --- g. Save the Final Model ---\n",
    "    final_output_dir = f\"{output_dir_base}_final\"\n",
    "    trainer.save_model(final_output_dir)\n",
    "    print(f\"--- Saved final optimized model to {final_output_dir} ---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00aec5",
   "metadata": {},
   "source": [
    "# Outdated RM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for config in CANDIDATE_WEIGHTS:\n",
    "#     config_name = config[\"name\"]\n",
    "#     weights = config[\"weights\"]\n",
    "#     output_dir_base = f\"rm_out_{config_name}\"\n",
    "\n",
    "#     print(f\"--- Processing configuration: {config_name} ---\")\n",
    "#     print(f\"Weights: {weights}\")\n",
    "\n",
    "#     # --- 1. Generate Reward Data for this specific configuration ---\n",
    "#     reward_data = []\n",
    "#     for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=f\"Generating rewards for {config_name}\"):\n",
    "#         original = row['original']\n",
    "#         simplified = row['simplified']\n",
    "\n",
    "#         try:\n",
    "#             # Use the new function with the current set of weights\n",
    "#             score = compute_reward(original, simplified, weights)\n",
    "#             reward_data.append({\"text\": simplified, \"reward\": float(score)})\n",
    "#         except Exception as e:\n",
    "#             # print(f\"Row {index} failed for {config_name}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     #Create DataSet and split into train and test\n",
    "#     reward_df = pd.DataFrame(reward_data)\n",
    "#     reward_dataset = Dataset.from_pandas(reward_df).train_test_split(test_size=0.15, seed=42)\n",
    "\n",
    "#     #Load tokenizer and process the dataset\n",
    "#     tokenizer_rm = AutoTokenizer.from_pretrained(\"distilbert-base-german-cased\")\n",
    "#     tokenized_dataset_rm = reward_dataset.map(\n",
    "#         lambda examples: preprocess_function(examples, tokenizer_rm), # Pass tokenizer to the map function\n",
    "#         batched=True, remove_columns=[\"text\"]\n",
    "#     )\n",
    "#     #tokenized_dataset_rm = reward_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"]) #remove text after tokenization\n",
    "    \n",
    "    \n",
    "#     tokenized_dataset_rm.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "#     # --- 2. Set up Training Parameters ---\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=output_dir_base,\n",
    "#         evaluation_strategy=\"epoch\",\n",
    "#         save_strategy=\"epoch\",\n",
    "#         load_best_model_at_end=True,\n",
    "#         metric_for_best_model=\"mse\",\n",
    "#         greater_is_better=False,\n",
    "#         pin_memory=False, ##TRUE if GPU is available\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model_init=model_init, # Use the model_init function\n",
    "#         args=training_args,\n",
    "#         train_dataset=tokenized_dataset_rm[\"train\"],\n",
    "#         eval_dataset=tokenized_dataset_rm[\"test\"],\n",
    "#         compute_metrics=compute_metrics,\n",
    "#         tokenizer=tokenizer_rm,\n",
    "#     )\n",
    "#     # --- 3. Run Hyperparameter Search ---\n",
    "#     print(f\"--- Running hyperparameter search for {config_name} ---\")\n",
    "#     best_run = trainer.hyperparameter_search(\n",
    "#         direction=\"minimize\",\n",
    "#         hp_space=model_hp_space,\n",
    "#         n_trials= 2 #10, # Number of hyperparameter combinations to try\n",
    "#     )\n",
    "#     print(f\"Best run for {config_name}: {best_run}\")\n",
    "\n",
    "#     # --- 4. Train Final Model with Best Hyperparameters ---\n",
    "#     print(f\"--- Training final model for {config_name} with best hyperparameters ---\")\n",
    "#     for k, v in best_run.hyperparameters.items():\n",
    "#         setattr(trainer.args, k, v)\n",
    "    \n",
    "#     trainer.train()\n",
    "\n",
    "#     # --- 5. Save the Final Model ---\n",
    "#     final_output_dir = f\"{output_dir_base}_final\"\n",
    "#     trainer.save_model(final_output_dir)\n",
    "#     print(f\"--- Saved final optimized model to {final_output_dir} ---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0352a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for config in CANDIDATE_WEIGHTS:\n",
    "#     config_name = config[\"name\"]\n",
    "#     weights = config[\"weights\"]\n",
    "#     output_dir_base = f\"rm_out_{config_name}\"\n",
    "\n",
    "#     print(f\"--- Processing configuration: {config_name} ---\")\n",
    "#     print(f\"Weights: {weights}\")\n",
    "\n",
    "#     # --- 1. Generate Reward Data for this specific configuration ---\n",
    "#     print(\"Calculating reward scores...\")\n",
    "#     train_rewards = [\n",
    "#         compute_reward(ex['original'], ex['simplified'], weights) \n",
    "#         for ex in tqdm(split_dataset[\"train\"], desc=\"Train rewards\")\n",
    "#     ]\n",
    "#     test_rewards = [\n",
    "#         compute_reward(ex['original'], ex['simplified'], weights) \n",
    "#         for ex in tqdm(split_dataset[\"test\"], desc=\"Test rewards\")\n",
    "#     ]\n",
    "\n",
    "#     # --- 1.2. Add reward 'labels' to the pre-tokenized datasets ---\n",
    "#     train_dataset_for_run = tokenized_train_base.add_column(\"labels\", train_rewards)\n",
    "#     test_dataset_for_run = tokenized_test_base.add_column(\"labels\", test_rewards)\n",
    "    \n",
    "#     # --- 1.3. Finalize dataset format for the Trainer ---\n",
    "#     train_dataset_for_run.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "#     test_dataset_for_run.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "#     # --- 2. Set up Training Parameters ---\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=output_dir_base,\n",
    "#         evaluation_strategy=\"epoch\",\n",
    "#         save_strategy=\"epoch\",\n",
    "#         load_best_model_at_end=True,\n",
    "#         metric_for_best_model=\"mse\",\n",
    "#         greater_is_better=False,\n",
    "#         pin_memory=False, ##TRUE if GPU is available\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model_init=model_init, # Use the model_init function\n",
    "#         args=training_args,\n",
    "#         train_dataset=train_dataset_for_run,\n",
    "#         eval_dataset=test_dataset_for_run,\n",
    "#         compute_metrics=compute_metrics,\n",
    "#         tokenizer=tokenizer_rm,\n",
    "#     )\n",
    "#     # --- 3. Run Hyperparameter Search ---\n",
    "#     print(f\"--- Running hyperparameter search for {config_name} ---\")\n",
    "#     best_run = trainer.hyperparameter_search(\n",
    "#         direction=\"minimize\",\n",
    "#         hp_space=model_hp_space,\n",
    "#         n_trials= 2 #10, # Number of hyperparameter combinations to try\n",
    "#     )\n",
    "#     print(f\"Best run for {config_name}: {best_run}\")\n",
    "\n",
    "#     # --- 4. Train Final Model with Best Hyperparameters ---\n",
    "#     print(f\"--- Training final model for {config_name} with best hyperparameters ---\")\n",
    "#     for k, v in best_run.hyperparameters.items():\n",
    "#         setattr(trainer.args, k, v)\n",
    "    \n",
    "#     trainer.train()\n",
    "\n",
    "#     # --- 5. Save the Final Model ---\n",
    "#     final_output_dir = f\"{output_dir_base}_final\"\n",
    "#     trainer.save_model(final_output_dir)\n",
    "#     print(f\"--- Saved final optimized model to {final_output_dir} ---\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05277c03",
   "metadata": {},
   "source": [
    "## Compute the Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate reward scores for each example\n",
    "# This will take time, as it runs your full spaCy/SBERT pipeline for each row\n",
    "reward_data = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    original = row['original']\n",
    "    simplified = row['simplified']\n",
    "    \n",
    "    # implement custom reward computation function\n",
    "    try:\n",
    "        score = compute_reward(original, simplified, weights)\n",
    "    except Exception as e:\n",
    "        #print(f\"Row {index} failed with error: {e}\")\n",
    "        #print(f\"Original: {original}\")\n",
    "        #print(f\"Simplified: {simplified}\")\n",
    "        continue  # Assign a default score in case of failure\n",
    "        \n",
    "    \n",
    "    reward_data.append({\n",
    "        \"text\": simplified, # The input for the reward model\n",
    "        \"reward\": float(score)  # The score we want it to predict\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the reward data into a df\n",
    "reward_df = pd.DataFrame(reward_data)\n",
    "\n",
    "# 3. Create a Hugging Face Dataset\n",
    "reward_dataset = Dataset.from_pandas(reward_df)\n",
    "\n",
    "# 4. Split into training and testing sets\n",
    "reward_dataset = reward_dataset.train_test_split(test_size=0.15, seed=42) # 85/90% train, 15/10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # 1. Create a larger figure to give the labels more space\n",
    "# fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "# # 2. Create the bar plot\n",
    "# ax.bar(reward_df['text'], reward_df['labels'], color='skyblue')\n",
    "# ax.set_ylim(0, 1)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# reward_df_sort = reward_df.sort_values('labels')\n",
    "# reward_df_sort_capped = reward_df_sort[:20]  # Take the top 20 rows for better visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ce928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_df_sort = reward_df.sort_values('labels')\n",
    "# reward_df_sort_capped = reward_df_sort[:20]  # Take the top 20 rows for better visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_df_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_df_sort.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8b60d",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dbf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-german-cased\" #bert-base-german-cased\n",
    "tokenizer_rm = AutoTokenizer.from_pretrained(model_name)\n",
    "model_rm = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1, problem_type=\"regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bff40",
   "metadata": {},
   "source": [
    "### Eval Metriics for regression RM\n",
    "- for the chosen regression RM model MSE loss is chosen\n",
    "- the following metrics are also loggeed\n",
    "  - MSE (Mean Squared Error) → matches your training loss, so you can track consistency.\n",
    "  - MAE (Mean Absolute Error) → more interpretable (average absolute difference).\n",
    "  - R² (Coefficient of Determination) → tells you how well your model explains variance (1 = perfect, 0 = baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.squeeze()   # shape: (batch,)\n",
    "    labels = labels.squeeze()\n",
    "\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    mae = mean_absolute_error(labels, preds)\n",
    "    r2  = r2_score(labels, preds)\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b23617",
   "metadata": {},
   "source": [
    "### Dataset formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b163461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'text' column (the simplified sentences)\n",
    "def preprocess_function(examples):\n",
    "    tokenized = tokenizer_rm(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    tokenized[\"labels\"] = [float(x) for x in examples[\"reward\"]] #np.array(examples[\"labels\"], dtype=np.float32)\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset_rm = reward_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"]) #remove text after tokenization\n",
    "tokenized_dataset_rm.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"rm_out\",\n",
    "#     num_train_epochs=3,                     # increase if dataset is small\n",
    "#     per_device_train_batch_size=16,         # 8 if GPU-limited\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     learning_rate=2e-5,                     # tune 1e-5 ↔ 3e-5\n",
    "#     weight_decay=0.01,\n",
    "#     logging_steps=50,                       # not too spammy\n",
    "#     do_eval=True,            # run evaluation during training\n",
    "#     eval_steps=200,                         # less frequent, more meaningful\n",
    "#     metric_for_best_model=\"mse\",            # if you define compute_metrics\n",
    "#     greater_is_better=False,              # because lower MSE is better\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"rm_out\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    #load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mse\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer instantiation\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_rm,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_rm[\"train\"],\n",
    "    eval_dataset=tokenized_dataset_rm[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeeaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the hyperparameter search space\n",
    "# def model_hp_space(trial):\n",
    "#     return {\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "#         \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 5),\n",
    "#         \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
    "#         \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "#     }\n",
    "\n",
    "# # Run hyperparameter search (Optuna by default)\n",
    "# best_run = trainer.hyperparameter_search(\n",
    "#     direction=\"minimize\",   # since we want to minimize mse\n",
    "#     hp_space=model_hp_space,\n",
    "#     n_trials=10,            # how many configs to try\n",
    "# )\n",
    "\n",
    "#RuntimeError: To use hyperparameter search, you need to pass your model through a model_init function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ada53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training process\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb93f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final, trained reward model\n",
    "trainer.save_model(\"model_rm\")\n",
    "tokenizer_rm.save_pretrained(\"model_rm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f887b",
   "metadata": {},
   "source": [
    "### Model_rm has been trained with the whole dataset now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09991c",
   "metadata": {},
   "source": [
    "# Start the PPO process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38d8b9",
   "metadata": {},
   "source": [
    "- if you use AutoModelForCauselLMWithValueHead - it already bundles BOTH the policy and the value head into a single model\n",
    "- you do not need to supply a separate value model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462e904",
   "metadata": {},
   "source": [
    "- I managed to make it work with gpt-2\n",
    "- there might be some adjustments needed, once frhew/sigdial_ft_a2 actually loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from trl import PPOConfig, PPOTrainer, AutoModelForCausalLMWithValueHead\n",
    "import torch.nn.functional as F\n",
    "from transformers import BitsAndBytesConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration and Model Loading ---\n",
    "# load your target model using quantization\n",
    "MODEL_ID = \"frhew/sigdial_ft_a2\" \n",
    "RM_PATH = \"reward_model_ger\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b98c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load Models and Tokenizers with Quantization ---\n",
    "\n",
    "# Define the quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # Use bfloat16 for modern GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Model (the one we're training)\n",
    "# We load it with the quantization config.\n",
    "# device_map=\"auto\" is still useful here to correctly place the quantized model on the GPU.\n",
    "policy_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01579150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. choose your base model\n",
    "# MODEL_ID = \"gpt2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "# policy_model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "# value_model  = AutoModelForCausalLM.from_pretrained(MODEL_ID)   # simple value net\n",
    "\n",
    "# RM_PATH = \"model_rm\"\n",
    "# reward_model = AutoModelForSequenceClassification.from_pretrained(RM_PATH) # or instantiate your RM\n",
    "# tokenizer_rm = AutoTokenizer.from_pretrained(RM_PATH)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1 use policy model and value head - both will be the same\n",
    "\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# MODEL_ID = \"frhew/sigdial_ft_a2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# # Add a padding token if one doesn't exist\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# policy_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "#     MODEL_ID, \n",
    "#     device_map=\"auto\", \n",
    "#     dtype=torch.float16)\n",
    "# #value_model = policy_model  # use the same model for policy and value head, PPOTrainer will handle this automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca080bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model.save_pretrained(\"frhew/sigdial_ft_a2_local\")\n",
    "tokenizer.save_pretrained(\"frhew/sigdial_ft_a2_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"dbmdz/german-gpt2\"\n",
    "RM_PATH = \"model_rm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Configuration\n",
    "config = PPOConfig(\n",
    "    model_name=MODEL_ID,\n",
    "    learning_rate=1.41e-5,\n",
    "    batch_size=8, # Use a slightly larger batch size\n",
    "    mini_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    kl_penalty=\"kl\",\n",
    "    target_kl=0.1,\n",
    "    use_score_scaling=True, #enable reward normalization\n",
    "    score_clip=10.0,\n",
    "    seed=42,\n",
    "    log_with=None, # Set to \"wandb\" if you use it\n",
    ")\n",
    "\n",
    "# # 2. Configure PPO\n",
    "# config = PPOConfig(\n",
    "#     # — PPO-specific\n",
    "#     exp_name                      = \"my_ppo_test\",\n",
    "#     reward_model_path             = \"model_rm\",       # only needed if you want to reload RM via name\n",
    "#     num_ppo_epochs                = 3,\n",
    "#     kl_coef                       = 0.1,\n",
    "#     cliprange                     = 0.2,\n",
    "#     vf_coef                       = 0.1,\n",
    "#     gamma                         = 0.99,\n",
    "#     lam                           = 0.95,\n",
    "#     # — TrainingArguments / OnPolicyConfig\n",
    "#     learning_rate                 = 1e-5,\n",
    "#     per_device_train_batch_size   = 2,\n",
    "#     gradient_accumulation_steps   = 1,\n",
    "#     num_mini_batches              = 1,\n",
    "#     local_rollout_forward_batch_size = 1,\n",
    "#     response_length               = 20,\n",
    "#     temperature                   = 1.0,\n",
    "#     report_to                     = None,            # or \"wandb\"\n",
    "#     fp16                          = False,\n",
    "#     bf16= False,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. policy/ref model - both will be the same\n",
    "\n",
    "policy_model = AutoModelForCausalLMWithValueHead.from_pretrained(MODEL_ID)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(MODEL_ID)\n",
    "\n",
    "\n",
    "policy_tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "policy_tokenizer.pad_token = policy_tokenizer.eos_token\n",
    "policy_tokenizer.padding_side  = \"left\" #GPT-2 a decoder only model expects any pdding tokens on the LEFT of the sequence, by default tokenizers pad on the right\n",
    "# policy_model.save_pretrained(\"gpt2_local\")\n",
    "# tokenizer.save_pretrained(\"gpt2_local\")\n",
    "\n",
    "#load the pretrained reward model & tokenizer\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(RM_PATH)\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(RM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the reward model is in evaluation mode and move to device\n",
    "reward_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reward_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0f8f5",
   "metadata": {},
   "source": [
    "## Prepare Dataset and PPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ordered_simplifications_with_rules.csv\", index_col=0)\n",
    "\n",
    "#Use the original sentence as the prompt/query\n",
    "df.rename(columns={\"original_sentence\": \"query\"}, inplace=True)\n",
    "\n",
    "#Create a train/eval set\n",
    "train_df, eval_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}, Evaluation set size: {len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7aff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, using a small sample\n",
    "train_sample_df = train_df.sample(n=32, random_state=42)\n",
    "\n",
    "# Create the PPO dataset ONLY from the training split\n",
    "dataset = Dataset.from_pandas(train_sample_df)\n",
    "print(\"Created Hugging Face Dataset:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5338c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the correct tokenization function\n",
    "def tokenize_function(examples):\n",
    "    # The tokenizer, when called on a list of strings, returns a dictionary\n",
    "    # with `input_ids` and `attention_mask`. This is the format we need.\n",
    "    # We set the padding and truncation strategy here.\n",
    "    output = policy_tokenizer(examples[\"query\"], truncation=True, padding=\"max_length\", max_length=40)\n",
    "    return output\n",
    "\n",
    "# Step 3: Apply the tokenization using .map()\n",
    "# batched=True makes it much faster\n",
    "tokenized_dataset = dataset.map(tokenize_function, \n",
    "                                batched=True,\n",
    "                                remove_columns=['final_simplification', 'applied_rules', 'uid', 'query']\n",
    "                                )\n",
    "\n",
    "# Important: The PPOTrainer needs the columns in torch format\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "print(\"\\nTokenized Dataset format:\")\n",
    "print(tokenized_dataset)\n",
    "print(tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(\n",
    "    config=config,\n",
    "    model=policy_model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=policy_tokenizer,\n",
    "    dataset=tokenized_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_rewards_from_rm(responses: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes rewards for a list of strings using the trained regression reward model.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Tokenize the responses\n",
    "        enc = reward_tokenizer(\n",
    "            responses,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128 # Match the max_length used during RM training\n",
    "        )\n",
    "        \n",
    "        # Move tensors to the same device as the reward model\n",
    "        inputs = {k: v.to(reward_model.device) for k, v in enc.items()}\n",
    "        \n",
    "        # Get the reward model's output\n",
    "        out = reward_model(**inputs)\n",
    "        \n",
    "        # The output logits are the scalar reward values.\n",
    "        # Squeeze to remove the extra dimension.\n",
    "        rewards = out.logits.squeeze(-1)\n",
    "        \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a76e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. The PPO Training Loop ---\n",
    "\n",
    "# Generation settings for creating responses\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": policy_tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 50, # How long the simplifications should be\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(ppo_trainer.dataloader, \"Training Step\"):\n",
    "    #2D tensor\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #Debug -Convert the 2D batch tensor into a list of 1D tensors for generation\n",
    "    queries_list = [q for q in query_tensors]\n",
    "\n",
    "    # Generate responses from the policy model\n",
    "    response_tensors = ppo_trainer.generate(queries_list, **generation_kwargs)\n",
    "    \n",
    "    # Decode the responses. Your batch_decode is more efficient than a loop.\n",
    "    batch[\"response\"] = policy_tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "    # Compute rewards\n",
    "    rewards_tensor = compute_rewards_from_rm(batch[\"response\"])\n",
    "    rewards_list = [r for r in rewards_tensor]\n",
    "    \n",
    "    # Perform the PPO optimization step\n",
    "    stats = ppo_trainer.step(queries_list, response_tensors, rewards_list)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards_list)\n",
    "\n",
    "print(\"PPO Training Finished!\")\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Saving PPO-tuned model...\")\n",
    "ppo_trainer.save_pretrained(\"my_ppo_tuned_model\")\n",
    "print(\"Model saved to 'my_ppo_tuned_model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluating and Logging Final Model Performance ---\")\n",
    "\n",
    "# Take a small, fresh sample from your original dataframe for evaluation\n",
    "# Using a different random_state ensures we get a different set of prompts\n",
    "\n",
    "eval_df = eval_df.sample(n=8, random_state=49)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# Tokenize the evaluation prompts\n",
    "# Note: We are not using the dataloader here, just tokenizing a small batch\n",
    "eval_prompts = policy_tokenizer(\n",
    "    eval_df[\"query\"].tolist(), # Use the pandas DataFrame here\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "eval_queries_list = [q.to(ppo_trainer.accelerator.device) for q in eval_prompts['input_ids']] # Ensure tensors are on the correct device\n",
    "\n",
    "# Generate responses with the FINAL trained model\n",
    "# We use torch.no_grad() for efficiency as we are not training\n",
    "with torch.no_grad():\n",
    "    eval_response_tensors = ppo_trainer.generate(eval_queries_list, **generation_kwargs)\n",
    "\n",
    "# THE FIX: Isolate the generated tokens before decoding\n",
    "# ==============================================================================\n",
    "generated_tokens = []\n",
    "# Get the original prompts' attention mask to find their true, unpadded lengths\n",
    "prompt_attention_mask = eval_prompts['attention_mask']\n",
    "\n",
    "for i, response_tensor in enumerate(eval_response_tensors):\n",
    "    # Find the actual length of the prompt by summing its attention mask\n",
    "    prompt_len = torch.sum(prompt_attention_mask[i])\n",
    "    \n",
    "    # Slice the individual response tensor to get only the newly generated part\n",
    "    generated_part = response_tensor[prompt_len:]\n",
    "    generated_tokens.append(generated_part)\n",
    "\n",
    "# Decode only the generated part\n",
    "eval_responses = policy_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "# ==============================================================================\n",
    "\n",
    "# Score the final responses with the reward model\n",
    "eval_rewards = compute_rewards_from_rm(eval_responses)\n",
    "\n",
    "# Print the results in a clean format\n",
    "print(\"\\n--- Final Model Generations ---\")\n",
    "for i in range(len(eval_dataset[\"query\"])):\n",
    "    print(f\"Query:    {eval_dataset['query'][i]}\")\n",
    "    print(f\"Response: {eval_responses[i]}\")\n",
    "    print(f\"Reward:   {eval_rewards[i].item():.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e426210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForCausalLM,\n",
    "#     AutoModelForSequenceClassification,\n",
    "# )\n",
    "# from trl import PPOConfig, PPOTrainer\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # 1️⃣  Load your policy & value LMs\n",
    "# MODEL_ID     = \"gpt2\"\n",
    "# tokenizer    = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# policy_model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "# value_model  = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "\n",
    "# # 2️⃣  Load your fine-tuned Reward Model (must use SequenceClassification loader)\n",
    "# tokenizer_rm = AutoTokenizer.from_pretrained(\"rm_dummy\")\n",
    "# reward_model = AutoModelForSequenceClassification.from_pretrained(\"rm_dummy\")\n",
    "\n",
    "# # 3️⃣  Build your PPO config\n",
    "# config = PPOConfig(\n",
    "#     exp_name                         = \"ppo_with_correct_rm\",\n",
    "#     num_ppo_epochs                   = 4,\n",
    "#     kl_coef                          = 0.1,\n",
    "#     cliprange                        = 0.2,\n",
    "#     vf_coef                          = 0.1,\n",
    "#     gamma                            = 0.99,\n",
    "#     lam                              = 0.95,\n",
    "\n",
    "#     learning_rate                    = 1e-5,\n",
    "#     per_device_train_batch_size      = 2,\n",
    "#     gradient_accumulation_steps      = 1,\n",
    "#     num_mini_batches                 = 1,\n",
    "#     local_rollout_forward_batch_size = 1,\n",
    "#     response_length                  = 20,\n",
    "#     temperature                      = 1.0,\n",
    "#     report_to                        = None,\n",
    "#     fp16                             = False,\n",
    "# )\n",
    "\n",
    "# # 4️⃣  Instantiate your PPOTrainer\n",
    "# ppo_trainer = PPOTrainer(\n",
    "#     args         = config,\n",
    "#     model        = policy_model,\n",
    "#     ref_model    = None,           # default: frozen copy of policy_model\n",
    "#     reward_model = reward_model,\n",
    "#     value_model  = value_model,\n",
    "#     tokenizer    = tokenizer,\n",
    "#     train_dataset= load_dataset(\"daily_dialog\", split=\"train[:8]\"),\n",
    "# )\n",
    "\n",
    "# # 5️⃣  Wrap RM inference into your reward function\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def compute_rewards(responses):\n",
    "#     # tokenize the generated strings with the RM’s tokenizer\n",
    "#     enc = tokenizer_rm(\n",
    "#         responses,\n",
    "#         padding=True,\n",
    "#         truncation=True,\n",
    "#         max_length=64,\n",
    "#         return_tensors=\"pt\",\n",
    "#     ).to(reward_model.device)\n",
    "\n",
    "#     # forward pass through your classifier head\n",
    "#     out = reward_model(**enc)\n",
    "#     # assume label 1 = “good”; take its probability\n",
    "#     probs = F.softmax(out.logits, dim=-1)[:, 1]\n",
    "#     return probs.tolist()\n",
    "\n",
    "# # 6️⃣  Run a single PPO step\n",
    "# batch    = [\"Tell me a joke.\", \"What is the capital of France?\"]\n",
    "# tok      = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "# queries  = tok.input_ids.to(ppo_trainer.args.device)\n",
    "\n",
    "# # generate responses\n",
    "# response_tensors = ppo_trainer.generate(queries)\n",
    "# responses        = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "# # score them\n",
    "# rewards = compute_rewards(responses)\n",
    "\n",
    "# # update the policy\n",
    "# stats = ppo_trainer.step(queries, response_tensors, rewards)\n",
    "\n",
    "# print(\"RESPONSES:\", responses)\n",
    "# print(\"REWARDS:  \", rewards)\n",
    "# print(\"PPO STATS:\", stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da41e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. train loop\n",
    "# for epoch in range(2):        # two passes for demo\n",
    "#     for prompt in prompts:\n",
    "#         # tokenize prompt\n",
    "#         inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "#         query_tensors = inputs.input_ids.to(ppo_trainer.device)\n",
    "\n",
    "#         # generate a response (this calls model.generate under the hood)\n",
    "#         response_tensors = ppo_trainer.generate(query_tensors, max_new_tokens=20)\n",
    "\n",
    "#         # decode\n",
    "#         responses = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "#         # compute rewards\n",
    "#         rewards = reward_fn(responses)\n",
    "\n",
    "#         # one PPO step (updates model in-place)\n",
    "#         stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "\n",
    "#         print(f\"PROMPT: {prompt!r}\")\n",
    "#         print(f\"RESPONSES: {responses}\")\n",
    "#         print(f\"REWARDS:   {rewards}\")\n",
    "#         print(f\"PPO stats: {stats}\")\n",
    "#         print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
