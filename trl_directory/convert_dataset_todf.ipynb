{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c66fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c857615",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_TRAIN_DATASET = \"sft_train_dataset.csv\"\n",
    "MASTER_EVAL_DATASET  = \"sft_eval_dataset.csv\"\n",
    "MASTER_TEST_DATASET  = \"sft_test_dataset.csv\"\n",
    "\n",
    "#Where to write flat files\n",
    "EXPORT_DIR = Path(\"sft_split_dataset\")\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train:\n",
      "  CSV    -> sft_split_dataset/train.csv\n",
      "Saved eval:\n",
      "  CSV    -> sft_split_dataset/eval.csv\n",
      "Saved test:\n",
      "  CSV    -> sft_split_dataset/test.csv\n"
     ]
    }
   ],
   "source": [
    "DESIRED_COLS = [\"uid\", \"original\", \"simplified\", \"applied_rules\"]\n",
    "\n",
    "def coerce_to_list(x):\n",
    "    \"\"\"Ensure applied_rules is a Python list.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        # Try JSON first\n",
    "        try:\n",
    "            y = json.loads(x)\n",
    "            return y if isinstance(y, list) else [y]\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Try Python-literal format: \"['a', 'b']\"\n",
    "        try:\n",
    "            y = literal_eval(x)\n",
    "            return y if isinstance(y, list) else [y]\n",
    "        except Exception:\n",
    "            # Fallback: split by comma, strip\n",
    "            return [p.strip() for p in x.split(\",\") if p.strip()]\n",
    "    # Fallback: wrap singletons\n",
    "    return [x]\n",
    "\n",
    "def ensure_schema(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop 'text' if present\n",
    "    if \"text\" in df.columns:\n",
    "        df = df.drop(columns=[\"text\"])\n",
    "\n",
    "    # Recover/construct uid\n",
    "    if \"uid\" not in df.columns:\n",
    "        # Some round-trips leave an index column like \"__index_level_0__\"\n",
    "        idx_cols = [c for c in df.columns if c.startswith(\"__index_level_\")]\n",
    "        if idx_cols:\n",
    "            df = df.rename(columns={idx_cols[0]: \"uid\"})\n",
    "        else:\n",
    "            # If nothing present, create a stable uid from current order\n",
    "            df[\"uid\"] = np.arange(1, len(df) + 1, dtype=int)\n",
    "\n",
    "    # Ensure required text columns exist (fill empty if missing)\n",
    "    for col in [\"original\", \"simplified\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # Ensure applied_rules exists\n",
    "    if \"applied_rules\" not in df.columns:\n",
    "        df[\"applied_rules\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "    # Type coercions\n",
    "    df[\"uid\"] = pd.to_numeric(df[\"uid\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    df[\"original\"] = df[\"original\"].astype(str)\n",
    "    df[\"simplified\"] = df[\"simplified\"].astype(str)\n",
    "    df[\"applied_rules\"] = df[\"applied_rules\"].apply(coerce_to_list)\n",
    "\n",
    "    # Order and sort\n",
    "    # Keep exactly these columns, in this order\n",
    "    df = df[DESIRED_COLS].sort_values(\"uid\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def save_all(df: pd.DataFrame, stem: str):\n",
    "    # CSV: serialize list to JSON so it round-trips cleanly\n",
    "    csv_df = df.copy()\n",
    "    csv_df[\"applied_rules\"] = csv_df[\"applied_rules\"].apply(json.dumps, ensure_ascii=False)\n",
    "    csv_path = EXPORT_DIR / f\"{stem}.csv\"\n",
    "    csv_df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Saved {stem}:\")\n",
    "    print(f\"  CSV    -> {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "def load_clean_save(ds_path: str, stem: str) -> pd.DataFrame:\n",
    "    ds = load_from_disk(ds_path)\n",
    "    df = ds.to_pandas()\n",
    "    df = ensure_schema(df)\n",
    "    save_all(df, stem)\n",
    "    return df\n",
    "\n",
    "train_df = load_clean_save(MASTER_TRAIN_DATASET, \"train\")\n",
    "eval_df  = load_clean_save(MASTER_EVAL_DATASET,  \"eval\")\n",
    "test_df  = load_clean_save(MASTER_TEST_DATASET,  \"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
