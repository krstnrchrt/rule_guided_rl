{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61652f61",
   "metadata": {},
   "source": [
    "# This notebook focuses on calculating quantifying metrics to assess the simplification quality of the pipeline\n",
    "\n",
    "### Primary Metric\n",
    "- SARI\n",
    "\n",
    "- Flesch Reading Ease formula (de)\n",
    "- Wiener Sachtextformel (the lower the score, the easier to read)\n",
    "  - 1 (WSTF-1) – For newspaper articles\n",
    "  - 2 (WSTF-2) – For brochures or technical texts\n",
    "  - 3 (WSTF-3) – For official documents\n",
    "  - 4 (WSTF-4) – For general texts (the most general/modern one, usually recommended unless you have a reason to choose another)\n",
    "  - usually 1 for newspapers, 2 for technical/brochure, 3 for official gov/admin texts\n",
    "- LIX (Lesbarkeitsindex), RIX (slightly adjusted)\n",
    "  - either from scratch or implemented from github source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7aeaf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9384e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from easse.sari import corpus_sari\n",
    "import os\n",
    "import textstat\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3ad439e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working dir\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "ORIGINAL = os.path.join(BASE_DIR, \"preprocessed_texts\", \"apa-rst\", \"0_original\")\n",
    "SYSTEM = os.path.join(BASE_DIR, \"preprocessed_texts\", \"apa-rst\", \"3_simplified\")\n",
    "REFERENCE = os.path.join(BASE_DIR, \"preprocessed_texts\", \"apa-rst\", \"0_1_referenceB1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01ce1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plain_files(dir_path):\n",
    "    \"\"\"\n",
    "    Returns list of filenames that end with _plain\"\"\"\n",
    "    return [f for f in os.listdir(dir_path) if f.endswith(\"_plain.txt\")]\n",
    "def get_files(dir_path):\n",
    "    \"\"\"\n",
    "    Returns list of filenames that end with -a2.txt\"\"\"\n",
    "    return [f for f in os.listdir(dir_path) if not f.startswith('.')]\n",
    "\n",
    "def read_aligned_triplets(original_path, system_path, reference_path):\n",
    "    # Each file: one line per input sentence (system/reference may be multi-sentence per line)\n",
    "    with open(original_path, encoding=\"utf-8\") as f:\n",
    "        originals = [line.strip() for line in f if line.strip()]\n",
    "    with open(system_path, encoding=\"utf-8\") as f:\n",
    "        systems = [line.strip() for line in f if line.strip()]\n",
    "    with open(reference_path, encoding=\"utf-8\") as f:\n",
    "        references = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # Sanity check\n",
    "    assert len(originals) == len(systems) == len(references), \\\n",
    "        f\"Lengths do not match: {len(originals)}, {len(systems)}, {len(references)}\"\n",
    "    return originals, systems, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0f2dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sent_4-freitag-28-1-22-or.txt', 'sent_3-freitag-28-1-22-or.txt', 'sent_1-29-11-21-or.txt', 'sent_1-freitag-28-1-22-or.txt', 'sent_2-freitag-28-1-22-or.txt', 'sent_5-freitag-28-1-22-or.txt', 'sent_3-18-1-22-or.txt', 'sent_4-21-2-18-or.txt', 'sent_3-dienstag-8-2-22-or.txt', 'sent_4-18-1-22-or.txt', 'sent_2-29-11-21-or.txt', 'sent_4-dienstag-8-2-22-or.txt', 'sent_3-21-2-18-or.txt', 'sent_2-21-2-18-or.txt', 'sent_5-29-11-21-or.txt', 'sent_5-18-1-22-or.txt', 'sent_5-21-2-18-or.txt', 'sent_2-18-1-22-or.txt', 'sent_4-29-11-21-or.txt', 'sent_1-dienstag-8-2-22-or.txt', 'sent_5-dienstag-8-2-22-or.txt', 'sent_1-21-2-18-or.txt', 'sent_1-18-1-22-or.txt', 'sent_2-dienstag-8-2-22-or.txt', 'sent_3-29-11-21-or.txt']\n"
     ]
    }
   ],
   "source": [
    "plain_files = get_plain_files(SYSTEM) # system output files\n",
    "reference_files = get_files(REFERENCE)\n",
    "original_files = get_files(ORIGINAL)\n",
    "print(original_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "deeca24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment error in sent_1-18-1-22-or_simplified_plain.txt: Lengths do not match: 20, 20, 6 -- flattening to whole document.\n",
      "Alignment error in sent_4-18-1-22-or_simplified_plain.txt: Lengths do not match: 10, 10, 8 -- flattening to whole document.\n",
      "Alignment error in sent_5-21-2-18-or_simplified_plain.txt: Lengths do not match: 24, 27, 8 -- flattening to whole document.\n",
      "Alignment error in sent_3-29-11-21-or_simplified_plain.txt: Lengths do not match: 22, 22, 10 -- flattening to whole document.\n",
      "Alignment error in sent_4-29-11-21-or_simplified_plain.txt: Lengths do not match: 32, 33, 11 -- flattening to whole document.\n",
      "Alignment error in sent_3-21-2-18-or_simplified_plain.txt: Lengths do not match: 9, 9, 7 -- flattening to whole document.\n",
      "Alignment error in sent_2-18-1-22-or_simplified_plain.txt: Lengths do not match: 64, 70, 9 -- flattening to whole document.\n",
      "Alignment error in sent_3-freitag-28-1-22-or_simplified_plain.txt: Lengths do not match: 9, 10, 8 -- flattening to whole document.\n",
      "Alignment error in sent_4-dienstag-8-2-22-or_simplified_plain.txt: Lengths do not match: 18, 18, 11 -- flattening to whole document.\n",
      "Alignment error in sent_2-21-2-18-or_simplified_plain.txt: Lengths do not match: 20, 20, 8 -- flattening to whole document.\n",
      "Alignment error in sent_2-29-11-21-or_simplified_plain.txt: Lengths do not match: 38, 41, 8 -- flattening to whole document.\n",
      "Alignment error in sent_5-dienstag-8-2-22-or_simplified_plain.txt: Lengths do not match: 16, 16, 7 -- flattening to whole document.\n",
      "Skipping sent_1-01-trial_simplified_plain.txt: missing original or reference file\n",
      "Alignment error in sent_2-freitag-28-1-22-or_simplified_plain.txt: Lengths do not match: 14, 15, 7 -- flattening to whole document.\n",
      "Alignment error in sent_3-18-1-22-or_simplified_plain.txt: Lengths do not match: 22, 22, 7 -- flattening to whole document.\n",
      "Alignment error in sent_1-freitag-28-1-22-or_simplified_plain.txt: Lengths do not match: 10, 10, 7 -- flattening to whole document.\n",
      "Alignment error in sent_5-freitag-28-1-22-or_simplified_plain.txt: Lengths do not match: 8, 8, 7 -- flattening to whole document.\n",
      "Alignment error in sent_5-18-1-22-or_simplified_plain.txt: Lengths do not match: 27, 27, 7 -- flattening to whole document.\n",
      "Alignment error in sent_2-dienstag-8-2-22-or_simplified_plain.txt: Lengths do not match: 29, 30, 9 -- flattening to whole document.\n",
      "Alignment error in sent_3-dienstag-8-2-22-or_simplified_plain.txt: Lengths do not match: 30, 31, 7 -- flattening to whole document.\n",
      "Alignment error in sent_4-freitag-28-1-22-or_simplified_plain.txt: Lengths do not match: 12, 12, 8 -- flattening to whole document.\n",
      "Alignment error in sent_1-29-11-21-or_simplified_plain.txt: Lengths do not match: 14, 14, 12 -- flattening to whole document.\n",
      "Alignment error in sent_1-21-2-18-or_simplified_plain.txt: Lengths do not match: 43, 43, 7 -- flattening to whole document.\n",
      "Alignment error in sent_1-dienstag-8-2-22-or_simplified_plain.txt: Lengths do not match: 21, 24, 8 -- flattening to whole document.\n",
      "Alignment error in sent_5-29-11-21-or_simplified_plain.txt: Lengths do not match: 19, 19, 10 -- flattening to whole document.\n",
      "Alignment error in sent_4-21-2-18-or_simplified_plain.txt: Lengths do not match: 52, 52, 11 -- flattening to whole document.\n"
     ]
    }
   ],
   "source": [
    "all_originals = []\n",
    "all_systems = []\n",
    "all_references = []\n",
    "\n",
    "for plain_file in plain_files:\n",
    "    # Get the base, e.g. sent_3-29-11-21-or\n",
    "    base = plain_file.replace('_simplified_plain.txt', '')\n",
    "    \n",
    "    # Original: exact match\n",
    "    original_file = os.path.join(ORIGINAL, base + \".txt\")\n",
    "\n",
    "    # Reference: remove -or or -trial if present, add -a2.txt\n",
    "    if base.endswith('-or'):\n",
    "        ref_base = base[:-3]  # remove '-or'\n",
    "    elif base.endswith('-trial'):\n",
    "        ref_base = base[:-6]  # remove '-trial'\n",
    "    else:\n",
    "        ref_base = base\n",
    "\n",
    "    reference_file = os.path.join(REFERENCE, ref_base + \"-b1.txt\") #check for a2 or b1\n",
    "    system_file = os.path.join(SYSTEM, plain_file)\n",
    "\n",
    "    # Print for debugging\n",
    "    # print(f\"\\nSystem: {system_file}\\nOriginal: {original_file}\\nReference: {reference_file}\")\n",
    "\n",
    "    # Check files exist\n",
    "    if not (os.path.exists(original_file) and os.path.exists(reference_file)):\n",
    "        print(f\"Skipping {plain_file}: missing original or reference file\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original, system, reference = read_aligned_triplets(\n",
    "            original_file, system_file, reference_file\n",
    "        )\n",
    "        for o, s, r in zip(original, system, reference):\n",
    "            all_originals.append(o)\n",
    "            all_systems.append(s)\n",
    "            all_references.append([r])  # Single reference per input\n",
    "    except AssertionError as e:\n",
    "        print(f\"Alignment error in {plain_file}: {e} -- flattening to whole document.\")\n",
    "        with open(original_file, encoding=\"utf-8\") as f:\n",
    "            o = \" \".join([line.strip() for line in f if line.strip()])\n",
    "        with open(system_file, encoding=\"utf-8\") as f:\n",
    "            s = \" \".join([line.strip() for line in f if line.strip()])\n",
    "        with open(reference_file, encoding=\"utf-8\") as f:\n",
    "            r = \" \".join([line.strip() for line in f if line.strip()])\n",
    "\n",
    "        all_originals.append(o)\n",
    "        all_systems.append(s)\n",
    "        all_references.append([r]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b362a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25\n",
      "[<class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_originals), len(all_systems), len(all_references))\n",
    "print([type(ref) for ref in all_references])\n",
    "print([len(ref) for ref in all_references])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "02c5f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARI for sample 0: 28.08\n",
      "SARI for sample 1: 28.95\n",
      "SARI for sample 2: 27.71\n",
      "SARI for sample 3: 30.35\n",
      "SARI for sample 4: 24.63\n",
      "SARI for sample 5: 27.94\n",
      "SARI for sample 6: 26.41\n",
      "SARI for sample 7: 25.35\n",
      "SARI for sample 8: 30.74\n",
      "SARI for sample 9: 27.87\n",
      "SARI for sample 10: 28.40\n",
      "SARI for sample 11: 24.83\n",
      "SARI for sample 12: 29.18\n",
      "SARI for sample 13: 30.73\n",
      "SARI for sample 14: 33.23\n",
      "SARI for sample 15: 37.72\n",
      "SARI for sample 16: 27.83\n",
      "SARI for sample 17: 27.75\n",
      "SARI for sample 18: 23.91\n",
      "SARI for sample 19: 31.85\n",
      "SARI for sample 20: 28.99\n",
      "SARI for sample 21: 24.67\n",
      "SARI for sample 22: 28.16\n",
      "SARI for sample 23: 27.98\n"
     ]
    }
   ],
   "source": [
    "def print_sari_per_sample(all_originals, all_systems, all_references, n=24):\n",
    "    for i in range(min(n, len(all_originals))):\n",
    "        sari = corpus_sari([all_originals[i]], [all_systems[i]], [all_references[i]])\n",
    "        print(f\"SARI for sample {i}: {sari:.2f}\")\n",
    "\n",
    "# Usage:\n",
    "print_sari_per_sample(all_originals, all_systems, all_references, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d550fe8",
   "metadata": {},
   "source": [
    "Above is the A2 calculation. Below is the B1 calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b963f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARI for sample 0: 25.44 ---\n",
      "SARI for sample 1: 33.11 ---\n",
      "SARI for sample 2: 27.98 ---\n",
      "SARI for sample 3: 30.85 ---\n",
      "SARI for sample 4: 23.85 ---\n",
      "SARI for sample 5: 29.60 ---\n",
      "SARI for sample 6: 25.93 ---\n",
      "SARI for sample 7: 26.44 ---\n",
      "SARI for sample 8: 34.15 ---\n",
      "SARI for sample 9: 27.84 ---\n",
      "SARI for sample 10: 29.23 ---\n",
      "SARI for sample 11: 25.76 ---\n",
      "SARI for sample 12: 34.01 ---\n",
      "SARI for sample 13: 31.93 ---\n",
      "SARI for sample 14: 38.62 ---\n",
      "SARI for sample 15: 44.58 ---\n",
      "SARI for sample 16: 28.13 ---\n",
      "SARI for sample 17: 29.05 ---\n",
      "SARI for sample 18: 24.13 ---\n",
      "SARI for sample 19: 33.39 ---\n",
      "SARI for sample 20: 28.49 ---\n",
      "SARI for sample 21: 25.06 ---\n",
      "SARI for sample 22: 28.93 ---\n",
      "SARI for sample 23: 27.49 ---\n",
      "SARI for sample 24: 22.45 ---\n"
     ]
    }
   ],
   "source": [
    "def print_sari_per_sample(all_originals, all_systems, all_references, n):\n",
    "    for i in range(min(n, len(all_originals))):\n",
    "        sari = corpus_sari([all_originals[i]], [all_systems[i]], [all_references[i]])\n",
    "        print(f\"SARI for sample {i}: {sari:.2f} ---\")\n",
    "\n",
    "# Usage:\n",
    "print_sari_per_sample(all_originals, all_systems, all_references, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2a0f5",
   "metadata": {},
   "source": [
    "# LIX + FLESCH + WIENER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e780f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plain_files(dir_path):\n",
    "    \"\"\"Returns list of filenames that end with _plain.txt\"\"\"\n",
    "    return [f for f in os.listdir(dir_path) if f.endswith(\"_plain.txt\")]\n",
    "\n",
    "def get_files(dir_path):\n",
    "    \"\"\"\n",
    "    Returns list of filenames that end with -a2.txt\"\"\"\n",
    "    return [f for f in os.listdir(dir_path) if not f.startswith('.')]\n",
    "\n",
    "def calc_lix(text):\n",
    "    \"\"\"\n",
    "    Custom LIX (Lesbarkeitsindex) calculation for German.\n",
    "    Formula: LIX = (words/sentences) + (100 * long_words/words)\n",
    "    where long_words = words with >= 7 letters.\n",
    "    \"\"\"\n",
    "    # Split sentences (naive, works for most German texts)\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    sentences = [s for s in sentences if s.strip()]\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    long_words = [w for w in words if len(w) >= 7]\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(words)\n",
    "    num_long_words = len(long_words)\n",
    "    if num_sentences == 0 or num_words == 0:\n",
    "        return 0.0\n",
    "    lix = (num_words / num_sentences) + (num_long_words * 100 / num_words)\n",
    "    return lix\n",
    "\n",
    "def process_metrics_for_files(system_dir, PLAIN):\n",
    "    if PLAIN == True:\n",
    "        files = get_plain_files(system_dir)\n",
    "    else:\n",
    "        files = get_files(system_dir)\n",
    "    results = []\n",
    "    for fname in files:\n",
    "        fpath = os.path.join(system_dir, fname)\n",
    "        with open(fpath, encoding=\"utf-8\") as f:\n",
    "            # Join all lines into one text\n",
    "            text = \" \".join([line.strip() for line in f if line.strip()])\n",
    "        # Calculate metrics\n",
    "        lix = calc_lix(text)\n",
    "        flesch = textstat.flesch_reading_ease(text)\n",
    "        wiener = textstat.wiener_sachtextformel(text, 1)\n",
    "        results.append({\n",
    "            \"filename\": fname,\n",
    "            \"LIX\": lix,\n",
    "            \"Flesch\": flesch,\n",
    "            \"Wiener_Sachtextformel\": wiener\n",
    "        })\n",
    "        print(f\"{fname}: LIX={lix:.2f} | Flesch={flesch:.2f} | Wiener={wiener:.2f}\")\n",
    "    # Optionally, save to CSV\n",
    "    # with open(\"readability_metrics_summary.csv\", \"w\", encoding=\"utf-8\", newline='') as out_csv:\n",
    "    #     writer = csv.DictWriter(out_csv, fieldnames=[\"filename\", \"LIX\", \"Flesch\", \"Wiener_Sachtextformel\"])\n",
    "    #     writer.writeheader()\n",
    "    #     writer.writerows(results)\n",
    "    # print(f\"Saved summary to readability_metrics_summary.csv\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "71bd1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_4-freitag-28-1-22-or.txt: LIX=44.74 | Flesch=59.78 | Wiener=5.88\n",
      "sent_3-freitag-28-1-22-or.txt: LIX=60.98 | Flesch=40.13 | Wiener=9.39\n",
      "sent_1-29-11-21-or.txt: LIX=51.89 | Flesch=45.64 | Wiener=9.37\n",
      "sent_1-freitag-28-1-22-or.txt: LIX=48.79 | Flesch=63.09 | Wiener=6.23\n",
      "sent_2-freitag-28-1-22-or.txt: LIX=51.76 | Flesch=64.52 | Wiener=7.05\n",
      "sent_5-freitag-28-1-22-or.txt: LIX=48.17 | Flesch=56.72 | Wiener=6.41\n",
      "sent_3-18-1-22-or.txt: LIX=52.66 | Flesch=54.55 | Wiener=7.01\n",
      "sent_4-21-2-18-or.txt: LIX=37.06 | Flesch=69.30 | Wiener=4.32\n",
      "sent_3-dienstag-8-2-22-or.txt: LIX=57.38 | Flesch=54.20 | Wiener=8.27\n",
      "sent_4-18-1-22-or.txt: LIX=44.57 | Flesch=59.34 | Wiener=6.94\n",
      "sent_2-29-11-21-or.txt: LIX=47.90 | Flesch=53.34 | Wiener=7.12\n",
      "sent_4-dienstag-8-2-22-or.txt: LIX=40.11 | Flesch=72.59 | Wiener=4.40\n",
      "sent_3-21-2-18-or.txt: LIX=56.10 | Flesch=41.58 | Wiener=9.74\n",
      "sent_2-21-2-18-or.txt: LIX=57.43 | Flesch=38.68 | Wiener=9.46\n",
      "sent_5-29-11-21-or.txt: LIX=41.89 | Flesch=69.40 | Wiener=4.79\n",
      "sent_5-18-1-22-or.txt: LIX=46.38 | Flesch=52.25 | Wiener=6.95\n",
      "sent_5-21-2-18-or.txt: LIX=47.90 | Flesch=54.05 | Wiener=6.93\n",
      "sent_2-18-1-22-or.txt: LIX=52.95 | Flesch=55.82 | Wiener=7.49\n",
      "sent_4-29-11-21-or.txt: LIX=49.04 | Flesch=51.99 | Wiener=7.22\n",
      "sent_1-dienstag-8-2-22-or.txt: LIX=43.21 | Flesch=56.37 | Wiener=6.64\n",
      "sent_5-dienstag-8-2-22-or.txt: LIX=61.12 | Flesch=33.06 | Wiener=10.23\n",
      "sent_1-21-2-18-or.txt: LIX=50.66 | Flesch=44.40 | Wiener=8.52\n",
      "sent_1-18-1-22-or.txt: LIX=51.66 | Flesch=51.55 | Wiener=7.95\n",
      "sent_2-dienstag-8-2-22-or.txt: LIX=52.96 | Flesch=49.24 | Wiener=8.15\n",
      "sent_3-29-11-21-or.txt: LIX=55.95 | Flesch=57.98 | Wiener=7.77\n",
      "sent_1-18-1-22-or_simplified_plain.txt: LIX=46.89 | Flesch=57.06 | Wiener=7.64\n",
      "sent_4-18-1-22-or_simplified_plain.txt: LIX=42.30 | Flesch=58.70 | Wiener=6.59\n",
      "sent_5-21-2-18-or_simplified_plain.txt: LIX=38.29 | Flesch=61.92 | Wiener=5.75\n",
      "sent_3-29-11-21-or_simplified_plain.txt: LIX=45.93 | Flesch=65.08 | Wiener=6.82\n",
      "sent_4-29-11-21-or_simplified_plain.txt: LIX=42.07 | Flesch=60.36 | Wiener=6.02\n",
      "sent_3-21-2-18-or_simplified_plain.txt: LIX=45.04 | Flesch=52.26 | Wiener=8.10\n",
      "sent_2-18-1-22-or_simplified_plain.txt: LIX=41.72 | Flesch=66.62 | Wiener=5.56\n",
      "sent_3-freitag-28-1-22-or_simplified_plain.txt: LIX=47.25 | Flesch=47.83 | Wiener=7.78\n",
      "sent_4-dienstag-8-2-22-or_simplified_plain.txt: LIX=33.03 | Flesch=81.79 | Wiener=3.36\n",
      "sent_2-21-2-18-or_simplified_plain.txt: LIX=49.54 | Flesch=48.45 | Wiener=8.03\n",
      "sent_2-29-11-21-or_simplified_plain.txt: LIX=44.95 | Flesch=58.96 | Wiener=6.53\n",
      "sent_5-dienstag-8-2-22-or_simplified_plain.txt: LIX=49.71 | Flesch=41.45 | Wiener=8.91\n",
      "sent_1-01-trial_simplified_plain.txt: LIX=28.57 | Flesch=91.88 | Wiener=1.28\n",
      "sent_2-freitag-28-1-22-or_simplified_plain.txt: LIX=42.25 | Flesch=70.57 | Wiener=6.06\n",
      "sent_3-18-1-22-or_simplified_plain.txt: LIX=45.82 | Flesch=62.11 | Wiener=6.07\n",
      "sent_1-freitag-28-1-22-or_simplified_plain.txt: LIX=40.87 | Flesch=72.18 | Wiener=4.97\n",
      "sent_5-freitag-28-1-22-or_simplified_plain.txt: LIX=37.02 | Flesch=62.01 | Wiener=5.72\n",
      "sent_5-18-1-22-or_simplified_plain.txt: LIX=39.54 | Flesch=58.61 | Wiener=6.16\n",
      "sent_2-dienstag-8-2-22-or_simplified_plain.txt: LIX=42.42 | Flesch=58.97 | Wiener=6.54\n",
      "sent_3-dienstag-8-2-22-or_simplified_plain.txt: LIX=44.20 | Flesch=62.49 | Wiener=6.86\n",
      "sent_4-freitag-28-1-22-or_simplified_plain.txt: LIX=33.82 | Flesch=71.40 | Wiener=4.21\n",
      "sent_1-29-11-21-or_simplified_plain.txt: LIX=46.39 | Flesch=55.23 | Wiener=8.00\n",
      "sent_1-21-2-18-or_simplified_plain.txt: LIX=43.75 | Flesch=52.32 | Wiener=7.34\n",
      "sent_1-dienstag-8-2-22-or_simplified_plain.txt: LIX=37.42 | Flesch=64.00 | Wiener=5.68\n",
      "sent_5-29-11-21-or_simplified_plain.txt: LIX=35.18 | Flesch=77.40 | Wiener=3.77\n",
      "sent_4-21-2-18-or_simplified_plain.txt: LIX=32.21 | Flesch=77.04 | Wiener=3.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'filename': 'sent_1-18-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 46.88967611336032,\n",
       "  'Flesch': 57.055150912838656,\n",
       "  'Wiener_Sachtextformel': 7.637591401648999},\n",
       " {'filename': 'sent_4-18-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 42.301587301587304,\n",
       "  'Flesch': 58.697828674948255,\n",
       "  'Wiener_Sachtextformel': 6.588515113871635},\n",
       " {'filename': 'sent_5-21-2-18-or_simplified_plain.txt',\n",
       "  'LIX': 38.293298071341034,\n",
       "  'Flesch': 61.91909883720933,\n",
       "  'Wiener_Sachtextformel': 5.7495834625323},\n",
       " {'filename': 'sent_3-29-11-21-or_simplified_plain.txt',\n",
       "  'LIX': 45.93333333333334,\n",
       "  'Flesch': 65.08284495548963,\n",
       "  'Wiener_Sachtextformel': 6.818469351420092},\n",
       " {'filename': 'sent_4-29-11-21-or_simplified_plain.txt',\n",
       "  'LIX': 42.07179487179487,\n",
       "  'Flesch': 60.35570692992647,\n",
       "  'Wiener_Sachtextformel': 6.021579063104918},\n",
       " {'filename': 'sent_3-21-2-18-or_simplified_plain.txt',\n",
       "  'LIX': 45.035353535353536,\n",
       "  'Flesch': 52.26159090909093,\n",
       "  'Wiener_Sachtextformel': 8.101225},\n",
       " {'filename': 'sent_2-18-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 41.71842054820778,\n",
       "  'Flesch': 66.62074239713778,\n",
       "  'Wiener_Sachtextformel': 5.558590412300877},\n",
       " {'filename': 'sent_3-freitag-28-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 47.25,\n",
       "  'Flesch': 47.83091743119269,\n",
       "  'Wiener_Sachtextformel': 7.777120838794232},\n",
       " {'filename': 'sent_4-dienstag-8-2-22-or_simplified_plain.txt',\n",
       "  'LIX': 33.028541226215644,\n",
       "  'Flesch': 81.79353637901862,\n",
       "  'Wiener_Sachtextformel': 3.364205897993716},\n",
       " {'filename': 'sent_2-21-2-18-or_simplified_plain.txt',\n",
       "  'LIX': 49.53843843843844,\n",
       "  'Flesch': 48.44912621359225,\n",
       "  'Wiener_Sachtextformel': 8.02673900234349},\n",
       " {'filename': 'sent_2-29-11-21-or_simplified_plain.txt',\n",
       "  'LIX': 44.95437995288071,\n",
       "  'Flesch': 58.96141245972075,\n",
       "  'Wiener_Sachtextformel': 6.5285925170068015},\n",
       " {'filename': 'sent_5-dienstag-8-2-22-or_simplified_plain.txt',\n",
       "  'LIX': 49.714285714285715,\n",
       "  'Flesch': 41.453537549407145,\n",
       "  'Wiener_Sachtextformel': 8.914121739130437},\n",
       " {'filename': 'sent_1-01-trial_simplified_plain.txt',\n",
       "  'LIX': 28.56777493606138,\n",
       "  'Flesch': 91.88075098814232,\n",
       "  'Wiener_Sachtextformel': 1.284478260869565},\n",
       " {'filename': 'sent_2-freitag-28-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 42.249188838416615,\n",
       "  'Flesch': 70.56871584699456,\n",
       "  'Wiener_Sachtextformel': 6.059098204527711},\n",
       " {'filename': 'sent_3-18-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 45.81720430107527,\n",
       "  'Flesch': 62.10809187279153,\n",
       "  'Wiener_Sachtextformel': 6.065404630193738},\n",
       " {'filename': 'sent_1-freitag-28-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 40.86868686868687,\n",
       "  'Flesch': 72.17818181818183,\n",
       "  'Wiener_Sachtextformel': 4.965296296296296},\n",
       " {'filename': 'sent_5-freitag-28-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 37.01875,\n",
       "  'Flesch': 62.00945652173917,\n",
       "  'Wiener_Sachtextformel': 5.721626086956521},\n",
       " {'filename': 'sent_5-18-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 39.536672629695886,\n",
       "  'Flesch': 58.61050400411435,\n",
       "  'Wiener_Sachtextformel': 6.16156948056719},\n",
       " {'filename': 'sent_2-dienstag-8-2-22-or_simplified_plain.txt',\n",
       "  'LIX': 42.41944847605225,\n",
       "  'Flesch': 58.972917964693664,\n",
       "  'Wiener_Sachtextformel': 6.542331568016616},\n",
       " {'filename': 'sent_3-dienstag-8-2-22-or_simplified_plain.txt',\n",
       "  'LIX': 44.20294523699954,\n",
       "  'Flesch': 62.493786135279265,\n",
       "  'Wiener_Sachtextformel': 6.861243262098552},\n",
       " {'filename': 'sent_4-freitag-28-1-22-or_simplified_plain.txt',\n",
       "  'LIX': 33.816435116760275,\n",
       "  'Flesch': 71.40454689984104,\n",
       "  'Wiener_Sachtextformel': 4.209232114467409},\n",
       " {'filename': 'sent_1-29-11-21-or_simplified_plain.txt',\n",
       "  'LIX': 46.38741134751773,\n",
       "  'Flesch': 55.23140434023449,\n",
       "  'Wiener_Sachtextformel': 7.998672037914691},\n",
       " {'filename': 'sent_1-21-2-18-or_simplified_plain.txt',\n",
       "  'LIX': 43.75353049060064,\n",
       "  'Flesch': 52.318472850678745,\n",
       "  'Wiener_Sachtextformel': 7.338335330524783},\n",
       " {'filename': 'sent_1-dienstag-8-2-22-or_simplified_plain.txt',\n",
       "  'LIX': 37.42385884158036,\n",
       "  'Flesch': 64.00036322125365,\n",
       "  'Wiener_Sachtextformel': 5.678096803652968},\n",
       " {'filename': 'sent_5-29-11-21-or_simplified_plain.txt',\n",
       "  'LIX': 35.17640320733104,\n",
       "  'Flesch': 77.39648947508663,\n",
       "  'Wiener_Sachtextformel': 3.769094697575273},\n",
       " {'filename': 'sent_4-21-2-18-or_simplified_plain.txt',\n",
       "  'LIX': 32.210111431187336,\n",
       "  'Flesch': 77.03555588235298,\n",
       "  'Wiener_Sachtextformel': 3.3107727058823535}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "PLAIN =False\n",
    "og_scores = process_metrics_for_files(ORIGINAL,PLAIN)\n",
    "og_scores\n",
    "\n",
    "PLAIN = True\n",
    "sys_scores = process_metrics_for_files(SYSTEM,PLAIN)\n",
    "sys_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b1496bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def safe_mode(lst):\n",
    "    try:\n",
    "        return statistics.mode(lst)\n",
    "    except statistics.StatisticsError:\n",
    "        # If multiple modes, return the smallest one (arbitrary choice)\n",
    "        return min(statistics.multimode(lst))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def describe_and_compare(og_scores, sys_scores, metric):\n",
    "    og_vals = [d[metric] for d in og_scores]\n",
    "    sys_vals = [d[metric] for d in sys_scores]\n",
    "    \n",
    "    if not og_vals or not sys_vals:\n",
    "        print(f\"\\n==== {metric} ====\")\n",
    "        print(f\"Not enough data for {metric}: original={len(og_vals)}, system={len(sys_vals)}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    mean_og = statistics.mean(og_vals)\n",
    "    median_og = statistics.median(og_vals)\n",
    "    mode_og = safe_mode(og_vals)\n",
    "\n",
    "    mean_sys = statistics.mean(sys_vals)\n",
    "    median_sys = statistics.median(sys_vals)\n",
    "    mode_sys = safe_mode(sys_vals)\n",
    "\n",
    "    abs_diff_mean = abs(mean_og - mean_sys)\n",
    "    abs_diff_median = abs(median_og - median_sys)\n",
    "    abs_diff_mode = abs(mode_og - mode_sys)\n",
    "\n",
    "    pct_diff_mean = (abs_diff_mean / mean_og * 100) if mean_og != 0 else float('nan')\n",
    "    pct_diff_median = (abs_diff_median / median_og * 100) if median_og != 0 else float('nan')\n",
    "    pct_diff_mode = (abs_diff_mode / mode_og * 100) if mode_og != 0 else float('nan')\n",
    "\n",
    "    print(f\"\\n==== {metric} ====\")\n",
    "    print(f\"Original: mean={mean_og:.2f}, median={median_og:.2f}, mode={mode_og:.2f}\")\n",
    "    print(f\"System:   mean={mean_sys:.2f}, median={median_sys:.2f}, mode={mode_sys:.2f}\")\n",
    "    print(f\"Difference in means:   abs={abs_diff_mean:.2f} | pct={pct_diff_mean:.2f}%\")\n",
    "    print(f\"Difference in medians: abs={abs_diff_median:.2f} | pct={pct_diff_median:.2f}%\")\n",
    "    print(f\"Difference in modes:   abs={abs_diff_mode:.2f} | pct={pct_diff_mode:.2f}%\")\n",
    "\n",
    "def report_stats(og_scores, sys_scores):\n",
    "    for metric in [\"LIX\", \"Flesch\", \"Wiener_Sachtextformel\"]:\n",
    "        describe_and_compare(og_scores, sys_scores, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e900c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== LIX ====\n",
      "Original: mean=50.13, median=50.66, mode=44.74\n",
      "System:   mean=41.39, median=42.28, mode=46.89\n",
      "Difference in means:   abs=8.74 | pct=17.43%\n",
      "Difference in medians: abs=8.38 | pct=16.55%\n",
      "Difference in modes:   abs=2.15 | pct=4.81%\n",
      "\n",
      "==== Flesch ====\n",
      "Original: mean=53.98, median=54.20, mode=59.78\n",
      "System:   mean=62.95, median=61.96, mode=57.06\n",
      "Difference in means:   abs=8.97 | pct=16.61%\n",
      "Difference in medians: abs=7.77 | pct=14.33%\n",
      "Difference in modes:   abs=2.72 | pct=4.55%\n",
      "\n",
      "==== Wiener_Sachtextformel ====\n",
      "Original: mean=7.37, median=7.12, mode=5.88\n",
      "System:   mean=6.04, median=6.11, mode=7.64\n",
      "Difference in means:   abs=1.33 | pct=18.03%\n",
      "Difference in medians: abs=1.01 | pct=14.15%\n",
      "Difference in modes:   abs=1.76 | pct=29.87%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "report_stats(og_scores, sys_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e118a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "\n",
    "tool = language_tool_python.LanguageTool('de')\n",
    "\n",
    "# def grammar_score(texts):\n",
    "#     # texts: list of sentences\n",
    "#     scores = []\n",
    "#     for sent in texts:\n",
    "#         matches = tool.check(sent)\n",
    "#         num_errors = len(matches)\n",
    "#         scores.append({\n",
    "#             \"sentence\": sent,\n",
    "#             \"errors\": num_errors,\n",
    "#             \"score\": 1 - num_errors / max(1, len(sent.split()))  # crude normalized \"correctness\"\n",
    "#         })\n",
    "#     return scores\n",
    "\n",
    "# sentences = [\n",
    "#     \"Ich habe ein Hund gesehen.\",\n",
    "#     \"Heute ist das Wetter schön.\",\n",
    "#     \"Sie gehen in die Schule morgen.\"\n",
    "# ]\n",
    "# results = grammar_score(sentences)\n",
    "# for r in results:\n",
    "#     print(f\"{r['sentence']} - Errors: {r['errors']}, Score: {r['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c49870",
   "metadata": {},
   "outputs": [
    {
     "ename": "LanguageToolError",
     "evalue": "Error: Internal Error: java.lang.RuntimeException: Could not activate rules, detected: de-DE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/site-packages/requests/models.py:963\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/site-packages/language_tool_python/server.py:248\u001b[0m, in \u001b[0;36mLanguageTool._query_server\u001b[0;34m(self, url, params, num_tries)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 971\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLanguageToolError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIch habe ein Hund gesehen.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/site-packages/language_tool_python/server.py:141\u001b[0m, in \u001b[0;36mLanguageTool.check\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Match text against enabled rules.\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m url \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murljoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 141\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m matches \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [Match(match) \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches]\n",
      "File \u001b[0;32m~/anaconda3/envs/im_env/lib/python3.8/site-packages/language_tool_python/server.py:258\u001b[0m, in \u001b[0;36mLanguageTool._query_server\u001b[0;34m(self, url, params, num_tries)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m    257\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m--> 258\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m LanguageToolError(response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIOError\u001b[39;00m, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPException) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[0;31mLanguageToolError\u001b[0m: Error: Internal Error: java.lang.RuntimeException: Could not activate rules, detected: de-DE"
     ]
    }
   ],
   "source": [
    "print(tool.check(\"Ich habe ein Hund gesehen.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6e6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "im_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
